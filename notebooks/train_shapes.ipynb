{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN - Train on Shapes Dataset\n",
    "\n",
    "\n",
    "This notebook shows how to train Mask R-CNN on your own dataset. To keep things simple we use a synthetic dataset of shapes (squares, triangles, and circles) which enables fast training. You'd still need a GPU, though, because the network backbone is a Resnet101, which would be too slow to train on a CPU. On a GPU, you can start to get okay-ish results in a few minutes, and good results in less than an hour.\n",
    "\n",
    "The code of the *Shapes* dataset is included below. It generates images on the fly, so it doesn't require downloading any data. And it can generate images of any size, so we pick a small image size to train faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Tensorflow Version: 1.4.0   Keras Version : 2.1.3 \n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('../')\n",
    "\n",
    "from mrcnn.config import Config\n",
    "import mrcnn.model as modellib\n",
    "import mrcnn.visualize as visualize\n",
    "from mrcnn.model import log\n",
    "import mrcnn.shapes as shapes\n",
    "from mrcnn.dataset import Dataset \n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "MODEL_PATH = 'E:/Models'\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(MODEL_PATH, \"mrcnn_logs\")\n",
    "\n",
    "# Path to COCO trained weights\n",
    "COCO_MODEL_PATH = os.path.join(MODEL_PATH, \"mask_rcnn_coco.h5\")\n",
    "RESNET_MODEL_PATH = os.path.join(MODEL_PATH,\"resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "print(\"Tensorflow Version: {}   Keras Version : {} \".format(tf.__version__,keras.__version__))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as KB\n",
    "if 'tensorflow' == KB.backend():\n",
    "    import tensorflow as tf\n",
    "    from keras.backend.tensorflow_backend import set_session\n",
    "    tfconfig = tf.ConfigProto(\n",
    "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.5),\n",
    "        device_count = {'GPU': 1}\n",
    "    )    \n",
    "#session = tf.Session(config=config)\n",
    "set_session(tf.Session(config=tfconfig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE_SHAPES                [[32 32]\n",
      " [16 16]\n",
      " [ 8  8]\n",
      " [ 4  4]\n",
      " [ 2  2]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     8\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "GPU_COUNT                      1\n",
      "IMAGES_PER_GPU                 8\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [128 128   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           shapes\n",
      "NUM_CLASSES                    4\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                100\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = shapes.ShapesConfig()\n",
    "config.display() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Create a synthetic dataset\n",
    "\n",
    "Extend the Dataset class and add a method to load the shapes dataset, `load_shapes()`, and override the following methods:\n",
    "\n",
    "* load_image()\n",
    "* load_mask()\n",
    "* image_reference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "# generate 500 shapes \n",
    "dataset_train = shapes.ShapesDataset()\n",
    "dataset_train.load_shapes(500, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = shapes.ShapesDataset()\n",
    "dataset_val.load_shapes(50, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1adfc4c61d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ade7f702e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ade82249b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 3)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " IMAGE SHAPE is : 128    128\n",
      "<class 'list'>\n",
      "Tensor(\"rpn_class_logits_1/concat:0\", shape=(?, ?, 2), dtype=float32) rpn_class_logits_1/concat:0\n",
      "Tensor(\"rpn_class_1/concat:0\", shape=(?, ?, 2), dtype=float32) rpn_class_1/concat:0\n",
      "Tensor(\"rpn_bbox_1/concat:0\", shape=(?, ?, 4), dtype=float32) rpn_bbox_1/concat:0\n",
      "Proposal Layer init complete. Size of anchors:  (4092, 4)\n",
      ">>> MaskRCNN build complete\n",
      ">>> MaskRCNN initialization complete\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(model)\n",
    "# Create model in training mode\n",
    "# MODEL_DIR = os.path.join(MODEL_PATH, \"mrcnn_logs\")\n",
    "import  gc\n",
    "# del history\n",
    "del model.keras_model\n",
    "gc.collect()\n",
    "\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:/Models\n",
      "E:/Models\\mask_rcnn_coco.h5\n",
      "E:/Models\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "E:/Models\\mrcnn_logs\n",
      "('E:/Models\\\\mrcnn_logs\\\\shapes20180303T1721', None)\n"
     ]
    }
   ],
   "source": [
    "print(MODEL_PATH)\n",
    "print(COCO_MODEL_PATH)\n",
    "print(RESNET_MODEL_PATH)\n",
    "print(MODEL_DIR)\n",
    "print(model.find_last())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Which weights to start with?\n",
    "init_with = \"last\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "#     loc=model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "    loc=model.load_weights(RESNET_MODEL_PATH, by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    loc=model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    loc= model.load_weights(model.find_last()[1], by_name=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  Name of layer:  input_image\n",
      "1  Name of layer:  zero_padding2d_1\n",
      "2  Name of layer:  conv1\n",
      "3  Name of layer:  bn_conv1\n",
      "4  Name of layer:  activation_1\n",
      "5  Name of layer:  max_pooling2d_1\n",
      "6  Name of layer:  res2a_branch2a\n",
      "7  Name of layer:  bn2a_branch2a\n",
      "8  Name of layer:  activation_2\n",
      "9  Name of layer:  res2a_branch2b\n",
      "10  Name of layer:  bn2a_branch2b\n",
      "11  Name of layer:  activation_3\n",
      "12  Name of layer:  res2a_branch2c\n",
      "13  Name of layer:  res2a_branch1\n",
      "14  Name of layer:  bn2a_branch2c\n",
      "15  Name of layer:  bn2a_branch1\n",
      "16  Name of layer:  add_1\n",
      "17  Name of layer:  res2a_out\n",
      "18  Name of layer:  res2b_branch2a\n",
      "19  Name of layer:  bn2b_branch2a\n",
      "20  Name of layer:  activation_4\n",
      "21  Name of layer:  res2b_branch2b\n",
      "22  Name of layer:  bn2b_branch2b\n",
      "23  Name of layer:  activation_5\n",
      "24  Name of layer:  res2b_branch2c\n",
      "25  Name of layer:  bn2b_branch2c\n",
      "26  Name of layer:  add_2\n",
      "27  Name of layer:  res2b_out\n",
      "28  Name of layer:  res2c_branch2a\n",
      "29  Name of layer:  bn2c_branch2a\n",
      "30  Name of layer:  activation_6\n",
      "31  Name of layer:  res2c_branch2b\n",
      "32  Name of layer:  bn2c_branch2b\n",
      "33  Name of layer:  activation_7\n",
      "34  Name of layer:  res2c_branch2c\n",
      "35  Name of layer:  bn2c_branch2c\n",
      "36  Name of layer:  add_3\n",
      "37  Name of layer:  res2c_out\n",
      "38  Name of layer:  res3a_branch2a\n",
      "39  Name of layer:  bn3a_branch2a\n",
      "40  Name of layer:  activation_8\n",
      "41  Name of layer:  res3a_branch2b\n",
      "42  Name of layer:  bn3a_branch2b\n",
      "43  Name of layer:  activation_9\n",
      "44  Name of layer:  res3a_branch2c\n",
      "45  Name of layer:  res3a_branch1\n",
      "46  Name of layer:  bn3a_branch2c\n",
      "47  Name of layer:  bn3a_branch1\n",
      "48  Name of layer:  add_4\n",
      "49  Name of layer:  res3a_out\n",
      "50  Name of layer:  res3b_branch2a\n",
      "51  Name of layer:  bn3b_branch2a\n",
      "52  Name of layer:  activation_10\n",
      "53  Name of layer:  res3b_branch2b\n",
      "54  Name of layer:  bn3b_branch2b\n",
      "55  Name of layer:  activation_11\n",
      "56  Name of layer:  res3b_branch2c\n",
      "57  Name of layer:  bn3b_branch2c\n",
      "58  Name of layer:  add_5\n",
      "59  Name of layer:  res3b_out\n",
      "60  Name of layer:  res3c_branch2a\n",
      "61  Name of layer:  bn3c_branch2a\n",
      "62  Name of layer:  activation_12\n",
      "63  Name of layer:  res3c_branch2b\n",
      "64  Name of layer:  bn3c_branch2b\n",
      "65  Name of layer:  activation_13\n",
      "66  Name of layer:  res3c_branch2c\n",
      "67  Name of layer:  bn3c_branch2c\n",
      "68  Name of layer:  add_6\n",
      "69  Name of layer:  res3c_out\n",
      "70  Name of layer:  res3d_branch2a\n",
      "71  Name of layer:  bn3d_branch2a\n",
      "72  Name of layer:  activation_14\n",
      "73  Name of layer:  res3d_branch2b\n",
      "74  Name of layer:  bn3d_branch2b\n",
      "75  Name of layer:  activation_15\n",
      "76  Name of layer:  res3d_branch2c\n",
      "77  Name of layer:  bn3d_branch2c\n",
      "78  Name of layer:  add_7\n",
      "79  Name of layer:  res3d_out\n",
      "80  Name of layer:  res4a_branch2a\n",
      "81  Name of layer:  bn4a_branch2a\n",
      "82  Name of layer:  activation_16\n",
      "83  Name of layer:  res4a_branch2b\n",
      "84  Name of layer:  bn4a_branch2b\n",
      "85  Name of layer:  activation_17\n",
      "86  Name of layer:  res4a_branch2c\n",
      "87  Name of layer:  res4a_branch1\n",
      "88  Name of layer:  bn4a_branch2c\n",
      "89  Name of layer:  bn4a_branch1\n",
      "90  Name of layer:  add_8\n",
      "91  Name of layer:  res4a_out\n",
      "92  Name of layer:  res4b_branch2a\n",
      "93  Name of layer:  bn4b_branch2a\n",
      "94  Name of layer:  activation_18\n",
      "95  Name of layer:  res4b_branch2b\n",
      "96  Name of layer:  bn4b_branch2b\n",
      "97  Name of layer:  activation_19\n",
      "98  Name of layer:  res4b_branch2c\n",
      "99  Name of layer:  bn4b_branch2c\n",
      "100  Name of layer:  add_9\n",
      "101  Name of layer:  res4b_out\n",
      "102  Name of layer:  res4c_branch2a\n",
      "103  Name of layer:  bn4c_branch2a\n",
      "104  Name of layer:  activation_20\n",
      "105  Name of layer:  res4c_branch2b\n",
      "106  Name of layer:  bn4c_branch2b\n",
      "107  Name of layer:  activation_21\n",
      "108  Name of layer:  res4c_branch2c\n",
      "109  Name of layer:  bn4c_branch2c\n",
      "110  Name of layer:  add_10\n",
      "111  Name of layer:  res4c_out\n",
      "112  Name of layer:  res4d_branch2a\n",
      "113  Name of layer:  bn4d_branch2a\n",
      "114  Name of layer:  activation_22\n",
      "115  Name of layer:  res4d_branch2b\n",
      "116  Name of layer:  bn4d_branch2b\n",
      "117  Name of layer:  activation_23\n",
      "118  Name of layer:  res4d_branch2c\n",
      "119  Name of layer:  bn4d_branch2c\n",
      "120  Name of layer:  add_11\n",
      "121  Name of layer:  res4d_out\n",
      "122  Name of layer:  res4e_branch2a\n",
      "123  Name of layer:  bn4e_branch2a\n",
      "124  Name of layer:  activation_24\n",
      "125  Name of layer:  res4e_branch2b\n",
      "126  Name of layer:  bn4e_branch2b\n",
      "127  Name of layer:  activation_25\n",
      "128  Name of layer:  res4e_branch2c\n",
      "129  Name of layer:  bn4e_branch2c\n",
      "130  Name of layer:  add_12\n",
      "131  Name of layer:  res4e_out\n",
      "132  Name of layer:  res4f_branch2a\n",
      "133  Name of layer:  bn4f_branch2a\n",
      "134  Name of layer:  activation_26\n",
      "135  Name of layer:  res4f_branch2b\n",
      "136  Name of layer:  bn4f_branch2b\n",
      "137  Name of layer:  activation_27\n",
      "138  Name of layer:  res4f_branch2c\n",
      "139  Name of layer:  bn4f_branch2c\n",
      "140  Name of layer:  add_13\n",
      "141  Name of layer:  res4f_out\n",
      "142  Name of layer:  res5a_branch2a\n",
      "143  Name of layer:  bn5a_branch2a\n",
      "144  Name of layer:  activation_28\n",
      "145  Name of layer:  res5a_branch2b\n",
      "146  Name of layer:  bn5a_branch2b\n",
      "147  Name of layer:  activation_29\n",
      "148  Name of layer:  res5a_branch2c\n",
      "149  Name of layer:  res5a_branch1\n",
      "150  Name of layer:  bn5a_branch2c\n",
      "151  Name of layer:  bn5a_branch1\n",
      "152  Name of layer:  add_14\n",
      "153  Name of layer:  res5a_out\n",
      "154  Name of layer:  res5b_branch2a\n",
      "155  Name of layer:  bn5b_branch2a\n",
      "156  Name of layer:  activation_30\n",
      "157  Name of layer:  res5b_branch2b\n",
      "158  Name of layer:  bn5b_branch2b\n",
      "159  Name of layer:  activation_31\n",
      "160  Name of layer:  res5b_branch2c\n",
      "161  Name of layer:  bn5b_branch2c\n",
      "162  Name of layer:  add_15\n",
      "163  Name of layer:  res5b_out\n",
      "164  Name of layer:  res5c_branch2a\n",
      "165  Name of layer:  bn5c_branch2a\n",
      "166  Name of layer:  activation_32\n",
      "167  Name of layer:  res5c_branch2b\n",
      "168  Name of layer:  bn5c_branch2b\n",
      "169  Name of layer:  activation_33\n",
      "170  Name of layer:  res5c_branch2c\n",
      "171  Name of layer:  bn5c_branch2c\n",
      "172  Name of layer:  add_16\n",
      "173  Name of layer:  res5c_out\n",
      "174  Name of layer:  fpn_c5p5\n",
      "175  Name of layer:  fpn_p5upsampled\n",
      "176  Name of layer:  fpn_c4p4\n",
      "177  Name of layer:  fpn_p4add\n",
      "178  Name of layer:  fpn_p4upsampled\n",
      "179  Name of layer:  fpn_c3p3\n",
      "180  Name of layer:  fpn_p3add\n",
      "181  Name of layer:  fpn_p3upsampled\n",
      "182  Name of layer:  fpn_c2p2\n",
      "183  Name of layer:  fpn_p2add\n",
      "184  Name of layer:  fpn_p5\n",
      "185  Name of layer:  fpn_p2\n",
      "186  Name of layer:  fpn_p3\n",
      "187  Name of layer:  fpn_p4\n",
      "188  Name of layer:  fpn_p6\n",
      "189  Name of layer:  rpn_model\n",
      "190  Name of layer:  rpn_class\n",
      "191  Name of layer:  rpn_bbox\n",
      "192  Name of layer:  input_gt_boxes\n",
      "193  Name of layer:  ROI\n",
      "194  Name of layer:  input_gt_class_ids\n",
      "195  Name of layer:  lambda_1\n",
      "196  Name of layer:  input_gt_masks\n",
      "197  Name of layer:  proposal_targets\n",
      "198  Name of layer:  roi_align_mask\n",
      "199  Name of layer:  mrcnn_mask_conv1\n",
      "200  Name of layer:  mrcnn_mask_bn1\n",
      "201  Name of layer:  activation_37\n",
      "202  Name of layer:  mrcnn_mask_conv2\n",
      "203  Name of layer:  roi_align_classifier\n",
      "204  Name of layer:  mrcnn_mask_bn2\n",
      "205  Name of layer:  mrcnn_class_conv1\n",
      "206  Name of layer:  activation_38\n",
      "207  Name of layer:  mrcnn_class_bn1\n",
      "208  Name of layer:  mrcnn_mask_conv3\n",
      "209  Name of layer:  activation_34\n",
      "210  Name of layer:  mrcnn_mask_bn3\n",
      "211  Name of layer:  mrcnn_class_conv2\n",
      "212  Name of layer:  activation_39\n",
      "213  Name of layer:  mrcnn_class_bn2\n",
      "214  Name of layer:  mrcnn_mask_conv4\n",
      "215  Name of layer:  activation_35\n",
      "216  Name of layer:  mrcnn_mask_bn4\n",
      "217  Name of layer:  pool_squeeze\n",
      "218  Name of layer:  activation_40\n",
      "219  Name of layer:  mrcnn_bbox_fc\n",
      "220  Name of layer:  mrcnn_mask_deconv\n",
      "221  Name of layer:  input_image_meta\n",
      "222  Name of layer:  rpn_class_logits\n",
      "223  Name of layer:  mrcnn_class_logits\n",
      "224  Name of layer:  mrcnn_bbox\n",
      "225  Name of layer:  mrcnn_mask\n",
      "226  Name of layer:  input_rpn_match\n",
      "227  Name of layer:  input_rpn_bbox\n",
      "228  Name of layer:  lambda_4\n",
      "229  Name of layer:  mrcnn_class\n",
      "230  Name of layer:  output_rois\n",
      "231  Name of layer:  rpn_class_loss\n",
      "232  Name of layer:  rpn_bbox_loss\n",
      "233  Name of layer:  mrcnn_class_loss\n",
      "234  Name of layer:  mrcnn_bbox_loss\n",
      "235  Name of layer:  mrcnn_mask_loss\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(model.keras_model.layers)):\n",
    "    print(i, ' Name of layer: ', model.keras_model.layers[i].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = tf.InteractiveSession()\n",
    "# model.keras_model.layers[229].output.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Train in two stages:\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
    "\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0 of 3 epochs. LR=0.001\n",
      "\n",
      "  Steps per epochs 5 \n",
      "Checkpoint Path: E:/Models\\mrcnn_logs\\shapes20180303T1727\\mask_rcnn_shapes_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Start of Training 1520094589.269974 \n",
      "Start epoch 0  loss {}  dict_keys([])\n",
      "\n",
      "Epoch 1/3\n",
      "\n",
      "... Start training of batch 0 size 8 keys dict_keys(['size', 'batch'])\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor of shape [] and type float\n\t [[Node: training_3/SGD/gradients/Square_364_grad/mul/x = Const[_class=[\"loc:@Square_364\"], dtype=DT_FLOAT, value=Tensor<type: float shape: [] values: 2>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](^training_3/SGD/gradients/mul_364_grad/Reshape_1)]]\n\nCaused by op 'training_3/SGD/gradients/Square_364_grad/mul/x', defined at:\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2856, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-28-953131452e03>\", line 9, in <module>\n    layers='heads')\n  File \"..\\mrcnn\\model.py\", line 795, in train\n    use_multiprocessing=False\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 2026, in fit_generator\n    self._make_train_function()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 970, in _make_train_function\n    loss=self.total_loss)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\optimizers.py\", line 162, in get_updates\n    grads = self.get_gradients(loss, params)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\optimizers.py\", line 78, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 2512, in gradients\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 581, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 353, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 581, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\", line 312, in _SquareGrad\n    return grad * (2.0 * x)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 909, in r_binary_op_wrapper\n    x = ops.convert_to_tensor(x, dtype=y.dtype.base_dtype, name=\"x\")\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 836, in convert_to_tensor\n    as_ref=False)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 926, in internal_convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\", line 229, in _constant_tensor_conversion_function\n    return constant(v, dtype=dtype, name=name)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\", line 214, in constant\n    name=name).outputs[0]\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\n...which was originally created as op 'Square_364', defined at:\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 19 identical lines from previous traceback]\n  File \"<ipython-input-28-953131452e03>\", line 9, in <module>\n    layers='heads')\n  File \"..\\mrcnn\\model.py\", line 783, in train\n    self.compile(learning_rate, self.config.LEARNING_MOMENTUM)\n  File \"..\\mrcnn\\model.py\", line 634, in compile\n    for w in self.keras_model.trainable_weights\n  File \"..\\mrcnn\\model.py\", line 635, in <listcomp>\n    if 'gamma' not in w.name and 'beta' not in w.name]\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\regularizers.py\", line 42, in __call__\n    regularization += K.sum(self.l2 * K.square(x))\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 1432, in square\n    return tf.square(x)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 449, in square\n    return gen_math_ops.square(x, name=name)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 4566, in square\n    \"Square\", x=x, name=name)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [] and type float\n\t [[Node: training_3/SGD/gradients/Square_364_grad/mul/x = Const[_class=[\"loc:@Square_364\"], dtype=DT_FLOAT, value=Tensor<type: float shape: [] values: 2>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](^training_3/SGD/gradients/mul_364_grad/Reshape_1)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [] and type float\n\t [[Node: training_3/SGD/gradients/Square_364_grad/mul/x = Const[_class=[\"loc:@Square_364\"], dtype=DT_FLOAT, value=Tensor<type: float shape: [] values: 2>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](^training_3/SGD/gradients/mul_364_grad/Reshape_1)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-953131452e03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             layers='heads')\n\u001b[0m",
      "\u001b[1;32mE:\\git_projs\\Mask_RCNN_2\\mrcnn\\model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers)\u001b[0m\n\u001b[0;32m    793\u001b[0m             \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m                                  \u001b[1;31m# max(self.config.BATCH_SIZE // 2, 2),\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    796\u001b[0m         )\n\u001b[0;32m    797\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2175\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2176\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2177\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2179\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1847\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1848\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1849\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1850\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1851\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2475\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2476\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1334\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1336\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [] and type float\n\t [[Node: training_3/SGD/gradients/Square_364_grad/mul/x = Const[_class=[\"loc:@Square_364\"], dtype=DT_FLOAT, value=Tensor<type: float shape: [] values: 2>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](^training_3/SGD/gradients/mul_364_grad/Reshape_1)]]\n\nCaused by op 'training_3/SGD/gradients/Square_364_grad/mul/x', defined at:\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2856, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-28-953131452e03>\", line 9, in <module>\n    layers='heads')\n  File \"..\\mrcnn\\model.py\", line 795, in train\n    use_multiprocessing=False\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 2026, in fit_generator\n    self._make_train_function()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 970, in _make_train_function\n    loss=self.total_loss)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\optimizers.py\", line 162, in get_updates\n    grads = self.get_gradients(loss, params)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\optimizers.py\", line 78, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 2512, in gradients\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 581, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 353, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 581, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\", line 312, in _SquareGrad\n    return grad * (2.0 * x)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 909, in r_binary_op_wrapper\n    x = ops.convert_to_tensor(x, dtype=y.dtype.base_dtype, name=\"x\")\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 836, in convert_to_tensor\n    as_ref=False)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 926, in internal_convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\", line 229, in _constant_tensor_conversion_function\n    return constant(v, dtype=dtype, name=name)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\", line 214, in constant\n    name=name).outputs[0]\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\n...which was originally created as op 'Square_364', defined at:\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 19 identical lines from previous traceback]\n  File \"<ipython-input-28-953131452e03>\", line 9, in <module>\n    layers='heads')\n  File \"..\\mrcnn\\model.py\", line 783, in train\n    self.compile(learning_rate, self.config.LEARNING_MOMENTUM)\n  File \"..\\mrcnn\\model.py\", line 634, in compile\n    for w in self.keras_model.trainable_weights\n  File \"..\\mrcnn\\model.py\", line 635, in <listcomp>\n    if 'gamma' not in w.name and 'beta' not in w.name]\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\regularizers.py\", line 42, in __call__\n    regularization += K.sum(self.l2 * K.square(x))\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 1432, in square\n    return tf.square(x)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 449, in square\n    return gen_math_ops.square(x, name=name)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 4566, in square\n    \"Square\", x=x, name=name)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [] and type float\n\t [[Node: training_3/SGD/gradients/Square_364_grad/mul/x = Const[_class=[\"loc:@Square_364\"], dtype=DT_FLOAT, value=Tensor<type: float shape: [] values: 2>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](^training_3/SGD/gradients/mul_364_grad/Reshape_1)]]\n"
     ]
    }
   ],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "config.STEPS_PER_EPOCH = 5\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=3, \n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model.keras_model.summary(line_length=110)\n",
    "\n",
    "# from keras.utils import plot_model\n",
    "# plot_model(model.keras_model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0 of 4 epochs. LR=0.0001\n",
      "\n",
      "  Steps per epochs 5 \n",
      "Checkpoint Path: E:/Models\\mrcnn_logs\\shapes20180303T1705\\mask_rcnn_shapes_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Start of Training 1520093511.0509152 \n",
      "Start epoch 0  loss {}  dict_keys([])\n",
      "\n",
      "Epoch 1/4\n",
      "\n",
      "... Start training of batch 0 size 8 keys dict_keys(['size', 'batch'])\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[8,512,32,32]\n\t [[Node: rpn_model/rpn_conv_shared/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](fpn_p2/BiasAdd, rpn_conv_shared/kernel/read)]]\n\t [[Node: ROI/strided_slice_145/_4825 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_7827_ROI/strided_slice_145\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'rpn_model/rpn_conv_shared/convolution', defined at:\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-c47828c1aa63>\", line 11, in <module>\n    model_dir=MODEL_DIR)\n  File \"..\\mrcnn\\model.py\", line 275, in __init__\n    self.keras_model = self.build(mode=mode, config=config)\n  File \"..\\mrcnn\\model.py\", line 377, in build\n    layer_outputs.append(rpn([p]))\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\engine\\topology.py\", line 617, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\engine\\topology.py\", line 2078, in call\n    output_tensors, _, _ = self.run_internal_graph(inputs, masks)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\engine\\topology.py\", line 2229, in run_internal_graph\n    output_tensors = _to_list(layer.call(computed_tensor, **kwargs))\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 168, in call\n    dilation_rate=self.dilation_rate)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 3332, in conv2d\n    data_format=tf_data_format)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 751, in convolution\n    return op(input, filter)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 835, in __call__\n    return self.conv_op(inp, filter)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 499, in __call__\n    return self.call(inp, filter)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 187, in __call__\n    name=self.name)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 630, in conv2d\n    data_format=data_format, name=name)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[8,512,32,32]\n\t [[Node: rpn_model/rpn_conv_shared/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](fpn_p2/BiasAdd, rpn_conv_shared/kernel/read)]]\n\t [[Node: ROI/strided_slice_145/_4825 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_7827_ROI/strided_slice_145\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[8,512,32,32]\n\t [[Node: rpn_model/rpn_conv_shared/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](fpn_p2/BiasAdd, rpn_conv_shared/kernel/read)]]\n\t [[Node: ROI/strided_slice_145/_4825 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_7827_ROI/strided_slice_145\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-44b8871bbdb5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             layers=\"all\")\n\u001b[0m",
      "\u001b[1;32mE:\\git_projs\\Mask_RCNN_2\\mrcnn\\model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers)\u001b[0m\n\u001b[0;32m    793\u001b[0m             \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m                                  \u001b[1;31m# max(self.config.BATCH_SIZE // 2, 2),\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    796\u001b[0m         )\n\u001b[0;32m    797\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2175\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2176\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2177\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2179\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1847\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1848\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1849\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1850\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1851\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2475\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2476\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1334\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1336\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[8,512,32,32]\n\t [[Node: rpn_model/rpn_conv_shared/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](fpn_p2/BiasAdd, rpn_conv_shared/kernel/read)]]\n\t [[Node: ROI/strided_slice_145/_4825 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_7827_ROI/strided_slice_145\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'rpn_model/rpn_conv_shared/convolution', defined at:\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-c47828c1aa63>\", line 11, in <module>\n    model_dir=MODEL_DIR)\n  File \"..\\mrcnn\\model.py\", line 275, in __init__\n    self.keras_model = self.build(mode=mode, config=config)\n  File \"..\\mrcnn\\model.py\", line 377, in build\n    layer_outputs.append(rpn([p]))\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\engine\\topology.py\", line 617, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\engine\\topology.py\", line 2078, in call\n    output_tensors, _, _ = self.run_internal_graph(inputs, masks)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\engine\\topology.py\", line 2229, in run_internal_graph\n    output_tensors = _to_list(layer.call(computed_tensor, **kwargs))\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 168, in call\n    dilation_rate=self.dilation_rate)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 3332, in conv2d\n    data_format=tf_data_format)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 751, in convolution\n    return op(input, filter)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 835, in __call__\n    return self.conv_op(inp, filter)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 499, in __call__\n    return self.call(inp, filter)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 187, in __call__\n    name=self.name)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 630, in conv2d\n    data_format=data_format, name=name)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[8,512,32,32]\n\t [[Node: rpn_model/rpn_conv_shared/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](fpn_p2/BiasAdd, rpn_conv_shared/kernel/read)]]\n\t [[Node: ROI/strided_slice_145/_4825 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_7827_ROI/strided_slice_145\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also \n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "config.STEPS_PER_EPOCH = 5\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=4,\n",
    "            layers=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "# Uncomment to save manually\n",
    "model_path = os.path.join(MODEL_DIR, \"mask_rcnn_shapes.h5\")\n",
    "model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(ShapesConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model_path = model.find_last()[1]\n",
    "\n",
    "# Load trained weights (fill in path to trained weights here)\n",
    "assert model_path != \"\", \"Provide path to trained weights\"\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a random image\n",
    "image_id = random.choice(dataset_val.image_ids)\n",
    "\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_val, inference_config, image_id, use_mini_mask=False)\n",
    "\n",
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"gt_class_id\", gt_bbox)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                            dataset_train.class_names, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.detect([original_image], verbose=1)\n",
    "\n",
    "r = results[0]\n",
    "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'], ax=get_ax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute VOC-Style mAP @ IoU=0.5\n",
    "# Running on 10 images. Increase for better accuracy.\n",
    "image_ids = np.random.choice(dataset_val.image_ids, 10)\n",
    "APs = []\n",
    "for image_id in image_ids:\n",
    "    # Load image and ground truth data\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, inference_config,\n",
    "                               image_id, use_mini_mask=False)\n",
    "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
    "    # Run object detection\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "    # Compute AP\n",
    "    AP, precisions, recalls, overlaps =\\\n",
    "        utils.compute_ap(gt_bbox, gt_class_id,\n",
    "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"])\n",
    "    APs.append(AP)\n",
    "    \n",
    "print(\"mAP: \", np.mean(APs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [TF_gpu]",
   "language": "python",
   "name": "Python [TF_gpu]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
