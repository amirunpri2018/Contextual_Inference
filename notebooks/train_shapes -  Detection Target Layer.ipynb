{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Mask R-CNN - Simulate the `DetectionTargetLayer` Process\n",
    "\n",
    "We generate the inputs to `DetectTargetLayer` , to manipulate and modify the layer to procduce a modified `output_rois` \n",
    "containing false positives. \n",
    "This will be passed on the the heatmap layer, and through there will become the input to FCN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T19:59:49.457539Z",
     "start_time": "2018-05-06T19:59:49.445510Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:94% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:94% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T19:59:59.894440Z",
     "start_time": "2018-05-06T19:59:50.158405Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 1.6.0   Keras Version : 2.1.4 \n",
      " Initialize config object - super\n",
      "\n",
      "Configuration Parameters:\n",
      "-------------------------\n",
      "BACKBONE_SHAPES                [[32 32]\n",
      " [16 16]\n",
      " [ 8  8]\n",
      " [ 4  4]\n",
      " [ 2  2]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "EPOCHS_TO_RUN                  0\n",
      "FCN_INPUT_SHAPE                [128 128]\n",
      "GPU_COUNT                      1\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [128 128   3]\n",
      "LAST_EPOCH_RAN                 0\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           shapes\n",
      "NUM_CLASSES                    4\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                2\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      " COCO Model Path       :  E:\\Models\\mask_rcnn_coco.h5\n",
      " Checkpoint folder Path:  E:\\Models\\mrcnn_logs\n",
      "    set_log_dir: Checkpoint path set to : E:\\Models\\mrcnn_logs\\shapes20180506T2159\\mask_rcnn_shapes_{epoch:04d}.h5\n",
      "    set_log_dir: self.epoch set to 0 \n",
      "\n",
      ">>> Resnet Graph \n",
      "     Input_image shape : (?, 128, 128, 3)\n",
      "     After ZeroPadding2D  : (?, 134, 134, 3) (?, 134, 134, 3)\n",
      "     After Conv2D padding : (?, 64, 64, 64) (?, 64, 64, 64)\n",
      "     After BatchNorm      : (?, 64, 64, 64) (?, 64, 64, 64)\n",
      "     After MaxPooling2D   : (?, 32, 32, 64) (?, 32, 32, 64)\n",
      "\n",
      ">>> Feature Pyramid Network (FPN) Graph \n",
      "     FPN P2 shape : (None, 32, 32, 256)\n",
      "     FPN P3 shape : (None, 16, 16, 256)\n",
      "     FPN P4 shape : (None, 8, 8, 256)\n",
      "     FPN P5 shape : (None, 4, 4, 256)\n",
      "     FPN P6 shape : (None, 2, 2, 256)\n",
      "\n",
      ">>> RPN Layer \n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     depth                   : 256\n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     anchor_stride           : 1\n",
      "\n",
      ">>> RPN Outputs  <class 'list'>\n",
      "      rpn_class_logits/concat:0\n",
      "      rpn_class/concat:0\n",
      "      rpn_bbox/concat:0\n",
      "\n",
      ">>> Proposal Layer - generate  2000  proposals\n",
      "    Init complete. Size of anchors:  (4092, 4)\n",
      "     Scores :  (1, 4092)\n",
      "     Deltas :  (1, 4092, 4)\n",
      "     Anchors:  (1, 4092, 4)\n",
      "     Boxes shape / type after processing:  (1, 4092, 4) <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "     Output: Prposals shape :  (1, ?, ?) (1, None, None)\n",
      "\n",
      ">>> Detection Target Layer \n",
      "    Detection Target Layer : call()  <class 'list'> 4\n",
      "     proposals.shape    : (1, ?, ?) (1, ?, ?) (None, 2000, 4)\n",
      "     gt_class_ids.shape : (?, ?) (?, ?) (None, None)\n",
      "     gt_bboxes.shape    : (?, ?, 4) (?, ?, 4) (None, None, 4)\n",
      "     gt_masks.shape     : (?, 56, 56, ?) (?, 56, 56, ?) (None, 56, 56, None)\n",
      ">>> detection_targets_graph \n",
      "     propsals.shape        : (?, ?) (?, ?) (None, None)\n",
      "     gt_boxes.shape        : (?, 4) (None, 4)\n",
      "     gt_class_ids.shape    : (?,) (None,)\n",
      "     gt_masks.shape        : (56, 56, ?) (56, 56, None)\n",
      "\t     Overlaps_graph(): Shape of output overlaps Tensor(\"proposal_targets/Shape_5:0\", shape=(2,), dtype=int32) (?, ?)\n",
      "\t     Overlaps_graph(): Shape of output overlaps Tensor(\"proposal_targets/Shape_10:0\", shape=(2,), dtype=int32) (?, ?)\n",
      "\n",
      "    Detection Target Layer : return  <class 'list'> 5\n",
      "     output 0  shape (1, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 1  shape (1, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 2  shape (1, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 3  shape (1, ?, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 4  shape (1, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "\n",
      ">>> FPN Classifier Graph \n",
      "     rois shape          : (1, ?, ?)\n",
      "     feature_maps : 4\n",
      "     feature_maps shape  : (?, 32, 32, 256)\n",
      "     feature_maps shape  : (?, 16, 16, 256)\n",
      "     feature_maps shape  : (?, 8, 8, 256)\n",
      "     feature_maps shape  : (?, 4, 4, 256)\n",
      "     input_shape         : [128 128   3]\n",
      "     pool_size           : 7\n",
      "\n",
      ">>> FPN Mask Graph \n",
      "     rois shape          : (1, ?, ?)\n",
      "     feature_maps : 4\n",
      "     feature_maps shape  : (?, 32, 32, 256)\n",
      "     feature_maps shape  : (?, 16, 16, 256)\n",
      "     feature_maps shape  : (?, 8, 8, 256)\n",
      "     feature_maps shape  : (?, 4, 4, 256)\n",
      "     input_shape         : [128 128   3]\n",
      "     pool_size           : 14\n",
      "     FPN Mask Graph output shape : (?, 32, 28, 28, 4)\n",
      "\n",
      ">>> PCN Layer TF \n",
      "   > PCNLayerTF Call()  5\n",
      "     mrcnn_class.shape    : (?, 32, 4) (None, 32, 4)\n",
      "     mrcnn_bbox.shape     : (?, 32, 4, 4) (None, 32, 4, 4)\n",
      "     output_rois.shape    : (1, ?, ?) (None, 32, 4)\n",
      "     gt_class_ids.shape   : (?, ?) (None, None)\n",
      "     gt_bboxes.shape      : (?, ?, 4) (None, None, 4)\n",
      "\n",
      "  > BUILD_PREDICTIONS_TF()\n",
      "    num_rois          :  32\n",
      "    mrcnn_class shape :  Tensor(\"cntxt_layer/Shape:0\", shape=(3,), dtype=int32) (None, 32, 4)\n",
      "    mrcnn_bbox.shape  :  Tensor(\"cntxt_layer/Shape_1:0\", shape=(4,), dtype=int32) (None, 32, 4, 4) (?, 32, 4, 4)\n",
      "    output_rois.shape :  Tensor(\"cntxt_layer/Shape_2:0\", shape=(3,), dtype=int32) (1, None, 4)\n",
      "    pred_classes     :  (?, 32)\n",
      "    pred_classes_exp :  (?, 32, 1)\n",
      "    pred_scores      :  (?, 32, 1)\n",
      "    batch_grid       :  (1, 32)\n",
      "    roi_grid         :  (1, 32)\n",
      "    bbox_idx         :  (1, 32, 1)\n",
      "\n",
      "    -- pred_tensor tf ------------------------------\n",
      "    pred_array shape: (1, 32, 6)\n",
      "    pred_scatter shape is  (1, 4, 32, 6) Tensor(\"cntxt_layer/ScatterNd:0\", shape=(1, 4, 32, 6), dtype=float32)\n",
      "    sort inds shape :  (1, 4, 32)\n",
      "    class_grid   <class 'tensorflow.python.framework.ops.Tensor'> shape (1, 4, 32)\n",
      "    batch_grid   <class 'tensorflow.python.framework.ops.Tensor'> shape (1, 4, 32)\n",
      "    roi_grid shape (1, 4, 32) roi_grid_exp shape  (1, 4, 32, 1)\n",
      "    gather_inds  <class 'tensorflow.python.framework.ops.Tensor'> shape (1, 4, 32, 3)\n",
      "    pred_tensor (gathered)  :  (1, 4, 32, 6)\n",
      "    -- pred_tensor results (bboxes sorted by score) ----\n",
      "    final pred_tensor shape  :  (1, 4, 32, 6)\n",
      "    final pred_cls_cnt shape :  (1, 4)\n",
      "    complete\n",
      "\n",
      "\n",
      "  > BUILD_GROUND TRUTH_TF()\n",
      "    gt_class_ids shape :  (?, ?)     notm_gt_bbox.shape  :  (?, ?, 4)\n",
      "    gt_classes_exp shape  (?, ?, 1)\n",
      "    pred_ scores shape  (?, ?)\n",
      "    bbox_idx shape     (1, 100, 1)\n",
      "    gt_array shape     (?, ?, 6)\n",
      "    bbox_grid  shape   (1, 100)\n",
      "    batch_grid shape   (1, 100)\n",
      "    scatter_ind shape  (1, 100, 3)\n",
      "    gt_scatter shape  (1, 4, 100, 6)\n",
      "    build gathering indexes to use in sorting -------\n",
      "    sort inds shape :  (1, 4, 100)\n",
      "    class_grid  shape  (1, 4, 100)\n",
      "    batch_grid  shape  (1, 4, 100)\n",
      "    bbox_grid   shape  (1, 4, 100)  bbox_grid_exp shape  (1, 4, 100, 1)\n",
      "    gather_inds shape      :  (1, 4, 100, 3)\n",
      "    gt_tensor (gathered)   :  (1, 4, 100, 6)\n",
      "    final gt_tensor shape  :  (1, 4, 100, 6)\n",
      "    final gt_cls_cnt shape :  (1, 4)\n",
      "    complete\n",
      "\n",
      " \n",
      "  > BUILD_GAUSSIAN_TF() for  ['pred_gaussian']\n",
      "    orignal in_tensor shape :  (1, 4, 32, 6)\n",
      "    modified in_tensor shape :  (1, 4, 32, 6)\n",
      "    num of bboxes per class is :  Tensor(\"cntxt_layer/ToInt32_1/x:0\", shape=(), dtype=int32)\n",
      "    after transpose  (128, 128, 1, 32, 2)\n",
      "    pt2_sum shape  (1, 4, 32)\n",
      "    dense shape  (?, 6)\n",
      "    Build Stacked output from dynamically partitioned lists --------------\n",
      "    >> input to MVN.PROB: pos_grid (meshgrid) shape:  (128, 128, 1, 32, 2)\n",
      "    << output probabilities shape: (?, 32, 128, 128)\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    gaussian_grid      :  (?, 32, 128, 128)\n",
      "    class shape        :  (1, ?)\n",
      "    roi_grid shape     :  (1, 32)\n",
      "    batch_grid shape   :  (1, 32)\n",
      "    scatter_classes    :  (1, 32, 3)\n",
      "    gaussian scattered :  (1, 4, 32, 128, 128)\n",
      "\n",
      "    Reduce sum based on class ---------------------------------------------\n",
      "    gaussian sum type/name :  <class 'tensorflow.python.framework.ops.Tensor'> cntxt_layer/pred_gaussian_1:0 pred_gaussian\n",
      "    gaussian_sum shape     :  (1, 128, 128, 4) Keras tensor  False\n",
      "\n",
      " \n",
      "  > BUILD_GAUSSIAN_TF() for  ['gt_gaussian']\n",
      "    orignal in_tensor shape :  (1, 4, 100, 6)\n",
      "    modified in_tensor shape :  (1, 4, 100, 6)\n",
      "    num of bboxes per class is :  Tensor(\"cntxt_layer/ToInt32_4/x:0\", shape=(), dtype=int32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    after transpose  (128, 128, 1, 100, 2)\n",
      "    pt2_sum shape  (1, 4, 100)\n",
      "    dense shape  (?, 6)\n",
      "    Build Stacked output from dynamically partitioned lists --------------\n",
      "    >> input to MVN.PROB: pos_grid (meshgrid) shape:  (128, 128, 1, 100, 2)\n",
      "    << output probabilities shape: (?, 100, 128, 128)\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    gaussian_grid      :  (?, 100, 128, 128)\n",
      "    class shape        :  (1, ?)\n",
      "    roi_grid shape     :  (1, 100)\n",
      "    batch_grid shape   :  (1, 100)\n",
      "    scatter_classes    :  (1, 100, 3)\n",
      "    gaussian scattered :  (1, 4, 100, 128, 128)\n",
      "\n",
      "    Reduce sum based on class ---------------------------------------------\n",
      "    gaussian sum type/name :  <class 'tensorflow.python.framework.ops.Tensor'> cntxt_layer/gt_gaussian:0 gt_gaussian\n",
      "    gaussian_sum shape     :  (1, 128, 128, 4) Keras tensor  False\n",
      "\n",
      "    Output build_gaussian_tf \n",
      "     pred_gaussian :  (1, 128, 128, 4) Keras tensor  False\n",
      "     gt_gaussian   :  (1, 128, 128, 4) Keras tensor  False\n",
      "<<<  shape of pred_gaussian   :  (1, 128, 128, 4)  Keras tensor  True\n",
      "<<<  shape of gt_gaussian     :  (1, 128, 128, 4)  Keras tensor  True\n",
      "\n",
      ">>> rpn_bbox_loss_graph\n",
      "    rpn_match size : (?, ?)\n",
      "    rpn_bbox  size : (?, ?, 4)\n",
      "    tf default session:  None\n",
      "\n",
      ">>> rpn_bbox_loss_graph\n",
      "    rpn_match size : (?, ?)\n",
      "    rpn_bbox  size : (?, ?, 4)\n",
      "    tf default session:  None\n",
      "\n",
      ">>> mrcnn_class_loss_graph \n",
      "    target_class_ids  size : (1, ?)\n",
      "    pred_class_logits size : (?, 32, 4)\n",
      "    active_class_ids  size : (?, ?)\n",
      "\n",
      ">>> mrcnn_class_loss_graph \n",
      "    target_class_ids  size : (?, 1)\n",
      "    pred_class_logits size : (?, 32, 4)\n",
      "    active_class_ids  size : (?, ?)\n",
      "\n",
      ">>> mrcnn_bbox_loss_graph \n",
      "    target_class_ids  size : (1, ?)\n",
      "    pred_bbox size         : (?, 32, 4, 4)\n",
      "    target_bbox size       : (1, ?, ?)\n",
      "\n",
      ">>> mrcnn_bbox_loss_graph \n",
      "    target_class_ids  size : (?, 1)\n",
      "    pred_bbox size         : (?, 32, 4, 4)\n",
      "    target_bbox size       : (?, 32, 4)\n",
      "\n",
      ">>> mrcnn_mask_loss_graph \n",
      "    target_class_ids shape : (1, ?)\n",
      "    target_masks     shape : (1, ?, ?, ?)\n",
      "    pred_masks       shape : (?, 32, 28, 28, 4)\n",
      "    target_class_ids shape : (?,)\n",
      "    target_shape       shape : (4,)\n",
      "    target_masks     shape : (?, ?, ?)\n",
      "    pred_shape       shape : (5,)\n",
      "    pred_masks       shape : (?, ?, ?, ?)\n",
      "     y_true shape: (?, ?, ?)\n",
      "     y_pred shape: (?, ?, ?)\n",
      "     final loss shape: (1, 1) <class 'tensorflow.python.framework.ops.Tensor'> False\n",
      "\n",
      ">>> mrcnn_mask_loss_graph \n",
      "    target_class_ids shape : (?, 1)\n",
      "    target_masks     shape : (?, 32, 28, 28)\n",
      "    pred_masks       shape : (?, 32, 28, 28, 4)\n",
      "    target_class_ids shape : (?,)\n",
      "    target_shape       shape : (4,)\n",
      "    target_masks     shape : (?, ?, ?)\n",
      "    pred_shape       shape : (5,)\n",
      "    pred_masks       shape : (?, ?, ?, ?)\n",
      "     y_true shape: (?, ?, ?)\n",
      "     y_pred shape: (?, ?, ?)\n",
      "     final loss shape: (1, 1) <class 'tensorflow.python.framework.ops.Tensor'> False\n",
      "\n",
      "\n",
      "---------------------------------------------------\n",
      "    building fcn_loss\n",
      "---------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---------------------------------------------------\n",
      "    building fcn_norm_loss\n",
      "---------------------------------------------------\n",
      "\n",
      " Keras Tensors?? \n",
      " output_rois       : True\n",
      " pred_gaussian     : True\n",
      " gt_gaussian       : True\n",
      " mask_loss         : True\n",
      " rpn_proposal_rois : True\n",
      ">>> MaskRCNN build complete\n",
      ">>> MaskRCNN initialization complete\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import  gc\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pprint\n",
    "import keras.backend as KB\n",
    "import keras.layers as KL\n",
    "sys.path.append('../')\n",
    "\n",
    "import mrcnn.model     as modellib\n",
    "import mrcnn.visualize as visualize\n",
    "import mrcnn.shapes    as shapes\n",
    "from mrcnn.config      import Config\n",
    "from mrcnn.model       import log\n",
    "from mrcnn.dataset     import Dataset \n",
    "\n",
    "from mrcnn.utils       import stack_tensors, stack_tensors_3d\n",
    "from mrcnn.datagen     import data_generator, load_image_gt\n",
    "from mrcnn.callbacks   import get_layer_output_1,get_layer_output_2\n",
    "from mrcnn.visualize   import plot_gaussian\n",
    "# from mrcnn.pc_layer    import PCTensor\n",
    "# from mrcnn.pc_layer   import PCNLayer\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "MODEL_PATH = 'E:\\Models'\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(MODEL_PATH, \"mrcnn_logs\")\n",
    "# Path to COCO trained weights\n",
    "COCO_MODEL_PATH   = os.path.join(MODEL_PATH, \"mask_rcnn_coco.h5\")\n",
    "RESNET_MODEL_PATH = os.path.join(MODEL_PATH, \"resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n",
    "\n",
    "print(\"Tensorflow Version: {}   Keras Version : {} \".format(tf.__version__,keras.__version__))\n",
    "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
    "np.set_printoptions(linewidth=100,precision=4)\n",
    "\n",
    "\n",
    "# Build configuration object -----------------------------------------------\n",
    "config = shapes.ShapesConfig()\n",
    "config.BATCH_SIZE      = 1                  # Batch size is 2 (# GPUs * images/GPU).\n",
    "config.IMAGES_PER_GPU  = 1                  # Must match BATCH_SIZE\n",
    "config.STEPS_PER_EPOCH = 2\n",
    "config.FCN_INPUT_SHAPE = config.IMAGE_SHAPE[0:2]\n",
    "config.display() \n",
    "\n",
    "# Build shape dataset        -----------------------------------------------\n",
    "# Training dataset\n",
    "# generate 500 shapes \n",
    "dataset_train = shapes.ShapesDataset()\n",
    "dataset_train.load_shapes(500, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = shapes.ShapesDataset()\n",
    "dataset_val.load_shapes(50, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_val.prepare()\n",
    "\n",
    "try :\n",
    "    del model, train_generator, val_generator, mm\n",
    "    gc.collect()\n",
    "except: \n",
    "    pass\n",
    "# Load and display random samples\n",
    "# image_ids = np.random.choice(dataset_train.image_ids, 3)\n",
    "# for image_id in [3]:\n",
    "#     image = dataset_train.load_image(image_id)\n",
    "#     mask, class_ids = dataset_train.load_mask(image_id)\n",
    "#     visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "print(' COCO Model Path       : ', COCO_MODEL_PATH)\n",
    "print(' Checkpoint folder Path: ', MODEL_DIR)\n",
    "\n",
    "# sess = tf.InteractiveSession()\n",
    "# KB.set_session(sess)\n",
    "# # Create Model\n",
    "\n",
    "try :\n",
    "    del model\n",
    "    gc.collect()\n",
    "except: \n",
    "    pass\n",
    "# KB.clear_session()\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=MODEL_DIR)\n",
    "#model.keras_model.summary(line_length = 120) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T20:13:50.416878Z",
     "start_time": "2018-05-06T20:13:49.526509Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> load_weights()\n",
      "    load_weights: Loading weights from: E:\\Models\\mrcnn_logs\\shapes20180428T1819\\mask_rcnn_shapes_5784.h5\n",
      "    load_weights: Log directory set to : E:\\Models\\mrcnn_logs\\shapes20180428T1819\\mask_rcnn_shapes_5784.h5\n",
      "    set_log_dir: Checkpoint path set to : E:\\Models\\mrcnn_logs\\shapes20180428T1819\\mask_rcnn_shapes_{epoch:04d}.h5\n",
      "    set_log_dir: self.epoch set to 5785 \n",
      "    Load weights complete :  E:\\Models\\mrcnn_logs\\shapes20180428T1819\\mask_rcnn_shapes_5784.h5\n",
      "Load weights complete\n"
     ]
    }
   ],
   "source": [
    "# Which weights to start with?\n",
    "init_with = \"last\"  # imagenet, coco, or last\n",
    "if init_with == \"imagenet\":\n",
    "#     loc=model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "    loc=model.load_weights(RESNET_MODEL_PATH, by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    loc=model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    loc= model.load_weights(model.find_last()[1], by_name=True)\n",
    "print('Load weights complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false
   },
   "source": [
    "###  Print some model information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T19:28:35.939159Z",
     "start_time": "2018-05-06T19:28:35.715536Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print('\\n Learning phase values is L ' ,KB.learning_phase())\n",
    "# print('\\n Metrics (_get_deduped_metrics_names():) ') \n",
    "# pp.pprint(model.keras_model._get_deduped_metrics_names())\n",
    "print('\\n Outputs: ') \n",
    "for i,x in enumerate(model.keras_model.outputs):\n",
    "    print(' layer: {:2d}    output : {:40s}   Type: {}       Shape: {}'.format( i, x.name, x.dtype, x.shape) )\n",
    "# print('\\n Losses (model.metrics_names): ') \n",
    "# pp.pprint(model.keras_model.metrics_names)\n",
    "\n",
    "# model.keras_model.summary(line_length = 150) \n",
    "\n",
    "print(model.keras_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "\n",
    "### Define Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T20:00:07.314727Z",
     "start_time": "2018-05-06T20:00:07.085104Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_generator = data_generator(dataset_train, model.config, shuffle=True,\n",
    "                                 batch_size=model.config.BATCH_SIZE,\n",
    "                                 augment = False)\n",
    "val_generator = data_generator(dataset_val, model.config, shuffle=True, \n",
    "                                batch_size=model.config.BATCH_SIZE,\n",
    "                                augment=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Get next shapes from generator and display loaded shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T20:00:35.906974Z",
     "start_time": "2018-05-06T20:00:35.437727Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image id:  480\n",
      "Image meta [480 128 128   3   0   0 128 128   1   1   1   1]\n",
      "Classes (1: circle, 2: square, 3: triangle ):  [3 1 2 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2611319acf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_batch_x, train_batch_y = next(train_generator)\n",
    "\n",
    "### Display loaded shapes\n",
    "\n",
    "# train_batch_x, train_batch_y = next(train_generator)\n",
    "imgmeta_idx = model.keras_model.input_names.index('input_image_meta')\n",
    "img_meta    = train_batch_x[imgmeta_idx]\n",
    "\n",
    "for img_idx in range(config.BATCH_SIZE):\n",
    "    image_id = img_meta[img_idx,0]\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    print('Image id: ',image_id)\n",
    "    print('Image meta', img_meta[img_idx])\n",
    "    print('Classes (1: circle, 2: square, 3: triangle ): ',class_ids)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Push Data thru model using get_layer_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T08:49:54.914213Z",
     "start_time": "2018-05-06T08:49:43.794527Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# layers_out = get_layer_output_2(model.keras_model, train_batch_x, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Build input tensors from `train_batch_x` which is the input to the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T20:15:07.331615Z",
     "start_time": "2018-05-06T20:15:06.511747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/* Inputs */\n",
      "Input  0:  (input_image:0                           ) \t  Input shape: (1, 128, 128, 3)\n",
      "Input  1:  (input_image_meta:0                      ) \t  Input shape: (1, 12)\n",
      "Input  2:  (input_rpn_match:0                       ) \t  Input shape: (1, 4092, 1)\n",
      "Input  3:  (input_rpn_bbox:0                        ) \t  Input shape: (1, 256, 4)\n",
      "Input  4:  (input_gt_class_ids:0                    ) \t  Input shape: (1, 100)\n",
      "Input  5:  (input_gt_boxes:0                        ) \t  Input shape: (1, 100, 4)\n",
      "Input  6:  (input_gt_masks:0                        ) \t  Input shape: (1, 56, 56, 100)\n",
      "\n",
      "/* Outputs */\n",
      "Output  3: (rpn_proposal_rois/packed_2:0            ) \t  Output shape: (1, 2000, 4)\n"
     ]
    }
   ],
   "source": [
    "input_image, input_image_meta, input_rpn_match ,  input_rpn_bbox  ,  input_gt_class_ids, input_gt_boxes,  \\\n",
    "input_gt_masks     =  train_batch_x\n",
    "\n",
    "h, w = input_image.shape[0], input_image.shape[1]      #  tf.shape(input_image)[1], tf.shape(input_image)[2]\n",
    "input_normlzd_gt_boxes = tf.identity(input_gt_boxes / image_scale)\n",
    "\n",
    "rpn_proposal_rois = get_layer_output_1(model.keras_model, train_batch_x, [3], verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T20:15:14.006398Z",
     "start_time": "2018-05-06T20:15:13.767740Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 4) (1, 128, 128, 3)\n",
      "(1, 2000, 4)\n",
      "[[  8.5559   6.8063  53.2904  51.8479]\n",
      " [ 33.032   42.799   88.2882  99.7937]\n",
      " [ 12.5507  41.7644  68.7552  98.664 ]\n",
      " [ 33.9294  57.2783  86.9869 113.6012]\n",
      " [  9.0826  61.0126  67.2181 118.2515]]\n"
     ]
    }
   ],
   "source": [
    "print(input_gt_boxes.shape, input_image.shape)\n",
    "print(rpn_proposal_rois.shape)\n",
    "print((rpn_proposal_rois[0,:5,:]*[128,128,128,128]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T18:03:57.602322Z",
     "start_time": "2018-05-06T18:03:57.365693Z"
    }
   },
   "outputs": [],
   "source": [
    "# sess.close()\n",
    "# sess = tf.InteractiveSession()\n",
    "# KB.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Setup tensors to be passed to `detections_target_graph()`\n",
    "\n",
    "This is passed to the DetectionTargetLayer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T20:00:58.310343Z",
     "start_time": "2018-05-06T20:00:58.091744Z"
    }
   },
   "outputs": [],
   "source": [
    "import mrcnn.utils  as utils\n",
    "from mrcnn.detect_tgt_layer import overlaps_graph\n",
    "# proposals    = KB.identity(rpn_proposal_rois)[0]\n",
    "# gt_class_ids = KB.identity(input_gt_class_ids)[0]\n",
    "# gt_boxes     = KB.identity(input_normlzd_gt_boxes)[0]\n",
    "# gt_masks     = KB.identity(input_gt_masks)[0]\n",
    "\n",
    "# proposals    = rpn_proposal_rois[1]\n",
    "# gt_class_ids = input_gt_class_ids[1]\n",
    "# gt_boxes     = input_normlzd_gt_boxes[1]\n",
    "# gt_masks     = input_gt_masks[1]\n",
    "# config       = model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def `dev_detection_targets_graph`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T20:19:41.273566Z",
     "start_time": "2018-05-06T20:19:40.064308Z"
    },
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "def dev_detection_targets_graph(proposals, gt_class_ids, gt_boxes, gt_masks, config):\n",
    "\n",
    "\n",
    "    print('>>> detection_targets_graph ')\n",
    "    print('     propsals.shape        :',  proposals.shape, proposals.get_shape(), KB.int_shape(proposals) )\n",
    "    print('     gt_boxes.shape        :',  gt_boxes.shape ,    KB.int_shape(gt_boxes)   )\n",
    "    print('     gt_class_ids.shape    :',  gt_class_ids.shape, KB.int_shape(gt_class_ids))\n",
    "    print('     gt_masks.shape        :',  gt_masks.shape ,    KB.int_shape(gt_masks)   )\n",
    "\n",
    "    proposals, _        = utils.trim_zeros_graph(proposals, name=\"trim_proposals\")\n",
    "    gt_boxes, non_zeros = utils.trim_zeros_graph(gt_boxes , name=\"trim_gt_boxes\")\n",
    "    gt_class_ids        = tf.boolean_mask(gt_class_ids, non_zeros, name=\"trim_gt_class_ids\")\n",
    "    gt_masks            = tf.gather(gt_masks, tf.where(non_zeros)[:, 0], axis=2,name=\"trim_gt_masks\")\n",
    "\n",
    "    # print(tf.shape(proposals).eval())\n",
    "    # print(non_zeros.eval())\n",
    "    # print('gt_boxes :', tf.shape(gt_boxes).eval())\n",
    "\n",
    "    ###  Separate GT boxes and masks by 'crowd' and 'non-crowd' classifications\n",
    "\n",
    "    crowd_ix        = tf.where(gt_class_ids < 0)[:, 0]\n",
    "    non_crowd_ix    = tf.where(gt_class_ids > 0)[:, 0]\n",
    "    crowd_boxes     = tf.gather(gt_boxes, crowd_ix)\n",
    "    crowd_masks     = tf.gather(gt_masks, crowd_ix, axis=2)\n",
    "    gt_class_ids    = tf.gather(gt_class_ids, non_crowd_ix)\n",
    "    gt_boxes        = tf.gather(gt_boxes, non_crowd_ix)\n",
    "    gt_masks        = tf.gather(gt_masks, non_crowd_ix, axis=2)\n",
    "    # Compute overlaps with crowd boxes [anchors, crowds]\n",
    "    crowd_overlaps  = overlaps_graph(proposals, crowd_boxes)\n",
    "    crowd_iou_max   = tf.reduce_max(crowd_overlaps, axis=1)\n",
    "    no_crowd_bool   = (crowd_iou_max < 0.001)\n",
    "\n",
    "    # print('crowd ixs: ', crowd_ix.eval())\n",
    "    # print('non_crowrd_ixs', non_crowd_ix.eval())\n",
    "    # print('non crowd bool', no_crowd_bool.eval())\n",
    "\n",
    "    overlaps        = overlaps_graph(proposals, gt_boxes)\n",
    "    print('     overlaps.shape :',  tf.shape(overlaps).eval())\n",
    "    \n",
    "    roi_iou_max            = tf.reduce_max(overlaps, axis=1)\n",
    "    print(' RoI/Gt max IoU')\n",
    "    # print(roi_iou_max.eval())\n",
    "    positive_roi_bool     = (roi_iou_max >= 0.5)\n",
    "    all_positive_indices      = tf.where(positive_roi_bool) [:, 0]\n",
    "    print('Positive indices :',tf.shape(all_positive_indices).eval(),'\\nPositive Indices \\n',all_positive_indices.eval())\n",
    "    print('Positive IoUs \\n', tf.gather(roi_iou_max,all_positive_indices).eval())\n",
    "\n",
    "    ## current method\n",
    "    all_negative_indices     = tf.where(tf.logical_and(roi_iou_max < 0.5, no_crowd_bool))[:, 0]\n",
    "#     print('Negative indices :',tf.shape(all_negative_indices).eval(),'\\nNegative Indices \\n',all_negative_indices.eval())\n",
    "#     print('Negative IoUs \\n', tf.gather(roi_iou_max,all_negative_indices).eval())\n",
    "\n",
    "    ## method - suppress the proposals with 0 IoUs\n",
    "    # negative_nonzero_bool = tf.logical_and(~positive_roi_bool, (roi_iou_max > 0))\n",
    "    # negative_nonzero_bool = tf.logical_and(negative_nonzero_bool, no_crowd_bool)\n",
    "    # negative_nonzero_indices      = tf.where(negative_nonzero_bool) [:, 0]\n",
    "    # print('Negative indices')\n",
    "    # print(tf.shape(negative_nonzero_indices).eval(),'\\n',negative_nonzero_indices.eval())\n",
    "    # print(tf.gather(roi_iou_max,negative_nonzero_indices).eval())\n",
    "\n",
    "    ##------------------------------------------------------------------------------------------------------\n",
    "    ## 3. Subsample positive ROIs based on ROI_POSITIVE_RATIO\n",
    "    ##    Aim for 33% positive (config.ROI_POSITIVE_RATIO = 0.33)\n",
    "    ##    Positive ROIs   33% of config.TRAIN_ROIS_PER_IMAGE --> 10\n",
    "    ##------------------------------------------------------------------------------------------------------\n",
    "    # print('Positive indices :',tf.shape(all_positive_indices).eval(),'\\nPositive Indices \\n',all_positive_indices.eval())\n",
    "    # print('Negative indices :',tf.shape(all_negative_indices).eval(),'\\nNegative Indices \\n',all_negative_indices.eval())\n",
    "    # print(config.TRAIN_ROIS_PER_IMAGE * config.ROI_POSITIVE_RATIO )\n",
    "    # print(' Postive count using Ceiling : ', tf.ceil(config.TRAIN_ROIS_PER_IMAGE * config.ROI_POSITIVE_RATIO ).eval())\n",
    "\n",
    "    positive_ind_shuffled  = tf.random_shuffle(all_positive_indices, seed=1 )\n",
    "    negative_ind_shuffled  = tf.random_shuffle(all_negative_indices, seed=1 )\n",
    "    print('Shuffled Pos indices :',tf.shape(positive_ind_shuffled).eval(),'\\n',positive_ind_shuffled.eval())\n",
    "#     print('Shuffled Neg indices :',tf.shape(negative_ind_shuffled).eval(),'\\n',negative_ind_shuffled.eval())\n",
    "\n",
    "    ##------------------------------------------------------------------------------------------------------\n",
    "    ##  Select positive samples from amongst positive bounding boxes\n",
    "    ##------------------------------------------------------------------------------------------------------\n",
    "    ## current method\n",
    "    positive_count = int(config.TRAIN_ROIS_PER_IMAGE * config.ROI_POSITIVE_RATIO)\n",
    "    ## alternative option -round upwards using ceiling\n",
    "#     positive_count        = tf.cast(tf.ceil(config.TRAIN_ROIS_PER_IMAGE * config.ROI_POSITIVE_RATIO ), tf.int32)\n",
    "#     positive_indices      = tf.random_shuffle(positive_indices,seed = 1)[:true_positive_count]\n",
    "\n",
    "    ## New:\n",
    "    positive_indices      = positive_ind_shuffled[:positive_count]\n",
    "    positive_count        = tf.shape(positive_indices)[0]\n",
    "\n",
    "#     print('Selected Positive Indices: ',positive_count.eval())\n",
    "#     print(positive_indices.eval())\n",
    "#     print('Positive indices: \\n',positive_indices.eval())\n",
    "\n",
    "    ##------------------------------------------------------------------------------------------------------\n",
    "    ##   4. Add Negative ROIs. Add enough to maintain positive:negative ratio\n",
    "    ##\n",
    "    ## The current method to compute the negative_count in Mask_RCNN seems to result in a shortage of the \n",
    "    ## negative count, due to the fact that positive_count is cast to an int. \n",
    "    ## for eg. int(32 * 0.333) = int(10.56) = 10. \n",
    "    ## \n",
    "    ## This results in a negative_count of 1/0.33 * 10 = 30. (2 short of 32)\n",
    "    ## To resolve this we subtract the postivie count from  TRAIN_ROIS_PER_IMAGE to obtain the all_negs_count\n",
    "    ## some of these will be used to introduce false positives/\n",
    "    ##------------------------------------------------------------------------------------------------------\n",
    "    # r = 1.0 / config.ROI_POSITIVE_RATIO\n",
    "    # print(' r * positive_count : ', tf.cast(r * tf.cast(positive_count, tf.float32), tf.int32).eval())\n",
    "    # negative_count       = tf.cast(r * tf.cast(positive_count, tf.float32), tf.int32) - positive_count\n",
    "    # negative_indices     = tf.random_shuffle(negative_indices)[:negative_count]\n",
    "    # print('Negative Count : ', negative_count.eval())\n",
    "\n",
    "    # all_negative_count   = tf.cast(r * tf.cast(positive_count, tf.float32), tf.int32) - positive_count\n",
    "    # all_negative_indices = tf.random_shuffle(all_negative_indices)[:negative_count]\n",
    "    # print('All Negative Count : ', all_negative_count.eval())\n",
    "#     print('Positive indices: \\n',positive_indices.eval())\n",
    "    \n",
    "    ##------------------------------------------------------------------------------------------------------\n",
    "    ## Here is the alterantive method\n",
    "    ## Determine Negative count as different between total RoIs per image and number of positives we found\n",
    "    ## Then, select a ratio of the positives to introduce as False Positives (FALSE_POSITIVES_COUNT_GOAL)\n",
    "    ##   reserved the first shuffled negatives for FALSE POSITIVES and assign the rest as TRUE NEGATIVES  \n",
    "    \n",
    "    ##------------------------------------------------------------------------------------------------------\n",
    "    all_negative_count   =  config.TRAIN_ROIS_PER_IMAGE - positive_count\n",
    "    false_positive_count_goal  = tf.cast(0.33 * tf.cast(positive_count, tf.float32), tf.int32)\n",
    "\n",
    "    false_positive_indices= negative_ind_shuffled[:false_positive_count_goal]\n",
    "    false_positive_count  = tf.shape(false_positive_indices)[0]\n",
    "    \n",
    "    # print('Positive Count       : ', positive_count.eval())\n",
    "    # print('All Negative Count   : ', all_negative_count.eval())\n",
    "    # print('False Positive Count Goal: ', false_positive_count_goal.eval())\n",
    "\n",
    "\n",
    "    # print('False Positive Count/Indices: ',tf.shape(false_positive_indices).eval())\n",
    "    # print(false_positive_indices.eval())\n",
    "    \n",
    "    negative_indices   = negative_ind_shuffled[false_positive_count:all_negative_count]\n",
    "    negative_count     = tf.shape(negative_indices)[0]\n",
    "    # print(' All negs: {}   FP Count: {}    TT count {}  True Neg count: {}'.\n",
    "    #       format(all_negative_count.eval(), false_positive_count.eval(), tt_negative_count.eval(), negative_count.eval()))\n",
    "    # print('Selected Negative Indices: ',tf.shape(negative_indices).eval())\n",
    "\n",
    "\n",
    "    ##------------------------------------------------------------------------------------------------------\n",
    "    ## 5.   Gather selected positive and negative ROIs\n",
    "    ##------------------------------------------------------------------------------------------------------\n",
    "    positive_rois      = tf.gather(proposals, positive_indices)\n",
    "    false_positive_rois= tf.gather(proposals, false_positive_indices)\n",
    "    negative_rois      = tf.gather(proposals, negative_indices)\n",
    "\n",
    "    # print(positive_rois.eval())\n",
    "    # print(false_positive_rois.eval())\n",
    "    # print(negative_rois.eval())\n",
    "\n",
    "    #------------------------------------------------------------------------------------------------------\n",
    "    # 6.   Assign GT bbounding boxes and classes to the positive RoIs\n",
    "    #\n",
    "    #  For each positive RoI, gather IoUs between the RoI and all gt bboxes, find the index correwsponding \n",
    "    #  to the gt_box with the maximum overlap, and assign the corresponding gt_class and gt_bbox to the RoI\n",
    "    # \n",
    "    #  Remember: The same class can have multiple gt_bounding boxes. So RoIs assiged to same class could have \n",
    "    #            DIFFERENT gt_bboxes (classes can have multple bounding boxes -- like when the same shape \n",
    "    #           appears twice in an image)\n",
    "    #------------------------------------------------------------------------------------------------------\n",
    "    positive_overlaps     = tf.gather(overlaps, positive_indices)\n",
    "    roi_gt_box_assignment = tf.argmax(positive_overlaps, axis=1)\n",
    "    roi_gt_boxes          = tf.gather(gt_boxes    , roi_gt_box_assignment)\n",
    "    roi_gt_class_ids      = tf.gather(gt_class_ids, roi_gt_box_assignment)\n",
    "    \n",
    "#     print('Positive indices: \\n',positive_indices.eval())\n",
    "#     print(' positive overlaps        :\\n', positive_overlaps.eval())\n",
    "#     print(' positive overlaps shape  :  ', sess.run(positive_overlaps, roi_gt_box_assignment))\n",
    "#     print(tf.reduce_max(positive_overlaps, axis = 1).eval())\n",
    "#     print(' Pos roi gt class assign  :\\n', roi_gt_class_ids.eval())\n",
    "#     print(' Pos roi gt boxes         :\\n', roi_gt_boxes.eval())\n",
    "#     print(' Pos roi gt box assignment:\\n', roi_gt_box_assignment.eval())\n",
    "#     print(' positive overlaps        :\\n', positive_overlaps.eval())\n",
    "#     print(' Positive indices: \\n',positive_indices.eval())\n",
    "\n",
    "    #------------------------------------------------------------------------------------------------------\n",
    "    ## 7.   Compute bbox delta \n",
    "    #  Calculate refinement (difference b/w positive rois and its corresponding gt_boxes)\n",
    "    #------------------------------------------------------------------------------------------------------\n",
    "    deltas  = utils.box_refinement_graph(positive_rois, roi_gt_boxes)\n",
    "    deltas /= config.BBOX_STD_DEV\n",
    "    # print('deltas')\n",
    "    # print(deltas.eval())\n",
    "    # print(' Positive RoIs ')\n",
    "    # print(positive_rois.eval())\n",
    "\n",
    "    #------------------------------------------------------------------------------------------------------\n",
    "    # 6.   Assign GT bbounding boxes and classes to the false positive RoIs\n",
    "    #\n",
    "    #  For each positive RoI, gather IoUs between the RoI and all gt bboxes, find the index correwsponding \n",
    "    #  to the gt_box with the maximum overlap, and assign the corresponding gt_class and gt_bbox to the RoI\n",
    "    #\n",
    "    #------------------------------------------------------------------------------------------------------\n",
    "    fp_overlaps          = tf.gather(overlaps, false_positive_indices)\n",
    "    fp_gt_box_assignment = tf.argmax(fp_overlaps, axis=1)\n",
    "    fp_gt_boxes          = tf.gather(gt_boxes    , fp_gt_box_assignment)\n",
    "    fp_gt_class_ids      = tf.gather(gt_class_ids, fp_gt_box_assignment)\n",
    "#     print(' shape of false positive overlaps is :', fp_overlaps.get_shape())\n",
    "    # print(' FP overlaps            \\n', fp_overlaps.eval())\n",
    "    # print(' FP roi gt box assignemt:\\n', fp_gt_box_assignment.eval())\n",
    "    # print(' FP roi gt boxes        :\\n', fp_gt_boxes.eval())\n",
    "    # print(' FP roi gt class assign :\\n', fp_gt_class_ids.eval())\n",
    "    return positive_ind_shuffled, positive_indices, positive_overlaps, roi_gt_box_assignment,roi_gt_boxes, roi_gt_class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T20:18:11.889690Z",
     "start_time": "2018-05-06T20:18:11.607925Z"
    }
   },
   "outputs": [],
   "source": [
    "def overlaps_graph(boxes1, boxes2):\n",
    "    '''\n",
    "    Computes IoU overlaps between two sets of boxes.in normalized coordinates\n",
    "    \n",
    "    boxes1 - proposals :  [batch_size,  proposal_counts, 4 (y1, x1, y2, x2)] <-- Region proposals\n",
    "    boxes2 - gt_boxes  :  [batch_size, max_gt_instances, 4 (y1, x1, y2, x2)] <-- input_normlzd_gt_boxes\n",
    "    \n",
    "    proposal_counts : 1000 or 2000 based on training or inference\n",
    "    max_gt_instances: 100\n",
    "    \n",
    "    returns :\n",
    "    ---------\n",
    "    overlaps :          [ proposal_counts, max_gt_instances] \n",
    "                        IoU of all proposal box / gt_box pairs\n",
    "    '''\n",
    "    # 1. Tile boxes2 and repeat boxes1. This allows us to compare every boxes1 against every boxes2 without loops.\n",
    "    #    TF doesn't have an equivalent to np.repeat() so simulate it using tf.tile() and tf.reshape.\n",
    "    \n",
    "#     print('\\t>>> detection_targets_graph - calculate Overlaps_graph')    \n",
    "#     print('\\t     overlaps_graph: shape of boxes1 before reshape: ',tf.shape(boxes1).eval())  # (?,?)\n",
    "#     print('\\t     overlaps_graph: shape of boxes2 before reshape: ',tf.shape(boxes2).eval())  # (?,?)\n",
    "    \n",
    "    # tf.expand_dims(boxes1, 1) : makes b1:[1, proposal_count_sz, 4] \n",
    "    b1 = tf.reshape(tf.tile(tf.expand_dims(boxes1, 1), [1, 1, tf.shape(boxes2)[0]]), [-1, 4])\n",
    "    b2 = tf.tile(boxes2, [tf.shape(boxes1)[0], 1])\n",
    "    \n",
    "#     print('\\t     overlaps_graph: shape of boxes1 after reshape: ',tf.shape(b1).eval())  # (?,4)\n",
    "#     print('\\t     overlaps_graph: shape of boxes2 after reshape: ',tf.shape(b2).eval())  # (?,4)\n",
    "\n",
    "    # 2. Compute intersections\n",
    "    b1_y1, b1_x1, b1_y2, b1_x2 = tf.split(b1, 4, axis=1)\n",
    "    b2_y1, b2_x1, b2_y2, b2_x2 = tf.split(b2, 4, axis=1)\n",
    "    \n",
    "#     print('     overlaps_graph: shape of b1_y1 after split: ',tf.shape(b2_y1).eval())  # (?,4)\n",
    "    y1 = tf.maximum(b1_y1, b2_y1)\n",
    "    x1 = tf.maximum(b1_x1, b2_x1)\n",
    "    y2 = tf.minimum(b1_y2, b2_y2)\n",
    "    x2 = tf.minimum(b1_x2, b2_x2)\n",
    "    intersection = tf.maximum(x2 - x1, 0) * tf.maximum(y2 - y1, 0)\n",
    "\n",
    "    # 3. Compute unions\n",
    "    b1_area = (b1_y2 - b1_y1) * (b1_x2 - b1_x1)\n",
    "    b2_area = (b2_y2 - b2_y1) * (b2_x2 - b2_x1)\n",
    "    union = b1_area + b2_area - intersection\n",
    "    \n",
    "    # 4. Compute IoU and reshape to [boxes1, boxes2]\n",
    "    iou = intersection / union\n",
    "    overlaps = tf.reshape(iou, [tf.shape(boxes1)[0], tf.shape(boxes2)[0]])\n",
    "#     print('\\t     Overlaps_graph(): Shape of output overlaps', tf.shape(overlaps).eval(), overlaps.get_shape())\n",
    "    return overlaps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T18:49:46.246720Z",
     "start_time": "2018-05-06T18:49:46.019140Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# positive_ind_shuffled, positive_indices, positive_overlaps, roi_gt_box_assignment,roi_gt_boxes, roi_gt_class_ids \\\n",
    "#         = dev_detection_targets_graph(proposals, gt_class_ids, gt_boxes, gt_masks, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T17:58:00.775508Z",
     "start_time": "2018-05-06T17:58:00.140788Z"
    }
   },
   "outputs": [],
   "source": [
    "# tf.set_random_seed(1)\n",
    "# print(' Shuffled Positive indices: \\n',positive_ind_shuffled.eval())\n",
    "# print(' Positive indices:         \\n', positive_indices.eval())\n",
    "# print(' positive overlaps        :\\n', positive_overlaps.eval())\n",
    "# print(' positive overlaps shape  :  ', tf.shape(positive_overlaps).eval())\n",
    "# print(  positive_overlaps.eval())\n",
    "# print(' Pos roi gt class assign  :\\n', roi_gt_class_ids)\n",
    "# print(' Pos roi gt boxes         :\\n', roi_gt_boxes.eval)\n",
    "# print(' Pos roi gt box assignment:\\n', roi_gt_box_assignment)\n",
    "# print(' positive overlaps        :\\n', positive_overlaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  detetct_target_layer -- non function format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T20:15:28.250775Z",
     "start_time": "2018-05-06T20:15:27.701816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 4)\n",
      "(100, 4)\n",
      "(1, 2000, 4)\n",
      "(2000, 4)\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "proposals              = tf.identity(rpn_proposal_rois)[0]\n",
    "gt_class_ids           = tf.identity(input_gt_class_ids)[0]\n",
    "gt_boxes               = tf.identity(input_normlzd_gt_boxes)[0]\n",
    "gt_masks               = tf.identity(input_gt_masks)[0]\n",
    "print(input_normlzd_gt_boxes.shape)\n",
    "print(gt_boxes.shape)\n",
    "print(rpn_proposal_rois.shape)\n",
    "print(proposals.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T21:01:13.004981Z",
     "start_time": "2018-05-06T21:01:07.059401Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> detection_targets_graph \n",
      "     propsals.shape        : [183   4]\n",
      "     gt_boxes.shape        : [4 4]\n",
      "     gt_class_ids.shape    : [4]\n",
      "     gt_masks.shape        : [56 56  4]\n",
      "     propsals.shape        : [183   4]\n",
      "     gt_boxes.shape        : [4 4]\n",
      "   ####  gt_boxes :\n",
      " [[0.5547 0.5078 0.7188 0.8984]\n",
      " [0.0312 0.6172 0.375  0.9531]\n",
      " [0.1406 0.4062 0.5547 0.8203]\n",
      " [0.0625 0.0312 0.4453 0.4141]]\n",
      "Positive indices : [27] \n",
      "Positive Indices \n",
      " [  0   2   4   6   8  11  12  13  15  16  17  18  19  20  26  32  35  51  60  65  74  85 119 129\n",
      " 131 134 135]\n",
      "Negative indices : [156] \n",
      "Negative Indices \n",
      " [  1   3   5   7   9  10  14  21  22  23  24  25  27  28  29  30  31  33  34  36  37  38  39  40\n",
      "  41  42  43  44  45  46  47  48  49  50  52  53  54  55  56  57  58  59  61  62  63  64  66  67\n",
      "  68  69  70  71  72  73  75  76  77  78  79  80  81  82  83  84  86  87  88  89  90  91  92  93\n",
      "  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 120 121 122 123 124 125 126 127 128 130 132 133 136 137 138 139 140 141 142 143 144 145 146\n",
      " 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170\n",
      " 171 172 173 174 175 176 177 178 179 180 181 182]\n"
     ]
    }
   ],
   "source": [
    "print('>>> detection_targets_graph ')\n",
    "print('     propsals.shape        :',  tf.shape(proposals).eval())\n",
    "print('     gt_boxes.shape        :',  tf.shape(gt_boxes).eval() )\n",
    "print('     gt_class_ids.shape    :',  tf.shape(gt_class_ids).eval())\n",
    "print('     gt_masks.shape        :',  tf.shape(gt_masks).eval() )\n",
    "\n",
    "proposals, _        = utils.trim_zeros_graph(proposals, name=\"trim_proposals\")\n",
    "gt_boxes, non_zeros = utils.trim_zeros_graph(gt_boxes , name=\"trim_gt_boxes\")\n",
    "gt_class_ids        = tf.boolean_mask(gt_class_ids, non_zeros, name=\"trim_gt_class_ids\")\n",
    "gt_masks            = tf.gather(gt_masks, tf.where(non_zeros)[:, 0], axis=2,name=\"trim_gt_masks\")\n",
    "\n",
    "print('     propsals.shape        :',  tf.shape(proposals).eval())\n",
    "print('     gt_boxes.shape        :',  tf.shape(gt_boxes).eval() )\n",
    "print('   ####  gt_boxes :\\n', gt_boxes.eval())\n",
    "\n",
    "# print(non_zeros.eval())\n",
    "\n",
    "###  Separate GT boxes and masks by 'crowd' and 'non-crowd' classifications\n",
    "\n",
    "crowd_ix        = tf.where(gt_class_ids < 0)[:, 0]\n",
    "non_crowd_ix    = tf.where(gt_class_ids > 0)[:, 0]\n",
    "crowd_boxes     = tf.gather(gt_boxes, crowd_ix)\n",
    "crowd_masks     = tf.gather(gt_masks, crowd_ix, axis=2)\n",
    "gt_class_ids    = tf.gather(gt_class_ids, non_crowd_ix)\n",
    "gt_boxes        = tf.gather(gt_boxes, non_crowd_ix)\n",
    "gt_masks        = tf.gather(gt_masks, non_crowd_ix, axis=2)\n",
    "\n",
    "# get unique list of classes present in current image\n",
    "gt_classes_present, _ = tf.unique(gt_class_ids)\n",
    "\n",
    "# Compute overlaps with crowd boxes [anchors, crowds]\n",
    "crowd_overlaps  = overlaps_graph(proposals, crowd_boxes)\n",
    "crowd_iou_max   = tf.reduce_max(crowd_overlaps, axis=1)\n",
    "no_crowd_bool   = (crowd_iou_max < 0.001)\n",
    "\n",
    "# print('crowd ixs: ', crowd_ix.eval())\n",
    "# print('non_crowd_ixs', non_crowd_ix.eval())\n",
    "# print('non crowd bool', no_crowd_bool.eval())\n",
    " \n",
    "overlaps        = overlaps_graph(proposals, gt_boxes)\n",
    "roi_iou_max     = tf.reduce_max(overlaps, axis=1)\n",
    "\n",
    "# print('     overlaps.shape :',  tf.shape(overlaps).eval())\n",
    "# print(overlaps.eval())\n",
    "# print(' RoI/Gt max IoU')\n",
    "# print(roi_iou_max.eval())\n",
    "\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "## 2. Identify RoIs that have an IoU >= 0.5 - these are positive RoIs\n",
    "##    RoIs that have a max IoU < 0.5 and are not a crowd RoI are considered negative RoIs\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "positive_roi_bool         = (roi_iou_max >= 0.5)\n",
    "all_positive_indices      = tf.where(positive_roi_bool) [:, 0]\n",
    "print('Positive indices :',tf.shape(all_positive_indices).eval(),'\\nPositive Indices \\n',all_positive_indices.eval())\n",
    "# print('Positive IoUs    :\\n', tf.gather(roi_iou_max,all_positive_indices).eval())\n",
    "\n",
    "## current method\n",
    "all_negative_indices     = tf.where(tf.logical_and(roi_iou_max < 0.5, no_crowd_bool))[:, 0]\n",
    "print('Negative indices :',tf.shape(all_negative_indices).eval(),'\\nNegative Indices \\n',all_negative_indices.eval())\n",
    "# print('Negative IoUs \\n', tf.gather(roi_iou_max,all_negative_indices).eval())\n",
    "\n",
    "## method - suppress the proposals with 0 IoUs\n",
    "# negative_nonzero_bool = tf.logical_and(~positive_roi_bool, (roi_iou_max > 0))\n",
    "# negative_nonzero_bool = tf.logical_and(negative_nonzero_bool, no_crowd_bool)\n",
    "# negative_nonzero_indices      = tf.where(negative_nonzero_bool) [:, 0]\n",
    "# print('Negative indices')\n",
    "# print(tf.shape(negative_nonzero_indices).eval(),'\\n',negative_nonzero_indices.eval())\n",
    "# print(tf.gather(roi_iou_max,negative_nonzero_indices).eval())\n",
    "\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "## 3. Subsample positive ROIs based on ROI_POSITIVE_RATIO\n",
    "##    Aim for 33% positive (config.ROI_POSITIVE_RATIO = 0.33)\n",
    "##    Positive ROIs   33% of config.TRAIN_ROIS_PER_IMAGE --> 10\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "# print('Positive indices :',tf.shape(all_positive_indices).eval(),'\\nPositive Indices \\n',all_positive_indices.eval())\n",
    "# print('Negative indices :',tf.shape(all_negative_indices).eval(),'\\nNegative Indices \\n',all_negative_indices.eval())\n",
    "# print(config.TRAIN_ROIS_PER_IMAGE * config.ROI_POSITIVE_RATIO )\n",
    "# print(' Postive count using Ceiling : ', tf.ceil(config.TRAIN_ROIS_PER_IMAGE * config.ROI_POSITIVE_RATIO ).eval())\n",
    "\n",
    "positive_ind_shuffled  = tf.random_shuffle(all_positive_indices, seed=1 )\n",
    "negative_ind_shuffled  = tf.random_shuffle(all_negative_indices, seed=1 )\n",
    "# print('Shuffled Pos indices :',tf.shape(positive_ind_shuffled).eval(),'\\n',positive_ind_shuffled.eval())\n",
    "# print('Shuffled Neg indices :',tf.shape(negative_ind_shuffled).eval(),'\\n',negative_ind_shuffled.eval())\n",
    "\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "##  Select positive samples from amongst positive bounding boxes\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "## current method\n",
    "positive_count = int(config.TRAIN_ROIS_PER_IMAGE * config.ROI_POSITIVE_RATIO)\n",
    "## alternative option -round upwards using ceiling\n",
    "#     positive_count        = tf.cast(tf.ceil(config.TRAIN_ROIS_PER_IMAGE * config.ROI_POSITIVE_RATIO ), tf.int32)\n",
    "#     positive_indices      = tf.random_shuffle(positive_indices,seed = 1)[:true_positive_count]\n",
    "\n",
    "## New:\n",
    "positive_indices      = positive_ind_shuffled[:positive_count]\n",
    "positive_count        = tf.shape(positive_indices)[0]\n",
    "\n",
    "#     print('Selected Positive Indices: ',positive_count.eval())\n",
    "#     print(positive_indices.eval())\n",
    "#     print('Positive indices: \\n',positive_indices.eval())\n",
    "\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "##   4. Add Negative ROIs. Add enough to maintain positive:negative ratio\n",
    "##\n",
    "## The current method to compute the negative_count in Mask_RCNN seems to result in a shortage of the \n",
    "## negative count, due to the fact that positive_count is cast to an int. \n",
    "## for eg. int(32 * 0.333) = int(10.56) = 10. \n",
    "## \n",
    "## This results in a negative_count of 1/0.33 * 10 = 30. (2 short of 32)\n",
    "## To resolve this we subtract the postivie count from  TRAIN_ROIS_PER_IMAGE to obtain the all_negs_count\n",
    "## some of these will be used to introduce false positives/\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "# r = 1.0 / config.ROI_POSITIVE_RATIO\n",
    "# print(' r * positive_count : ', tf.cast(r * tf.cast(positive_count, tf.float32), tf.int32).eval())\n",
    "# negative_count       = tf.cast(r * tf.cast(positive_count, tf.float32), tf.int32) - positive_count\n",
    "# negative_indices     = tf.random_shuffle(negative_indices)[:negative_count]\n",
    "# print('Negative Count : ', negative_count.eval())\n",
    "\n",
    "# all_negative_count   = tf.cast(r * tf.cast(positive_count, tf.float32), tf.int32) - positive_count\n",
    "# all_negative_indices = tf.random_shuffle(all_negative_indices)[:negative_count]\n",
    "# print('All Negative Count : ', all_negative_count.eval())\n",
    "#     print('Positive indices: \\n',positive_indices.eval())\n",
    "\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "## Here is the alterantive method\n",
    "## Determine Negative count as different between total RoIs per image and number of positives we found\n",
    "## Then, select a ratio of the positives to introduce as False Positives (FALSE_POSITIVES_COUNT_GOAL)\n",
    "##   reserved the first shuffled negatives for FALSE POSITIVES and assign the rest as TRUE NEGATIVES  \n",
    "\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "all_negative_count   =  config.TRAIN_ROIS_PER_IMAGE - positive_count\n",
    "false_positive_count_goal  = tf.cast(0.33 * tf.cast(positive_count, tf.float32), tf.int32)\n",
    "\n",
    "false_positive_indices= negative_ind_shuffled[:false_positive_count_goal]\n",
    "false_positive_count  = tf.shape(false_positive_indices)[0]\n",
    "\n",
    "# print('Positive Count       : ', positive_count.eval())\n",
    "# print('All Negative Count   : ', all_negative_count.eval())\n",
    "# print('False Positive Count Goal: ', false_positive_count_goal.eval())\n",
    "\n",
    "\n",
    "# print('False Positive Count/Indices: ',tf.shape(false_positive_indices).eval())\n",
    "# print(false_positive_indices.eval())\n",
    "\n",
    "negative_indices   = negative_ind_shuffled[false_positive_count:all_negative_count]\n",
    "negative_count     = tf.shape(negative_indices)[0]\n",
    "# print(' All negs: {}   FP Count: {}    TT count {}  True Neg count: {}'.\n",
    "#       format(all_negative_count.eval(), false_positive_count.eval(), tt_negative_count.eval(), negative_count.eval()))\n",
    "# print('Selected Negative Indices: ',tf.shape(negative_indices).eval())\n",
    "\n",
    "\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "## 5.   Gather selected positive and negative ROIs\n",
    "##------------------------------------------------------------------------------------------------------\n",
    "positive_rois      = tf.gather(proposals, positive_indices)\n",
    "false_positive_rois= tf.gather(proposals, false_positive_indices)\n",
    "negative_rois      = tf.gather(proposals, negative_indices)\n",
    "\n",
    "# print(positive_rois.eval())\n",
    "# print(false_positive_rois.eval())\n",
    "# print(negative_rois.eval())\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "# 6.   Assign GT bbounding boxes and classes to the positive RoIs\n",
    "#\n",
    "#  For each positive RoI, gather IoUs between the RoI and all gt bboxes, find the index correwsponding \n",
    "#  to the gt_box with the maximum overlap, and assign the corresponding gt_class and gt_bbox to the RoI\n",
    "#\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "positive_overlaps     = tf.gather(overlaps, positive_indices)\n",
    "roi_gt_box_assignment = tf.argmax(positive_overlaps, axis=1)\n",
    "roi_gt_boxes          = tf.gather(gt_boxes    , roi_gt_box_assignment)\n",
    "roi_gt_class_ids      = tf.gather(gt_class_ids, roi_gt_box_assignment)\n",
    "\n",
    "# print('Positive indices: \\n',positive_indices.eval())\n",
    "# print(' positive overlaps        :\\n', positive_overlaps.eval())\n",
    "# print(' Pos roi gt box assignment:\\n', roi_gt_box_assignment.eval())\n",
    "\n",
    "#     print(' Pos roi gt class assign  :\\n', roi_gt_class_ids.eval())\n",
    "#     print(' Pos roi gt boxes         :\\n', roi_gt_boxes.eval())\n",
    "#     print(' positive overlaps        :\\n', positive_overlaps.eval())\n",
    "#     print(' Positive indices: \\n',positive_indices.eval())\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "## 7.   Compute bbox delta \n",
    "#  Calculate refinement (difference b/w positive rois and its corresponding gt_boxes)\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "deltas  = utils.box_refinement_graph(positive_rois, roi_gt_boxes)\n",
    "deltas /= config.BBOX_STD_DEV\n",
    "# print('deltas')\n",
    "# print(deltas.eval())\n",
    "# print(' Positive RoIs ')\n",
    "# print(positive_rois.eval())\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "# 6.   Assign GT bbounding boxes and classes to the false positive RoIs\n",
    "#\n",
    "#  For each positive RoI, gather IoUs between the RoI and all gt bboxes, find the index correwsponding \n",
    "#  to the gt_box with the maximum overlap, and assign the corresponding gt_class and gt_bbox to the RoI\n",
    "#\n",
    "#  Idea -- instead of using arg_max, use arg_min \n",
    "#------------------------------------------------------------------------------------------------------\n",
    "fp_overlaps          = tf.gather(overlaps, false_positive_indices)\n",
    "fp_gt_box_assignment = tf.argmax(fp_overlaps, axis=1)\n",
    "fp_gt_boxes          = tf.gather(gt_boxes    , fp_gt_box_assignment)\n",
    "fp_gt_class_ids      = tf.gather(gt_class_ids, fp_gt_box_assignment)\n",
    "##--------------------------------------------------------------------------------\n",
    "## To Randomly assign classes to the false positive bounding boxes,\n",
    "## use the gt_class_id / OR the box_assignement to pick a class from the \n",
    "## shuffled <gt_classes_present> tensor\n",
    "##--------------------------------------------------------------------------------\n",
    "\n",
    "# print(' shape of false positive overlaps is :', fp_overlaps.get_shape())\n",
    "# print(' FP overlaps            \\n', fp_overlaps.eval())\n",
    "# print(' FP roi gt box assignemt:\\n', fp_gt_box_assignment.eval())\n",
    "# print(' FP roi gt boxes        :\\n', fp_gt_boxes.eval())\n",
    "# print(' FP roi gt class assign :\\n', fp_gt_class_ids.eval())\n",
    "# return positive_ind_shuffled, positive_indices, positive_overlaps, roi_gt_box_assignment,roi_gt_boxes, roi_gt_class_ids\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "## 8.  prepare gt_masks \n",
    "#      transpose gt_masks from [h, w, N] to [N, height, width] and add 4th dim at end [N, height, width, 1]\n",
    "#      Pick the right mask for each ROI\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "transposed_masks = tf.expand_dims(tf.transpose(gt_masks, [2, 0, 1]), -1)\n",
    "roi_masks = tf.gather(transposed_masks, roi_gt_box_assignment)\n",
    "\n",
    "# Compute mask targets\n",
    "boxes = positive_rois\n",
    "\n",
    "if config.USE_MINI_MASK:\n",
    "    # Transform ROI corrdinates from normalized image space\n",
    "    # to normalized mini-mask space.\n",
    "    y1, x1, y2, x2 = tf.split(positive_rois, 4, axis=1)\n",
    "    gt_y1, gt_x1, gt_y2, gt_x2 = tf.split(roi_gt_boxes, 4, axis=1)\n",
    "    gt_h = gt_y2 - gt_y1\n",
    "    gt_w = gt_x2 - gt_x1\n",
    "    y1 = (y1 - gt_y1) / gt_h\n",
    "    x1 = (x1 - gt_x1) / gt_w\n",
    "    y2 = (y2 - gt_y1) / gt_h\n",
    "    x2 = (x2 - gt_x1) / gt_w\n",
    "    boxes = tf.concat([y1, x1, y2, x2], 1)\n",
    "\n",
    "box_ids = tf.range(0, tf.shape(roi_masks)[0])\n",
    "masks   = tf.image.crop_and_resize(tf.cast(roi_masks, tf.float32), \n",
    "                                   boxes,\n",
    "                                   box_ids,\n",
    "                                   config.MASK_SHAPE)\n",
    "# Remove the extra dimension from masks.\n",
    "masks = tf.squeeze(masks, axis=3)\n",
    "\n",
    "# Threshold mask pixels at 0.5 to have GT masks be 0 or 1 to use with\n",
    "# binary cross entropy loss.\n",
    "masks = tf.round(masks)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "# Append negative ROIs and pad bbox deltas and masks that\n",
    "# are not used for negative ROIs with zeros.\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "rois             = tf.concat([positive_rois, negative_rois], axis=0)\n",
    "fp_rois          = tf.concat([positive_rois, false_positive_rois, negative_rois], axis=0)\n",
    "fp_roi_gt_boxes     = tf.concat([roi_gt_boxes,fp_gt_boxes], axis=0)\n",
    "fp_roi_gt_class_ids = tf.concat([roi_gt_class_ids, fp_gt_class_ids],axis=0)\n",
    "\n",
    "N                = tf.shape(negative_rois)[0]\n",
    "P                = tf.maximum(config.TRAIN_ROIS_PER_IMAGE - tf.shape(rois)[0], 0)\n",
    "\n",
    "\n",
    "rois             = tf.pad(rois            , [(0, P), (0, 0)])\n",
    "roi_gt_boxes     = tf.pad(roi_gt_boxes    , [(0, N + P), (0, 0)])\n",
    "roi_gt_class_ids = tf.pad(roi_gt_class_ids, [(0, N + P)])\n",
    "deltas           = tf.pad(deltas          , [(0, N + P), (0, 0)])\n",
    "masks            = tf.pad(masks           , [[0, N + P], (0, 0), (0, 0)])\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "# SSetup False Positive structures\n",
    "#\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "P1                  = tf.maximum(config.TRAIN_ROIS_PER_IMAGE - tf.shape(fp_rois)[0], 0)\n",
    "fp_rois             = tf.pad(rois            , [(0, P1), (0, 0)])\n",
    "\n",
    "\n",
    "P2                  = tf.maximum(config.TRAIN_ROIS_PER_IMAGE - tf.shape(fp_roi_gt_boxes)[0], 0)\n",
    "fp_roi_gt_boxes     = tf.pad(fp_roi_gt_boxes    , [(0, P2), (0, 0)])\n",
    "fp_roi_gt_class_ids = tf.pad(fp_roi_gt_class_ids, [(0, P2)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T21:01:21.161696Z",
     "start_time": "2018-05-06T21:01:15.939765Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 12\n"
     ]
    }
   ],
   "source": [
    "sess1 = tf.Session()\n",
    "# with sess1.as_default():\n",
    "# FeedList = [positive_ind_shuffled, positive_indices, positive_overlaps, roi_gt_class_ids, roi_gt_boxes, roi_gt_box_assignment ]\n",
    "FeedList = [false_positive_indices, fp_overlaps, fp_gt_box_assignment, fp_gt_boxes, fp_gt_class_ids, gt_class_ids,\n",
    "            fp_rois, fp_roi_gt_boxes, fp_roi_gt_class_ids,\n",
    "            rois   , roi_gt_boxes   , roi_gt_class_ids]\n",
    "tt = sess1.run(FeedList)\n",
    "print(type(tt), len(tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T21:01:30.008198Z",
     "start_time": "2018-05-06T21:01:29.754526Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " False Positive indices: \n",
      " [122  64 113]\n",
      " shape of false positive overlaps is : (3, 4)\n",
      " FP overlaps             \n",
      " [[0.2018 0.     0.1709 0.0007]\n",
      " [0.     0.     0.1634 0.4433]\n",
      " [0.4376 0.     0.0875 0.    ]]\n",
      " FP gt box assignemt:\n",
      " [0 3 0]\n",
      " FP gt boxes        :\n",
      " [[0.5547 0.5078 0.7188 0.8984]\n",
      " [0.0625 0.0312 0.4453 0.4141]\n",
      " [0.5547 0.5078 0.7188 0.8984]]\n",
      " FP gt class assign :\n",
      " [3 1 3]\n",
      " gt class ids assign :\n",
      " [3 1 2 1]\n",
      "\n",
      "fp_rois  (32, 4) \n",
      " [[0.5414 0.5176 0.8407 0.921 ]\n",
      " [0.2434 0.5207 0.5782 0.8437]\n",
      " [0.0981 0.3263 0.5372 0.7708]\n",
      " [0.1711 0.3235 0.5503 0.696 ]\n",
      " [0.1312 0.3908 0.4702 0.7093]\n",
      " [0.5008 0.4778 0.7118 0.8456]\n",
      " [0.0011 0.7039 0.3173 0.9938]\n",
      " [0.071  0.4767 0.5251 0.9238]\n",
      " [0.1672 0.5248 0.5325 0.8812]\n",
      " [0.086  0.5817 0.4395 0.91  ]\n",
      " [0.4685 0.0556 0.8681 0.4424]\n",
      " [0.     0.3327 0.2198 0.6969]\n",
      " [0.1762 0.2711 0.8316 0.8166]\n",
      " [0.521  0.4551 0.7614 0.7848]\n",
      " [0.     0.4805 0.3505 0.808 ]\n",
      " [0.2911 0.1935 0.835  0.7313]\n",
      " [0.0205 0.3791 0.5877 0.9839]\n",
      " [0.41   0.1036 0.8002 0.519 ]\n",
      " [0.308  0.2424 0.9067 0.8342]\n",
      " [0.1322 0.6401 0.5577 1.    ]\n",
      " [0.445  0.2522 0.8289 0.8292]\n",
      " [0.4562 0.3941 0.843  0.7404]\n",
      " [0.     0.2777 0.713  1.    ]\n",
      " [0.1781 0.1878 0.5425 0.5643]\n",
      " [0.4818 0.3257 0.7018 0.685 ]\n",
      " [0.5609 0.4329 0.7472 0.6443]\n",
      " [0.     0.     0.5606 0.676 ]\n",
      " [0.3179 0.4684 0.6535 0.8246]\n",
      " [0.     0.4001 0.2362 0.648 ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]]\n",
      "rois  (32, 4) \n",
      " [[0.5414 0.5176 0.8407 0.921 ]\n",
      " [0.2434 0.5207 0.5782 0.8437]\n",
      " [0.0981 0.3263 0.5372 0.7708]\n",
      " [0.1711 0.3235 0.5503 0.696 ]\n",
      " [0.1312 0.3908 0.4702 0.7093]\n",
      " [0.5008 0.4778 0.7118 0.8456]\n",
      " [0.0011 0.7039 0.3173 0.9938]\n",
      " [0.071  0.4767 0.5251 0.9238]\n",
      " [0.1672 0.5248 0.5325 0.8812]\n",
      " [0.086  0.5817 0.4395 0.91  ]\n",
      " [0.4685 0.0556 0.8681 0.4424]\n",
      " [0.     0.3327 0.2198 0.6969]\n",
      " [0.1762 0.2711 0.8316 0.8166]\n",
      " [0.521  0.4551 0.7614 0.7848]\n",
      " [0.     0.4805 0.3505 0.808 ]\n",
      " [0.2911 0.1935 0.835  0.7313]\n",
      " [0.0205 0.3791 0.5877 0.9839]\n",
      " [0.41   0.1036 0.8002 0.519 ]\n",
      " [0.308  0.2424 0.9067 0.8342]\n",
      " [0.1322 0.6401 0.5577 1.    ]\n",
      " [0.445  0.2522 0.8289 0.8292]\n",
      " [0.4562 0.3941 0.843  0.7404]\n",
      " [0.     0.2777 0.713  1.    ]\n",
      " [0.1781 0.1878 0.5425 0.5643]\n",
      " [0.4818 0.3257 0.7018 0.685 ]\n",
      " [0.5609 0.4329 0.7472 0.6443]\n",
      " [0.     0.     0.5606 0.676 ]\n",
      " [0.3179 0.4684 0.6535 0.8246]\n",
      " [0.     0.4001 0.2362 0.648 ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]]\n",
      "\n",
      "fp_rois_gt_boxes  (32, 4) \n",
      " [[0.5547 0.5078 0.7188 0.8984]\n",
      " [0.1406 0.4062 0.5547 0.8203]\n",
      " [0.1406 0.4062 0.5547 0.8203]\n",
      " [0.1406 0.4062 0.5547 0.8203]\n",
      " [0.1406 0.4062 0.5547 0.8203]\n",
      " [0.5547 0.5078 0.7188 0.8984]\n",
      " [0.0312 0.6172 0.375  0.9531]\n",
      " [0.1406 0.4062 0.5547 0.8203]\n",
      " [0.1406 0.4062 0.5547 0.8203]\n",
      " [0.0312 0.6172 0.375  0.9531]\n",
      " [0.5547 0.5078 0.7188 0.8984]\n",
      " [0.0625 0.0312 0.4453 0.4141]\n",
      " [0.5547 0.5078 0.7188 0.8984]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]]\n",
      "rois_gt_boxes  (32, 4) \n",
      " [[0.5547 0.5078 0.7188 0.8984]\n",
      " [0.1406 0.4062 0.5547 0.8203]\n",
      " [0.1406 0.4062 0.5547 0.8203]\n",
      " [0.1406 0.4062 0.5547 0.8203]\n",
      " [0.1406 0.4062 0.5547 0.8203]\n",
      " [0.5547 0.5078 0.7188 0.8984]\n",
      " [0.0312 0.6172 0.375  0.9531]\n",
      " [0.1406 0.4062 0.5547 0.8203]\n",
      " [0.1406 0.4062 0.5547 0.8203]\n",
      " [0.0312 0.6172 0.375  0.9531]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]]\n",
      "\n",
      "fp_rois_gt_class_ids  (32,) \n",
      " [3 2 2 2 2 3 1 2 2 1 3 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "rois_gt_class_ids  (32,) \n",
      " [3 2 2 2 2 3 1 2 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(' False Positive indices: \\n', tt[0])\n",
    "print(' shape of false positive overlaps is :', tt[1].shape)\n",
    "print(' FP overlaps             \\n', tt[1])\n",
    "print(' FP gt box assignemt:\\n', tt[2])\n",
    "print(' FP gt boxes        :\\n', tt[3])\n",
    "print(' FP gt class assign :\\n', tt[4])\n",
    "print(' gt class ids assign :\\n', tt[5])\n",
    "print()\n",
    "print('fp_rois ', tt[6].shape, '\\n',tt[6])\n",
    "print('rois ', tt[9].shape, '\\n',tt[9])\n",
    "print()\n",
    "print('fp_rois_gt_boxes ', tt[7].shape, '\\n',tt[7])\n",
    "print('rois_gt_boxes ', tt[10].shape, '\\n',tt[10])\n",
    "print()\n",
    "print('fp_rois_gt_class_ids ', tt[8].shape, '\\n',tt[8])\n",
    "print('rois_gt_class_ids ', tt[11].shape, '\\n',tt[11])\n",
    "# return positive_ind_shuffled, positive_indices, positive_overlaps, roi_gt_box_assignment,roi_gt_boxes, roi_gt_class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T18:44:28.696521Z",
     "start_time": "2018-05-06T18:44:28.453845Z"
    }
   },
   "outputs": [],
   "source": [
    "print(type(tt), len(tt))\n",
    "print(' Shuffled Positive indices:\\n', tt[0])\n",
    "print(' Positive indices:         \\n', tt[1])\n",
    "print(' positive overlaps shape  :  ', tt[2].shape)\n",
    "print(' positive overlaps        :\\n', tt[2])\n",
    "print(' Pos roi gt box assignment:\\n', tt[5])    \n",
    "print(' Pos roi gt class assign  :\\n', tt[3])\n",
    "print(' Pos roi gt boxes         :\\n', tt[4])\n",
    "\n",
    "sess1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T20:24:33.788471Z",
     "start_time": "2018-05-06T20:24:33.549836Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 1 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(input_gt_class_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  4. Add Negative ROIs. Add enough to maintain positive:negative ratio\n",
    "    negative_count = int((positive_count / config.ROI_POSITIVE_RATIO) - positive_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T16:29:56.648968Z",
     "start_time": "2018-05-06T16:29:55.701753Z"
    }
   },
   "outputs": [],
   "source": [
    "### 5.   Gather selected positive and negative ROIs\n",
    "# positive_rois      = tf.gather(proposals, positive_indices)\n",
    "# false_positive_rois= tf.gather(proposals, false_positive_indices)\n",
    "# negative_rois      = tf.gather(proposals, negative_indices)\n",
    "\n",
    "# print(positive_rois.eval())\n",
    "# print(false_positive_rois.eval())\n",
    "# print(negative_rois.eval())\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "# for each positive RoI, gather IoUs between the RoI and all gt bboxes, \n",
    "# find the index correwsponding to the gt_box with the maximum overlap, \n",
    "# and assign the corresponding gt_class and gt_bbox to the RoI\n",
    "#---------------------------------------------------------------------------------\n",
    "# positive_overlaps     = tf.gather(overlaps, positive_indices)\n",
    "# roi_gt_box_assignment = tf.argmax(positive_overlaps, axis=1)\n",
    "# roi_gt_boxes          = tf.gather(gt_boxes    , roi_gt_box_assignment)\n",
    "# roi_gt_class_ids      = tf.gather(gt_class_ids, roi_gt_box_assignment)\n",
    "# print(' shape of positive overlaps is :', positive_overlaps.get_shape())\n",
    "# print(' positive overlaps \\n', positive_overlaps.eval())\n",
    "# print(' roi gt box assignment', roi_gt_box_assignment.eval())\n",
    "\n",
    "## 7.   Compute bbox delta \n",
    "# calculate refinement (difference b/w positive rois and its corresponding gt_boxes)\n",
    "# deltas  = utils.box_refinement_graph(positive_rois, roi_gt_boxes)\n",
    "# deltas /= config.BBOX_STD_DEV\n",
    "# print(deltas.eval())\n",
    "# print(positive_rois.eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_overlaps     = tf.gather(overlaps, false_positive_indices)\n",
    "fp_box_assignment = tf.argmax(fp_overlaps, axis=1)\n",
    "fp_gt_boxes          = tf.gather(gt_boxes    , fp_box_assignment)\n",
    "fp_gt_class_ids      = tf.gather(gt_class_ids, fp_box_assignment)\n",
    "# print('     shape of positive overlaps is :', positive_overlaps.get_shape())\n",
    "print('positive overlaps \\n', fp_overlaps.eval())\n",
    "print('roi gt box assignemt', fp_box_assignment.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois             = tf.concat([positive_rois, negative_rois], axis=0)\n",
    "N                = tf.shape(negative_rois)[0]\n",
    "P                = tf.maximum(config.TRAIN_ROIS_PER_IMAGE - tf.shape(rois)[0], 0)\n",
    "rois             = tf.pad(rois            , [(0, P), (0, 0)])\n",
    "print(rois.eval())\n",
    "print(tf.shape(rois).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T18:40:11.026918Z",
     "start_time": "2018-05-06T18:40:10.808297Z"
    }
   },
   "outputs": [],
   "source": [
    "# # del positive_ind_shuffled, positive_indices, positive_overlaps, roi_gt_class_ids, roi_gt_boxes, roi_gt_box_assignment\n",
    "# import collections \n",
    "# Feed = collections.namedtuple('Feed', ['positive_ind_shuffled_res', 'positive_indices_res', 'positive_overlaps_res', \n",
    "#                                   'roi_gt_class_ids_res', 'roi_gt_boxes_res', 'roi_gt_box_assignment_res' ], verbose=True)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "\n",
    "### Predicted and Ground Truth Probability Heatmaps `pred_gaussian` and `gt_gaussian`  (NUMPY)\n",
    "`gt_gaussian` and `gt_gaussian2` from Numpy and Tensorflow PCN layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-22T16:27:08.129743Z",
     "start_time": "2018-04-22T16:27:03.059257Z"
    },
    "hideCode": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gt_heatmap  = layers_out[21]     # gt_gaussiam \n",
    "pred_heatmap= layers_out[18]  # pred_gaussian\n",
    "\n",
    "print('gt_gaussian heatmap shape : ', gt_heatmap.shape, ' pred_gaussian heatmap shape: ', pred_heatmap.shape)\n",
    "num_images = 1 # config.IMAGES_PER_GPU\n",
    "num_classes = config.NUM_CLASSES\n",
    "\n",
    "img = 2\n",
    "\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "print('Classes (1: circle, 2: square, 3: triangle ): ')\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "\n",
    "for cls in range(num_classes):\n",
    "    ttl = 'GROUND TRUTH HEATMAP - image :  {} class: {} '.format(img,cls)\n",
    "    print(' *** Zout  ', gt_heatmap[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian( gt_heatmap[img,:,:,cls], title = ttl)\n",
    "    \n",
    "    ttl = 'PREDICTED heatmap  - image :  {} class: {} '.format(img,cls)     \n",
    "    print(' *** pred_heatmap ', pred_heatmap[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian(pred_heatmap[img,:,:,cls], title = ttl)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Plot Predicition Probability Heatmaps `pred_gaussian` and `pred_gaussian2` (Numpy vs. Tensorflow)\n",
    "\n",
    "`pred_gaussian` and `pred_gaussian2` from Numpy and Tensorflow layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-22T16:33:38.120521Z",
     "start_time": "2018-04-22T16:33:32.924696Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pred_heatmap_np = layers_out[18]  # pred_gaussiam \n",
    "# pred_heatmap_tf = layers_out[24]  # pred_gaussian2\n",
    "pred_heatmap_np = layers_out[21]  # pred_gaussiam \n",
    "pred_heatmap_tf = layers_out[27]  # pred_gaussian2\n",
    "\n",
    "print('pred_gaussian_np heatmap shape : ', pred_heatmap_np.shape, ' pred_gaussian_tf heatmap shape: ', pred_heatmap_tf.shape)\n",
    "num_images = 1 # config.IMAGES_PER_GPU\n",
    "num_classes = config.NUM_CLASSES\n",
    "\n",
    "img = 2\n",
    "\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "print('Classes (1: circle, 2: square, 3: triangle ): ')\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "\n",
    "for cls in range(num_classes):\n",
    "    ttl = 'NUMPY predicted HEATMAP - image :  {} class: {} '.format(img,cls)\n",
    "    print(' *** Zout  ', pred_heatmap_np[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian( pred_heatmap_np[img,:,:,cls], title = ttl)\n",
    "    \n",
    "    ttl = 'PREDICTED heatmap  - image :  {} class: {} '.format(img,cls)     \n",
    "    print(' *** pred_heatmap ', pred_heatmap_tf[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian(pred_heatmap_tf[img,:,:,cls], title = ttl)  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Plot Output from FCN network `fcn_bilinear` and compare with `pred_gaussian`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-22T15:35:57.324157Z",
     "start_time": "2018-04-22T15:35:51.897933Z"
    },
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "from mrcnn.visualize import plot_gaussian\n",
    "Zout  = layers_out[7]     # gt_gaussiam \n",
    "Zout2 = layers_out[18]    # gt_gaussian2\n",
    "\n",
    "print(Zout.shape, Zout2.shape)\n",
    "num_images = config.IMAGES_PER_GPU\n",
    "num_classes = config.NUM_CLASSES\n",
    "\n",
    "img = 0\n",
    "for cls in range(num_classes):\n",
    "    ttl = 'NUMPY - image :  {} class: {} '.format(img,cls)\n",
    "    print(' *** Zout  ', Zout[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian( Zout[img,:,:,cls], title = ttl)\n",
    "    \n",
    "    ttl = 'TENSORFLOW - image :  {} class: {} '.format(img,cls)     \n",
    "    print(' *** Zout2 ', Zout2[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian(Zout2[img,:,:,cls], title = ttl)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Display ground truth bboxes from Shapes database (using `load_image_gt` )\n",
    "\n",
    "Here we are displaying the ground truth bounding boxes as provided by the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-22T16:34:25.418871Z",
     "start_time": "2018-04-22T16:34:24.842809Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "img = 2\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "p_original_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "# print(p_gt_class_id.shape, p_gt_bbox.shape, p_gt_mask.shape)\n",
    "print(p_gt_bbox)\n",
    "print(p_gt_class_id)\n",
    "visualize.draw_boxes(p_original_image, p_gt_bbox)\n",
    "\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "p_original_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "# print(p_gt_class_id.shape, p_gt_bbox.shape, p_gt_mask.shape)\n",
    "print(p_gt_bbox)\n",
    "print(p_gt_class_id)\n",
    "visualize.draw_boxes(p_original_image, p_gt_bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Display Predicted  Ground Truth Bounding Boxes  `gt_tensor` and `gt_tensor2`\n",
    "\n",
    "layers_out[22]  `gt_tensor` is based on input_gt_class_ids and input_normlzd_gt_boxes\n",
    "layers_out[28]  `gt_tensor2` is based on input_gt_class_ids and input_normlzd_gt_boxes, generated using Tensorflow\n",
    "\n",
    "Display the Ground Truth bounding boxes from the tensor we've constructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-22T16:38:20.707162Z",
     "start_time": "2018-04-22T16:38:20.105860Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mrcnn.utils  import stack_tensors, stack_tensors_3d\n",
    "# print(gt_bboxes)\n",
    "# visualize.display_instances(p_original_image, p_gt_bbox, p_gt_mask, p_gt_class_id, \n",
    "#                             dataset_train.class_names, figsize=(8, 8))\n",
    "# pp.pprint(gt_bboxes)\n",
    "img = 2\n",
    "image_id = img_meta[img,0]\n",
    "\n",
    "print('Image id: ',image_id)\n",
    "p_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)   \n",
    "gt_bboxes_stacked = stack_tensors_3d(layers_out[22][img])\n",
    "print(gt_bboxes_stacked)\n",
    "visualize.draw_boxes(p_image, gt_bboxes_stacked[:,2:6])\n",
    "\n",
    "\n",
    "print('Image id: ',image_id)\n",
    "p_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)   \n",
    "gt_bboxes_stacked = stack_tensors_3d(layers_out[28][img])\n",
    "print(' From pcn_layer_tf (TENSORFLOW)')\n",
    "print(gt_bboxes_stacked)\n",
    "visualize.draw_boxes(p_image, gt_bboxes_stacked[:,2:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "### Display Predicted Bounding Boxes  `pred_tensor` and `gt_tensor` \n",
    "\n",
    "layers_out[19]  `gt_tensor` is based on input_gt_class_ids and input_normlzd_gt_boxes - Using Numpy\n",
    "layers_out[25]  `gt_tensor` is based on input_gt_class_ids and input_normlzd_gt_boxes - Using Tensorflow\n",
    "\n",
    "Display the Ground Truth bounding boxes from the tensor we've constructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T20:27:32.016395Z",
     "start_time": "2018-05-03T20:27:30.902320Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mrcnn.utils  import stack_tensors, stack_tensors_3d\n",
    "# print(gt_bboxes)\n",
    "# visualize.display_instances(p_original_image, p_gt_bbox, p_gt_mask, p_gt_class_id, \n",
    "#                             dataset_train.class_names, figsize=(8, 8))\n",
    "# pp.pprint(gt_bboxes)\n",
    "img = 4\n",
    "\n",
    "image_id = img_meta[img,0]\n",
    "print(pred_tensor.shape, gt_tensor.shape)\n",
    "print('Image id: ',image_id)\n",
    "p_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)   \n",
    "    \n",
    "pred_bboxes_stacked = stack_tensors_3d(pred_tensor[img])\n",
    "print(pred_bboxes_stacked)\n",
    "visualize.draw_boxes(p_image, pred_bboxes_stacked[15:21][:,:4])\n",
    "\n",
    "selected_boxes = np.where(pred_bboxes_stacked[:,4] == 1)\n",
    "print()\n",
    "print(pred_bboxes_stacked[selected_boxes])\n",
    "visualize.draw_boxes(p_image, pred_bboxes_stacked[selected_boxes][:,:4])\n",
    "\n",
    "selected_boxes = np.where(pred_bboxes_stacked[:,4] == 2)\n",
    "print()\n",
    "print(pred_bboxes_stacked[selected_boxes])\n",
    "visualize.draw_boxes(p_image, pred_bboxes_stacked[selected_boxes][:,:4])\n",
    "\n",
    "selected_boxes = np.where(pred_bboxes_stacked[:,4] == 3)\n",
    "print()\n",
    "print(pred_bboxes_stacked[selected_boxes])\n",
    "visualize.draw_boxes(p_image, pred_bboxes_stacked[selected_boxes][:,:4])\n",
    "\n",
    "print('Image id: ',image_id)\n",
    "p_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)   \n",
    "gt_bboxes_stacked = stack_tensors_3d(gt_tensor[img])\n",
    "print(' From pcn_layer_tf (TENSORFLOW)')\n",
    "print(gt_bboxes_stacked)\n",
    "visualize.draw_boxes(p_image, gt_bboxes_stacked[:,:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T15:57:11.173145Z",
     "start_time": "2018-04-20T15:57:10.930483Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=120, precision=5)\n",
    "print(' gt_cls_cnt from Numpy - shape: ', layers_out[5].shape)\n",
    "print(layers_out[5])\n",
    "\n",
    "\n",
    "print(' gt_cls_cnt from TF - shape: ', layers_out[13].shape)\n",
    "print(layers_out[13])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Display `output_rois` generated for  positive classes\n",
    "\n",
    "Display bounding boxes from tensor of proposals produced by the network \n",
    "Circle:1 ,  Square: 2 , Triangle 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T13:33:56.441052Z",
     "start_time": "2018-05-03T13:33:55.962780Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = 0\n",
    "cls = 3 # <==== Class to display\n",
    "output_rois = layers_out[0][img]\n",
    "target_class_ids = layers_out[1][img]\n",
    "positive_box_ids = np.where(target_class_ids > 0)\n",
    "\n",
    "boxes  =  output_rois* [128,128,128,128]\n",
    "print(positive_box_ids)\n",
    "print(output_rois.shape, boxes.shape)\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "p_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "#+'-'+str(np.around(int(x[1]),decimals = 3))\n",
    "# class id: str(int(x[6]))+'-'+\n",
    "caps = [str(X)  for X in positive_box_ids[0].tolist() ]\n",
    "print(caps)\n",
    "visualize.draw_boxes(p_image, boxes[positive_box_ids], captions = caps)\n",
    "print(boxes[positive_box_ids])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Display `output_rois` generated for  negative classes\n",
    "\n",
    "Display bounding boxes from tensor of proposals produced by the network \n",
    "Circle:1 ,  Square: 2 , Triangle 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T13:36:48.692374Z",
     "start_time": "2018-05-03T13:36:48.159959Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "negative_box_ids = np.where(target_class_ids <= 0)\n",
    "boxes  =  output_rois * [128,128,128,128]\n",
    "print(negative_box_ids)\n",
    "print(output_rois.shape, boxes.shape)\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "p_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "#+'-'+str(np.around(int(x[1]),decimals = 3))\n",
    "# class id: str(int(x[6]))+'-'+\n",
    "caps = [str(X)  for X in negative_box_ids[0].tolist() ]\n",
    "print(caps)\n",
    "visualize.draw_boxes(p_image, boxes[negative_box_ids], captions = caps)\n",
    "print(boxes[negative_box_ids])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Display `roi_gt_boxes` generated from Proposal Target Layer\n",
    "\n",
    "Display bounding boxes from tensor of proposals produced by the network \n",
    "Circle:1 ,  Square: 2 , Triangle 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T20:28:08.481906Z",
     "start_time": "2018-05-03T20:28:08.247238Z"
    }
   },
   "outputs": [],
   "source": [
    "print(roi_gt_boxes[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T19:42:14.468506Z",
     "start_time": "2018-05-03T19:42:14.019705Z"
    },
    "hideCode": true,
    "hideOutput": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = 0\n",
    "# roi_gt_boxes = layers_out[21][img]\n",
    "target_class_ids = layers_out[1][img]\n",
    "positive_box_ids = np.where(target_class_ids > 0)\n",
    "print(' Target_class_ids:', target_class_ids)\n",
    "boxes  =  roi_gt_boxes * [128,128,128,128]\n",
    "print(roi_gt_boxes.shape, boxes.shape)\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "p_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "\n",
    "\n",
    "#+'-'+str(np.around(int(x[1]),decimals = 3))\n",
    "# class id: str(int(x[6]))+'-'+\n",
    "caps = [str(i)  for i,x in enumerate(positive_box_ids[0].tolist()) ]\n",
    "print(caps)\n",
    "\n",
    "visualize.draw_boxes(p_image, boxes[positive_box_ids], captions = caps)\n",
    "print(boxes[positive_box_ids])\n",
    "\n",
    "\n",
    "# visualize.draw_boxes(p_image, roi_gt_boxes[img,:], captions = caps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Display RoI proposals `pred_bboxes` generated for all classes in image\n",
    "\n",
    "Display bounding boxes from tensor of proposals produced by the network \n",
    "Square: 1 , Circle:2 , Triangle -3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T16:08:04.719657Z",
     "start_time": "2018-04-20T16:08:04.051881Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = 0\n",
    "# cls = 1  # <==== Class to dispaly\n",
    "\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "p_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "\n",
    "pred_tensor = layers_out[4][img]\n",
    "print(pred_tensor[img,cls,:].shape)\n",
    "pred_bboxes_stacked = stack_tensors_3d(pred_tensor)\n",
    "# lst2   = [np.squeeze(item) for item in np.split(pred_tensor, pred_tensor.shape[0], axis = 0 )]\n",
    "# results = np.concatenate( [ i[~np.all(i[:,2:6] == 0, axis=1)] for i in lst2] , axis = 0)\n",
    "caps = [str(int(x[6]))+'-'+str(int(x[0]))+'-'+str(np.around(x[1],decimals = 3))  for x in pred_bboxes_stacked.tolist() ]\n",
    "print(caps)\n",
    "\n",
    "# print(pc_tensor.pred_tensor[1,3,:])\n",
    "# print(pc_tensor.pred_tensor[1,3,:,2:6])\n",
    "visualize.draw_boxes(p_image, pred_bboxes_stacked[:,2:6], captions = caps)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#+'-'+str(np.around(int(x[1]),decimals = 3))\n",
    "# class id: str(int(x[6]))+'-'+\n",
    "# caps = [str(int(x[0]))+'-'+str(np.around(x[1],decimals = 3))  for x in pred_tensor[img,cls,:].tolist() ]\n",
    "# print(caps)\n",
    "\n",
    "# visualize.draw_boxes(p_image, pred_tensor[img,cls,:,2:6], captions = caps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Verify matching results between numpy and tensorflow routines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Control pred_tensor / pred_tensor2 on 100 training shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T19:21:31.745089Z",
     "start_time": "2018-05-03T19:21:30.131058Z"
    },
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "layers_out = get_layer_output_1(model.keras_model, train_batch_x, [0,22], verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T19:22:36.277631Z",
     "start_time": "2018-05-03T19:22:33.123307Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    train_batch_x, train_batch_y = next(train_generator)\n",
    "\n",
    "    layers_out = get_layer_output_2(model.keras_model, train_batch_x, 1, verbose = False)\n",
    "\n",
    "    pt   = layers_out[5]   # pred_tensor\n",
    "    pt2  = layers_out[11]  # pred_tensor_2\n",
    "    \n",
    "#     pcc  = layers_out[9]   # pred_cls_cnt\n",
    "#     pcc2 = layers_out[15]  # pred_cls_cnt_2\n",
    "\n",
    "#     print( pt2.shape, pcc2.shape)\n",
    "#     print( pt.shape, pt2.shape)\n",
    "#     print(pc2)\n",
    "\n",
    "    for img in range(config.BATCH_SIZE):\n",
    "        for cls in range(4):\n",
    "#             print(pt2[img][cls])\n",
    "#             print(pt[img][cls])\n",
    "            pt_equal = np.all(pt2[img,cls,:,1:-1]== pt[img,cls,:,1:-1], axis = -1)\n",
    "            print('* Iteration', i , 'Image ',img,' Class ',cls, ' pred_tesnor == pred_tensor2 : ',pt_equal.all())\n",
    "            \n",
    "            if (~pt_equal.all()):\n",
    "#                 print(' Iteration', i , 'Image ',img,' Class ',cls, ' ALL pt_equal: ',pt_equal.all())\n",
    "                print(pt_equal)\n",
    "                print('\\n -- using numpy \\n',pt[img][cls,~pt_equal,:-1])\n",
    "                print('\\n -- using tensorflow \\n',pt2[img][cls,~pt_equal])\n",
    "                print()\n",
    "    #             print('\\n -- using numpy \\n',pt[img][cls])            \n",
    "    #             print('\\n -- using tensorflow \\n',pt2[img][cls])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Control output_rois/ new_output_rois"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Control pred_tesnor / pred_tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T10:43:43.392596Z",
     "start_time": "2018-04-17T10:43:43.123879Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pt   = layers_out[4]   # pred_tensor\n",
    "pt2  = layers_out[12] \n",
    " \n",
    "print( pt.shape, pt2.shape)\n",
    "\n",
    "for img in range(config.BATCH_SIZE):\n",
    "    for cls in range(4):\n",
    "        equal = np.all(pt[img][cls,:,1:7] == pt2[img][cls,:,1:7], axis = -1)\n",
    "        print('Image ',img,' Class ',cls, ' ALL EQUAL: ',equal.all())\n",
    "#         print(' numpy results ')\n",
    "#         print( pt[img,cls])\n",
    "#         print('tensorflow results ')\n",
    "#         print(pt2[img,cls])\n",
    "        if (~equal.all()):\n",
    "#             print('Image ',img,' Class ',cls, ' ALL EQUAL: ',equal.all())\n",
    "            print(equal)\n",
    "            print('\\n -- using numpy (pt) \\n',pt[img][cls,~equal,:-1])\n",
    "            print('\\n -- using tensorflow (pt2) \\n',pt2[img][cls,~equal])\n",
    "            print()\n",
    "#             print('\\n -- using numpy \\n',pt[img][cls])            \n",
    "#             print('\\n -- using tensorflow \\n',pt2[img][cls])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T19:27:37.317538Z",
     "start_time": "2018-05-03T19:25:41.115972Z"
    },
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    train_batch_x, train_batch_y = next(train_generator)\n",
    "    layers_out = get_layer_output_1(model.keras_model, train_batch_x, [0,22], verbose = False) \n",
    "#     print( layers_out[0].shape, layers_out[1].shape)\n",
    "\n",
    "    equal = np.all(layers_out[0] == layers_out[1], axis = -1)\n",
    "    print('Iteration :', i, '--  ALL EQUAL: ',equal.all())\n",
    "    if (~equal.all()):\n",
    "    #             print('Image ',img,' Class ',cls, ' ALL EQUAL: ',equal.all())\n",
    "        print(equal)\n",
    "        print('\\n -- output_rois \\n',layers_out[0])\n",
    "        print('\\n -- rois        \\n',layers_out[1])\n",
    "        print()\n",
    "        \n",
    "        \n",
    "# for img in range(config.BATCH_SIZE):\n",
    "#         print('Image ',img,' Class ',cls, ' ALL EQUAL: ',equal.all())\n",
    "#         print(' numpy results ')\n",
    "#         print( pt[img,cls])\n",
    "#         print('tensorflow results ')\n",
    "#         print(pt2[img,cls])\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(5):\n",
    "#     for j in range(32):\n",
    "#         print()\n",
    "#         print(layers_out[0][i,j])\n",
    "#         print(layers_out[1][i,j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control  xxxxxxx / yyyyyyy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T10:43:43.392596Z",
     "start_time": "2018-04-17T10:43:43.123879Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pt   = layers_out[4]   # pred_tensor\n",
    "pt2  = layers_out[12] \n",
    " \n",
    "print( pt.shape, pt2.shape)\n",
    "\n",
    "for img in range(config.BATCH_SIZE):\n",
    "    for cls in range(4):\n",
    "        equal = np.all(pt[img][cls,:,1:7] == pt2[img][cls,:,1:7], axis = -1)\n",
    "        print('Image ',img,' Class ',cls, ' ALL EQUAL: ',equal.all())\n",
    "#         print(' numpy results ')\n",
    "#         print( pt[img,cls])\n",
    "#         print('tensorflow results ')\n",
    "#         print(pt2[img,cls])\n",
    "        if (~equal.all()):\n",
    "#             print('Image ',img,' Class ',cls, ' ALL EQUAL: ',equal.all())\n",
    "            print(equal)\n",
    "            print('\\n -- using numpy (pt) \\n',pt[img][cls,~equal,:-1])\n",
    "            print('\\n -- using tensorflow (pt2) \\n',pt2[img][cls,~equal])\n",
    "            print()\n",
    "#             print('\\n -- using numpy \\n',pt[img][cls])            \n",
    "#             print('\\n -- using tensorflow \\n',pt2[img][cls])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python [conda env:TF_gpu]",
   "language": "python",
   "name": "conda-env-TF_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
