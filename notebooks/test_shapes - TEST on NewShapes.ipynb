{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN - Test on Shapes Dataset\n",
    "\n",
    "Run the Mask R-CNN net in inference mode, with the additional PCILayer that generates the context-based tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T10:33:01.959404Z",
     "start_time": "2018-05-10T10:32:57.845332Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 1.6.0   Keras Version : 2.1.4 \n",
      " Initialize config object - super\n",
      "(56, 56)\n",
      "\n",
      "Configuration Parameters:\n",
      "-------------------------\n",
      "BACKBONE_SHAPES                [[32 32]\n",
      " [16 16]\n",
      " [ 8  8]\n",
      " [ 4  4]\n",
      " [ 2  2]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     2\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "EPOCHS_TO_RUN                  0\n",
      "FCN_INPUT_SHAPE                [128 128]\n",
      "GPU_COUNT                      1\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [128 128   3]\n",
      "LAST_EPOCH_RAN                 0\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           shapes\n",
      "NUM_CLASSES                    7\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                7\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      " Add image --->  0\n",
      " Add image --->  1\n",
      " Add image --->  2\n",
      " Add image --->  3\n",
      " Add image --->  4\n",
      " Add image --->  5\n",
      " Add image --->  6\n",
      " Add image --->  7\n",
      " Add image --->  8\n",
      " Add image --->  9\n",
      " Add image --->  10\n",
      " Add image --->  11\n",
      " Add image --->  12\n",
      " Add image --->  13\n",
      " Add image --->  14\n",
      " Add image --->  15\n",
      " Add image --->  16\n",
      " Add image --->  17\n",
      " Add image --->  18\n",
      " Add image --->  19\n",
      " Add image --->  20\n",
      " Add image --->  21\n",
      " Add image --->  22\n",
      " Add image --->  23\n",
      " Add image --->  24\n",
      " Add image --->  25\n",
      " Add image --->  26\n",
      " Add image --->  27\n",
      " Add image --->  28\n",
      " Add image --->  29\n",
      " Add image --->  30\n",
      " Add image --->  31\n",
      " !!!!!!  Zero Mask Found !!!!!!\n",
      " !!!!!!  Zero Mask Found !!!!!!\n",
      " ===> Find Hidden Shapes() found hidden objects \n",
      "[ ('building', (158, 224, 213), (70, 53, 12, 15)),\n",
      "  ('tree', (210, 8, 24), (91, 64, 13, 13)),\n",
      "  ('tree', (254, 240, 249), (90, 67, 14, 14)),\n",
      "  ('building', (79, 155, 174), (84, 75, 17, 25)),\n",
      "  ('car', (229, 5, 17), (39, 99, 27, 13)),\n",
      "  ('car', (179, 74, 62), (71, 100, 27, 13))]\n",
      " ****** Objects completely hidden are :  [2, 1]\n",
      "('tree', (254, 240, 249), (90, 67, 14, 14))\n",
      "('tree', (210, 8, 24), (91, 64, 13, 13))\n",
      "( 31 ) ------ shapes after removeal of totally hidden shapes ------\n",
      "[ ('building', (158, 224, 213), (70, 53, 12, 15)),\n",
      "  ('building', (79, 155, 174), (84, 75, 17, 25)),\n",
      "  ('car', (229, 5, 17), (39, 99, 27, 13)),\n",
      "  ('car', (179, 74, 62), (71, 100, 27, 13))]\n",
      "    Number of shapes now is :  4\n",
      " Add image --->  32\n",
      " Add image --->  33\n",
      " Add image --->  34\n",
      " Add image --->  35\n",
      " Add image --->  36\n",
      " Add image --->  37\n",
      " Add image --->  38\n",
      " Add image --->  39\n",
      " Add image --->  40\n",
      " Add image --->  41\n",
      " Add image --->  42\n",
      " Add image --->  43\n",
      " Add image --->  44\n",
      " Add image --->  45\n",
      " Add image --->  46\n",
      " Add image --->  47\n",
      " Add image --->  48\n",
      " Add image --->  49\n",
      " Add image --->  50\n",
      " Add image --->  51\n",
      " Add image --->  52\n",
      " Add image --->  53\n",
      " Add image --->  54\n",
      " Add image --->  55\n",
      " Add image --->  56\n",
      " Add image --->  57\n",
      " Add image --->  58\n",
      " Add image --->  59\n",
      " Add image --->  60\n",
      " Add image --->  61\n",
      " Add image --->  62\n",
      " Add image --->  63\n",
      " Add image --->  64\n",
      " Add image --->  65\n",
      " Add image --->  66\n",
      " Add image --->  67\n",
      " Add image --->  68\n",
      " Add image --->  69\n",
      " Add image --->  70\n",
      " Add image --->  71\n",
      " Add image --->  72\n",
      " Add image --->  73\n",
      " Add image --->  74\n",
      " Add image --->  75\n",
      " Add image --->  76\n",
      " Add image --->  77\n",
      " Add image --->  78\n",
      " Add image --->  79\n",
      " Add image --->  80\n",
      " Add image --->  81\n",
      " Add image --->  82\n",
      " Add image --->  83\n",
      " Add image --->  84\n",
      " Add image --->  85\n",
      " Add image --->  86\n",
      " Add image --->  87\n",
      " Add image --->  88\n",
      " Add image --->  89\n",
      " Add image --->  90\n",
      " Add image --->  91\n",
      " Add image --->  92\n",
      " Add image --->  93\n",
      " Add image --->  94\n",
      " Add image --->  95\n",
      " Add image --->  96\n",
      " Add image --->  97\n",
      " Add image --->  98\n",
      " Add image --->  99\n",
      " !!!!!!  Zero Mask Found !!!!!!\n",
      " ===> Find Hidden Shapes() found hidden objects \n",
      "[ ('building', (192, 251, 107), (54, 62, 14, 19)),\n",
      "  ('car', (165, 5, 183), (93, 69, 16, 8)),\n",
      "  ('building', (16, 188, 229), (91, 82, 19, 28)),\n",
      "  ('tree', (169, 94, 166), (107, 100, 22, 22)),\n",
      "  ('tree', (111, 32, 160), (76, 104, 23, 23))]\n",
      " ****** Objects completely hidden are :  [1]\n",
      "('car', (165, 5, 183), (93, 69, 16, 8))\n",
      "( 99 ) ------ shapes after removeal of totally hidden shapes ------\n",
      "[ ('building', (192, 251, 107), (54, 62, 14, 19)),\n",
      "  ('building', (16, 188, 229), (91, 82, 19, 28)),\n",
      "  ('tree', (169, 94, 166), (107, 100, 22, 22)),\n",
      "  ('tree', (111, 32, 160), (76, 104, 23, 23))]\n",
      "    Number of shapes now is :  4\n",
      " Add image --->  100\n",
      " Add image --->  101\n",
      " Add image --->  102\n",
      " Add image --->  103\n",
      " Add image --->  104\n",
      " Add image --->  105\n",
      " Add image --->  106\n",
      " Add image --->  107\n",
      " Add image --->  108\n",
      " Add image --->  109\n",
      " Add image --->  110\n",
      " Add image --->  111\n",
      " Add image --->  112\n",
      " Add image --->  113\n",
      " Add image --->  114\n",
      " Add image --->  115\n",
      " Add image --->  116\n",
      " Add image --->  117\n",
      " Add image --->  118\n",
      " Add image --->  119\n",
      " Add image --->  120\n",
      " Add image --->  121\n",
      " Add image --->  122\n",
      " Add image --->  123\n",
      " Add image --->  124\n",
      " Add image --->  125\n",
      " Add image --->  126\n",
      " Add image --->  127\n",
      " Add image --->  128\n",
      " Add image --->  129\n",
      " Add image --->  130\n",
      " Add image --->  131\n",
      " Add image --->  132\n",
      " Add image --->  133\n",
      " Add image --->  134\n",
      " Add image --->  135\n",
      " Add image --->  136\n",
      " Add image --->  137\n",
      " Add image --->  138\n",
      " Add image --->  139\n",
      " Add image --->  140\n",
      " Add image --->  141\n",
      " Add image --->  142\n",
      " Add image --->  143\n",
      " Add image --->  144\n",
      " Add image --->  145\n",
      " Add image --->  146\n",
      " Add image --->  147\n",
      " Add image --->  148\n",
      " Add image --->  149\n",
      " Add image --->  150\n",
      " Add image --->  151\n",
      " Add image --->  152\n",
      " Add image --->  153\n",
      " Add image --->  154\n",
      " Add image --->  155\n",
      " Add image --->  156\n",
      " Add image --->  157\n",
      " Add image --->  158\n",
      " Add image --->  159\n",
      " Add image --->  160\n",
      " Add image --->  161\n",
      " Add image --->  162\n",
      " Add image --->  163\n",
      " Add image --->  164\n",
      " Add image --->  165\n",
      " Add image --->  166\n",
      " Add image --->  167\n",
      " Add image --->  168\n",
      " Add image --->  169\n",
      " Add image --->  170\n",
      " Add image --->  171\n",
      " Add image --->  172\n",
      " Add image --->  173\n",
      " Add image --->  174\n",
      " Add image --->  175\n",
      " Add image --->  176\n",
      " Add image --->  177\n",
      " Add image --->  178\n",
      " Add image --->  179\n",
      " Add image --->  180\n",
      " Add image --->  181\n",
      " Add image --->  182\n",
      " Add image --->  183\n",
      " Add image --->  184\n",
      " Add image --->  185\n",
      " Add image --->  186\n",
      " Add image --->  187\n",
      " Add image --->  188\n",
      " !!!!!!  Zero Mask Found !!!!!!\n",
      " ===> Find Hidden Shapes() found hidden objects \n",
      "[ ('sun', (195, 235, 182), (92, 7, 4, 4)),\n",
      "  ('tree', (24, 200, 254), (32, 63, 13, 13)),\n",
      "  ('car', (154, 94, 165), (83, 74, 18, 9)),\n",
      "  ('building', (127, 245, 21), (36, 77, 18, 26)),\n",
      "  ('person', (55, 232, 191), (53, 92, 4, 21)),\n",
      "  ('person', (118, 29, 80), (82, 97, 4, 22))]\n",
      " ****** Objects completely hidden are :  [1]\n",
      "('tree', (24, 200, 254), (32, 63, 13, 13))\n",
      "( 188 ) ------ shapes after removeal of totally hidden shapes ------\n",
      "[ ('sun', (195, 235, 182), (92, 7, 4, 4)),\n",
      "  ('car', (154, 94, 165), (83, 74, 18, 9)),\n",
      "  ('building', (127, 245, 21), (36, 77, 18, 26)),\n",
      "  ('person', (55, 232, 191), (53, 92, 4, 21)),\n",
      "  ('person', (118, 29, 80), (82, 97, 4, 22))]\n",
      "    Number of shapes now is :  5\n",
      " Add image --->  189\n",
      " Add image --->  190\n",
      " Add image --->  191\n",
      " Add image --->  192\n",
      " Add image --->  193\n",
      " Add image --->  194\n",
      " Add image --->  195\n",
      " Add image --->  196\n",
      " Add image --->  197\n",
      " Add image --->  198\n",
      " Add image --->  199\n",
      " Add image --->  200\n",
      " Add image --->  201\n",
      " Add image --->  202\n",
      " Add image --->  203\n",
      " Add image --->  204\n",
      " Add image --->  205\n",
      " Add image --->  206\n",
      " Add image --->  207\n",
      " Add image --->  208\n",
      " Add image --->  209\n",
      " Add image --->  210\n",
      " Add image --->  211\n",
      " Add image --->  212\n",
      " Add image --->  213\n",
      " Add image --->  214\n",
      " Add image --->  215\n",
      " Add image --->  216\n",
      " Add image --->  217\n",
      " Add image --->  218\n",
      " Add image --->  219\n",
      " Add image --->  220\n",
      " Add image --->  221\n",
      " Add image --->  222\n",
      " Add image --->  223\n",
      " Add image --->  224\n",
      " Add image --->  225\n",
      " Add image --->  226\n",
      " Add image --->  227\n",
      " Add image --->  228\n",
      " Add image --->  229\n",
      " Add image --->  230\n",
      " Add image --->  231\n",
      " Add image --->  232\n",
      " Add image --->  233\n",
      " Add image --->  234\n",
      " Add image --->  235\n",
      " Add image --->  236\n",
      " Add image --->  237\n",
      " Add image --->  238\n",
      " Add image --->  239\n",
      " Add image --->  240\n",
      " Add image --->  241\n",
      " Add image --->  242\n",
      " Add image --->  243\n",
      " Add image --->  244\n",
      " Add image --->  245\n",
      " Add image --->  246\n",
      " Add image --->  247\n",
      " Add image --->  248\n",
      " Add image --->  249\n",
      " Add image --->  250\n",
      " Add image --->  251\n",
      " Add image --->  252\n",
      " Add image --->  253\n",
      " Add image --->  254\n",
      " !!!!!!  Zero Mask Found !!!!!!\n",
      " ===> Find Hidden Shapes() found hidden objects \n",
      "[ ('cloud', (247, 46, 83), (84, 20, 15, 3)),\n",
      "  ('cloud', (232, 68, 137), (17, 26, 27, 5)),\n",
      "  ('tree', (225, 5, 21), (30, 75, 16, 16)),\n",
      "  ('building', (105, 166, 73), (23, 84, 19, 29)),\n",
      "  ('car', (31, 63, 58), (89, 92, 24, 12))]\n",
      " ****** Objects completely hidden are :  [2]\n",
      "('tree', (225, 5, 21), (30, 75, 16, 16))\n",
      "( 254 ) ------ shapes after removeal of totally hidden shapes ------\n",
      "[ ('cloud', (247, 46, 83), (84, 20, 15, 3)),\n",
      "  ('cloud', (232, 68, 137), (17, 26, 27, 5)),\n",
      "  ('building', (105, 166, 73), (23, 84, 19, 29)),\n",
      "  ('car', (31, 63, 58), (89, 92, 24, 12))]\n",
      "    Number of shapes now is :  4\n",
      " Add image --->  255\n",
      " Add image --->  256\n",
      " !!!!!!  Zero Mask Found !!!!!!\n",
      " ===> Find Hidden Shapes() found hidden objects \n",
      "[ ('tree', (188, 53, 127), (50, 64, 13, 13)),\n",
      "  ('tree', (180, 35, 58), (96, 69, 14, 14)),\n",
      "  ('building', (156, 58, 64), (97, 84, 19, 29))]\n",
      " ****** Objects completely hidden are :  [1]\n",
      "('tree', (180, 35, 58), (96, 69, 14, 14))\n",
      "( 256 ) ------ shapes after removeal of totally hidden shapes ------\n",
      "[('tree', (188, 53, 127), (50, 64, 13, 13)), ('building', (156, 58, 64), (97, 84, 19, 29))]\n",
      "    Number of shapes now is :  2\n",
      " Add image --->  257\n",
      " Add image --->  258\n",
      " Add image --->  259\n",
      " Add image --->  260\n",
      " Add image --->  261\n",
      " Add image --->  262\n",
      " Add image --->  263\n",
      " Add image --->  264\n",
      " Add image --->  265\n",
      " Add image --->  266\n",
      " Add image --->  267\n",
      " Add image --->  268\n",
      " Add image --->  269\n",
      " Add image --->  270\n",
      " Add image --->  271\n",
      " Add image --->  272\n",
      " !!!!!!  Zero Mask Found !!!!!!\n",
      " ===> Find Hidden Shapes() found hidden objects \n",
      "[ ('sun', (221, 50, 208), (26, 15, 6, 6)),\n",
      "  ('cloud', (87, 118, 182), (16, 31, 37, 7)),\n",
      "  ('cloud', (88, 67, 202), (10, 32, 40, 13)),\n",
      "  ('tree', (155, 219, 153), (44, 74, 15, 15)),\n",
      "  ('building', (187, 206, 224), (39, 78, 18, 26)),\n",
      "  ('car', (184, 62, 252), (106, 81, 20, 10)),\n",
      "  ('car', (175, 167, 98), (90, 88, 23, 11))]\n",
      " ****** Objects completely hidden are :  [3]\n",
      "('tree', (155, 219, 153), (44, 74, 15, 15))\n",
      "( 272 ) ------ shapes after removeal of totally hidden shapes ------\n",
      "[ ('sun', (221, 50, 208), (26, 15, 6, 6)),\n",
      "  ('cloud', (87, 118, 182), (16, 31, 37, 7)),\n",
      "  ('cloud', (88, 67, 202), (10, 32, 40, 13)),\n",
      "  ('building', (187, 206, 224), (39, 78, 18, 26)),\n",
      "  ('car', (184, 62, 252), (106, 81, 20, 10)),\n",
      "  ('car', (175, 167, 98), (90, 88, 23, 11))]\n",
      "    Number of shapes now is :  6\n",
      " Add image --->  273\n",
      " Add image --->  274\n",
      " Add image --->  275\n",
      " Add image --->  276\n",
      " Add image --->  277\n",
      " Add image --->  278\n",
      " Add image --->  279\n",
      " Add image --->  280\n",
      " Add image --->  281\n",
      " Add image --->  282\n",
      " Add image --->  283\n",
      " Add image --->  284\n",
      " Add image --->  285\n",
      " Add image --->  286\n",
      " Add image --->  287\n",
      " !!!!!!  Zero Mask Found !!!!!!\n",
      " ===> Find Hidden Shapes() found hidden objects \n",
      "[ ('cloud', (117, 77, 87), (15, 27, 29, 5)),\n",
      "  ('cloud', (173, 25, 216), (103, 31, 37, 7)),\n",
      "  ('cloud', (188, 245, 108), (103, 31, 37, 7)),\n",
      "  ('tree', (13, 107, 18), (25, 70, 14, 14)),\n",
      "  ('person', (132, 2, 236), (53, 72, 3, 16)),\n",
      "  ('person', (134, 11, 222), (28, 88, 4, 20))]\n",
      " ****** Objects completely hidden are :  [1]\n",
      "('cloud', (173, 25, 216), (103, 31, 37, 7))\n",
      "( 287 ) ------ shapes after removeal of totally hidden shapes ------\n",
      "[ ('cloud', (117, 77, 87), (15, 27, 29, 5)),\n",
      "  ('cloud', (188, 245, 108), (103, 31, 37, 7)),\n",
      "  ('tree', (13, 107, 18), (25, 70, 14, 14)),\n",
      "  ('person', (132, 2, 236), (53, 72, 3, 16)),\n",
      "  ('person', (134, 11, 222), (28, 88, 4, 20))]\n",
      "    Number of shapes now is :  5\n",
      " Add image --->  288\n",
      " Add image --->  289\n",
      " Add image --->  290\n",
      " Add image --->  291\n",
      " Add image --->  292\n",
      " Add image --->  293\n",
      " Add image --->  294\n",
      " Add image --->  295\n",
      " Add image --->  296\n",
      " Add image --->  297\n",
      " Add image --->  298\n",
      " Add image --->  299\n",
      " Add image --->  300\n",
      " Add image --->  301\n",
      " Add image --->  302\n",
      " Add image --->  303\n",
      " !!!!!!  Zero Mask Found !!!!!!\n",
      " ===> Find Hidden Shapes() found hidden objects \n",
      "[ ('cloud', (236, 226, 144), (58, 24, 23, 4)),\n",
      "  ('tree', (163, 4, 178), (79, 59, 12, 12)),\n",
      "  ('person', (28, 166, 34), (23, 71, 3, 16)),\n",
      "  ('building', (95, 88, 139), (79, 76, 17, 25)),\n",
      "  ('person', (242, 121, 150), (58, 80, 3, 18)),\n",
      "  ('person', (12, 150, 5), (35, 83, 3, 19))]\n",
      " ****** Objects completely hidden are :  [1]\n",
      "('tree', (163, 4, 178), (79, 59, 12, 12))\n",
      "( 303 ) ------ shapes after removeal of totally hidden shapes ------\n",
      "[ ('cloud', (236, 226, 144), (58, 24, 23, 4)),\n",
      "  ('person', (28, 166, 34), (23, 71, 3, 16)),\n",
      "  ('building', (95, 88, 139), (79, 76, 17, 25)),\n",
      "  ('person', (242, 121, 150), (58, 80, 3, 18)),\n",
      "  ('person', (12, 150, 5), (35, 83, 3, 19))]\n",
      "    Number of shapes now is :  5\n",
      " Add image --->  304\n",
      " Add image --->  305\n",
      " Add image --->  306\n",
      " !!!!!!  Zero Mask Found !!!!!!\n",
      " ===> Find Hidden Shapes() found hidden objects \n",
      "[ ('building', (208, 18, 103), (93, 55, 13, 16)),\n",
      "  ('person', (170, 70, 225), (79, 73, 3, 17)),\n",
      "  ('building', (231, 127, 135), (84, 78, 18, 26)),\n",
      "  ('building', (11, 237, 93), (58, 84, 19, 29)),\n",
      "  ('car', (255, 143, 157), (65, 107, 30, 15))]\n",
      " ****** Objects completely hidden are :  [1]\n",
      "('person', (170, 70, 225), (79, 73, 3, 17))\n",
      "( 306 ) ------ shapes after removeal of totally hidden shapes ------\n",
      "[ ('building', (208, 18, 103), (93, 55, 13, 16)),\n",
      "  ('building', (231, 127, 135), (84, 78, 18, 26)),\n",
      "  ('building', (11, 237, 93), (58, 84, 19, 29)),\n",
      "  ('car', (255, 143, 157), (65, 107, 30, 15))]\n",
      "    Number of shapes now is :  4\n",
      " Add image --->  307\n",
      " Add image --->  308\n",
      " Add image --->  309\n",
      " Add image --->  310\n",
      " Add image --->  311\n",
      " Add image --->  312\n",
      " Add image --->  313\n",
      " Add image --->  314\n",
      " Add image --->  315\n",
      " Add image --->  316\n",
      " Add image --->  317\n",
      " Add image --->  318\n",
      " Add image --->  319\n",
      " Add image --->  320\n",
      " Add image --->  321\n",
      " Add image --->  322\n",
      " Add image --->  323\n",
      " Add image --->  324\n",
      " Add image --->  325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Add image --->  326\n",
      " Add image --->  327\n",
      " Add image --->  328\n",
      " Add image --->  329\n",
      " Add image --->  330\n",
      " Add image --->  331\n",
      " Add image --->  332\n",
      " Add image --->  333\n",
      " Add image --->  334\n",
      " Add image --->  335\n",
      " Add image --->  336\n",
      " Add image --->  337\n",
      " Add image --->  338\n",
      " Add image --->  339\n",
      " Add image --->  340\n",
      " Add image --->  341\n",
      " Add image --->  342\n",
      " Add image --->  343\n",
      " Add image --->  344\n",
      " Add image --->  345\n",
      " Add image --->  346\n",
      " Add image --->  347\n",
      " !!!!!!  Zero Mask Found !!!!!!\n",
      " ===> Find Hidden Shapes() found hidden objects \n",
      "[ ('building', (251, 181, 224), (45, 54, 12, 15)),\n",
      "  ('tree', (181, 42, 110), (69, 62, 12, 12)),\n",
      "  ('building', (112, 126, 63), (63, 80, 18, 27)),\n",
      "  ('car', (75, 54, 180), (81, 85, 22, 11)),\n",
      "  ('tree', (10, 61, 175), (86, 93, 20, 20)),\n",
      "  ('tree', (103, 175, 83), (71, 103, 23, 23))]\n",
      " ****** Objects completely hidden are :  [1]\n",
      "('tree', (181, 42, 110), (69, 62, 12, 12))\n",
      "( 347 ) ------ shapes after removeal of totally hidden shapes ------\n",
      "[ ('building', (251, 181, 224), (45, 54, 12, 15)),\n",
      "  ('building', (112, 126, 63), (63, 80, 18, 27)),\n",
      "  ('car', (75, 54, 180), (81, 85, 22, 11)),\n",
      "  ('tree', (10, 61, 175), (86, 93, 20, 20)),\n",
      "  ('tree', (103, 175, 83), (71, 103, 23, 23))]\n",
      "    Number of shapes now is :  5\n",
      " Add image --->  348\n",
      " Add image --->  349\n",
      " Add image --->  350\n",
      " Add image --->  351\n",
      " Add image --->  352\n",
      " Add image --->  353\n",
      " Add image --->  354\n",
      " Add image --->  355\n",
      " Add image --->  356\n",
      " Add image --->  357\n",
      " Add image --->  358\n",
      " Add image --->  359\n",
      " Add image --->  360\n",
      " Add image --->  361\n",
      " Add image --->  362\n",
      " Add image --->  363\n",
      " Add image --->  364\n",
      " Add image --->  365\n",
      " Add image --->  366\n",
      " Add image --->  367\n",
      " Add image --->  368\n",
      " Add image --->  369\n",
      " Add image --->  370\n",
      " Add image --->  371\n",
      " Add image --->  372\n",
      " Add image --->  373\n",
      " Add image --->  374\n",
      " Add image --->  375\n",
      " Add image --->  376\n",
      " Add image --->  377\n",
      " Add image --->  378\n",
      " Add image --->  379\n",
      " Add image --->  380\n",
      " Add image --->  381\n",
      " Add image --->  382\n",
      " Add image --->  383\n",
      " Add image --->  384\n",
      " Add image --->  385\n",
      " Add image --->  386\n",
      " Add image --->  387\n",
      " Add image --->  388\n",
      " Add image --->  389\n",
      " Add image --->  390\n",
      " Add image --->  391\n",
      " Add image --->  392\n",
      " Add image --->  393\n",
      " Add image --->  394\n",
      " Add image --->  395\n",
      " !!!!!!  Zero Mask Found !!!!!!\n",
      " ===> Find Hidden Shapes() found hidden objects \n",
      "[ ('sun', (192, 94, 95), (82, 11, 5, 5)),\n",
      "  ('tree', (26, 61, 134), (48, 65, 13, 13)),\n",
      "  ('building', (152, 221, 87), (43, 73, 17, 24)),\n",
      "  ('person', (82, 65, 141), (41, 89, 4, 20)),\n",
      "  ('person', (127, 26, 180), (87, 90, 4, 21)),\n",
      "  ('person', (239, 50, 152), (60, 95, 4, 22))]\n",
      " ****** Objects completely hidden are :  [1]\n",
      "('tree', (26, 61, 134), (48, 65, 13, 13))\n",
      "( 395 ) ------ shapes after removeal of totally hidden shapes ------\n",
      "[ ('sun', (192, 94, 95), (82, 11, 5, 5)),\n",
      "  ('building', (152, 221, 87), (43, 73, 17, 24)),\n",
      "  ('person', (82, 65, 141), (41, 89, 4, 20)),\n",
      "  ('person', (127, 26, 180), (87, 90, 4, 21)),\n",
      "  ('person', (239, 50, 152), (60, 95, 4, 22))]\n",
      "    Number of shapes now is :  5\n",
      " Add image --->  396\n",
      " Add image --->  397\n",
      " Add image --->  398\n",
      " Add image --->  399\n",
      " Add image --->  400\n",
      " Add image --->  401\n",
      " Add image --->  402\n",
      " Add image --->  403\n",
      " Add image --->  404\n",
      " Add image --->  405\n",
      " Add image --->  406\n",
      " Add image --->  407\n",
      " Add image --->  408\n",
      " Add image --->  409\n",
      " Add image --->  410\n",
      " Add image --->  411\n",
      " Add image --->  412\n",
      " Add image --->  413\n",
      " Add image --->  414\n",
      " Add image --->  415\n",
      " Add image --->  416\n",
      " Add image --->  417\n",
      " Add image --->  418\n",
      " Add image --->  419\n",
      " Add image --->  420\n",
      " Add image --->  421\n",
      " Add image --->  422\n",
      " Add image --->  423\n",
      " Add image --->  424\n",
      " Add image --->  425\n",
      " Add image --->  426\n",
      " Add image --->  427\n",
      " Add image --->  428\n",
      " Add image --->  429\n",
      " Add image --->  430\n",
      " Add image --->  431\n",
      " Add image --->  432\n",
      " Add image --->  433\n",
      " Add image --->  434\n",
      " Add image --->  435\n",
      " Add image --->  436\n",
      " Add image --->  437\n",
      " Add image --->  438\n",
      " Add image --->  439\n",
      " Add image --->  440\n",
      " Add image --->  441\n",
      " !!!!!!  Zero Mask Found !!!!!!\n",
      " ===> Find Hidden Shapes() found hidden objects \n",
      "[ ('sun', (187, 135, 208), (74, 15, 6, 6)),\n",
      "  ('person', (185, 45, 206), (29, 70, 3, 16)),\n",
      "  ('building', (249, 107, 86), (43, 75, 17, 25)),\n",
      "  ('building', (78, 67, 246), (31, 80, 18, 27)),\n",
      "  ('person', (9, 143, 34), (43, 81, 3, 18)),\n",
      "  ('tree', (123, 235, 7), (81, 102, 22, 22)),\n",
      "  ('person', (63, 72, 128), (22, 105, 4, 24))]\n",
      " ****** Objects completely hidden are :  [1]\n",
      "('person', (185, 45, 206), (29, 70, 3, 16))\n",
      "( 441 ) ------ shapes after removeal of totally hidden shapes ------\n",
      "[ ('sun', (187, 135, 208), (74, 15, 6, 6)),\n",
      "  ('building', (249, 107, 86), (43, 75, 17, 25)),\n",
      "  ('building', (78, 67, 246), (31, 80, 18, 27)),\n",
      "  ('person', (9, 143, 34), (43, 81, 3, 18)),\n",
      "  ('tree', (123, 235, 7), (81, 102, 22, 22)),\n",
      "  ('person', (63, 72, 128), (22, 105, 4, 24))]\n",
      "    Number of shapes now is :  6\n",
      " Add image --->  442\n",
      " Add image --->  443\n",
      " !!!!!!  Zero Mask Found !!!!!!\n",
      " ===> Find Hidden Shapes() found hidden objects \n",
      "[ ('sun', (17, 241, 109), (42, 6, 4, 4)),\n",
      "  ('car', (249, 222, 101), (100, 65, 15, 7)),\n",
      "  ('building', (204, 196, 209), (104, 85, 20, 30)),\n",
      "  ('person', (171, 93, 89), (41, 87, 4, 20))]\n",
      " ****** Objects completely hidden are :  [1]\n",
      "('car', (249, 222, 101), (100, 65, 15, 7))\n",
      "( 443 ) ------ shapes after removeal of totally hidden shapes ------\n",
      "[ ('sun', (17, 241, 109), (42, 6, 4, 4)),\n",
      "  ('building', (204, 196, 209), (104, 85, 20, 30)),\n",
      "  ('person', (171, 93, 89), (41, 87, 4, 20))]\n",
      "    Number of shapes now is :  3\n",
      " Add image --->  444\n",
      " Add image --->  445\n",
      " Add image --->  446\n",
      " Add image --->  447\n",
      " !!!!!!  Zero Mask Found !!!!!!\n",
      " ===> Find Hidden Shapes() found hidden objects \n",
      "[ ('sun', (13, 184, 185), (28, 22, 9, 9)),\n",
      "  ('tree', (79, 159, 33), (75, 61, 12, 12)),\n",
      "  ('tree', (1, 92, 10), (51, 67, 14, 14)),\n",
      "  ('building', (132, 82, 77), (50, 79, 18, 27)),\n",
      "  ('car', (213, 76, 141), (74, 82, 21, 10)),\n",
      "  ('car', (218, 252, 8), (49, 88, 23, 11))]\n",
      " ****** Objects completely hidden are :  [2]\n",
      "('tree', (1, 92, 10), (51, 67, 14, 14))\n",
      "( 447 ) ------ shapes after removeal of totally hidden shapes ------\n",
      "[ ('sun', (13, 184, 185), (28, 22, 9, 9)),\n",
      "  ('tree', (79, 159, 33), (75, 61, 12, 12)),\n",
      "  ('building', (132, 82, 77), (50, 79, 18, 27)),\n",
      "  ('car', (213, 76, 141), (74, 82, 21, 10)),\n",
      "  ('car', (218, 252, 8), (49, 88, 23, 11))]\n",
      "    Number of shapes now is :  5\n",
      " Add image --->  448\n",
      " !!!!!!  Zero Mask Found !!!!!!\n",
      " ===> Find Hidden Shapes() found hidden objects \n",
      "[ ('tree', (26, 7, 248), (62, 46, 8, 8)),\n",
      "  ('building', (83, 72, 213), (79, 61, 14, 18)),\n",
      "  ('building', (71, 212, 56), (80, 61, 14, 18)),\n",
      "  ('building', (112, 98, 135), (72, 62, 14, 19)),\n",
      "  ('tree', (145, 79, 233), (37, 72, 15, 15)),\n",
      "  ('building', (74, 192, 218), (66, 79, 18, 27))]\n",
      " ****** Objects completely hidden are :  [1]\n",
      "('building', (83, 72, 213), (79, 61, 14, 18))\n",
      "( 448 ) ------ shapes after removeal of totally hidden shapes ------\n",
      "[ ('tree', (26, 7, 248), (62, 46, 8, 8)),\n",
      "  ('building', (71, 212, 56), (80, 61, 14, 18)),\n",
      "  ('building', (112, 98, 135), (72, 62, 14, 19)),\n",
      "  ('tree', (145, 79, 233), (37, 72, 15, 15)),\n",
      "  ('building', (74, 192, 218), (66, 79, 18, 27))]\n",
      "    Number of shapes now is :  5\n",
      " Add image --->  449\n",
      " Add image --->  450\n",
      " Add image --->  451\n",
      " Add image --->  452\n",
      " Add image --->  453\n",
      " Add image --->  454\n",
      " Add image --->  455\n",
      " Add image --->  456\n",
      " Add image --->  457\n",
      " Add image --->  458\n",
      " Add image --->  459\n",
      " Add image --->  460\n",
      " Add image --->  461\n",
      " Add image --->  462\n",
      " Add image --->  463\n",
      " Add image --->  464\n",
      " Add image --->  465\n",
      " Add image --->  466\n",
      " Add image --->  467\n",
      " Add image --->  468\n",
      " Add image --->  469\n",
      " Add image --->  470\n",
      " Add image --->  471\n",
      " Add image --->  472\n",
      " Add image --->  473\n",
      " Add image --->  474\n",
      " Add image --->  475\n",
      " Add image --->  476\n",
      " Add image --->  477\n",
      " Add image --->  478\n",
      " Add image --->  479\n",
      " Add image --->  480\n",
      " Add image --->  481\n",
      " Add image --->  482\n",
      " Add image --->  483\n",
      " Add image --->  484\n",
      " Add image --->  485\n",
      " Add image --->  486\n",
      " Add image --->  487\n",
      " Add image --->  488\n",
      " Add image --->  489\n",
      " Add image --->  490\n",
      " Add image --->  491\n",
      " Add image --->  492\n",
      " Add image --->  493\n",
      " Add image --->  494\n",
      " !!!!!!  Zero Mask Found !!!!!!\n",
      " ===> Find Hidden Shapes() found hidden objects \n",
      "[ ('tree', (255, 209, 51), (90, 55, 11, 11)),\n",
      "  ('tree', (161, 10, 157), (86, 78, 16, 16)),\n",
      "  ('car', (199, 182, 100), (97, 82, 21, 10)),\n",
      "  ('building', (218, 184, 250), (92, 82, 19, 28)),\n",
      "  ('person', (112, 79, 251), (74, 90, 4, 21)),\n",
      "  ('person', (194, 140, 211), (70, 91, 4, 21))]\n",
      " ****** Objects completely hidden are :  [1]\n",
      "('tree', (161, 10, 157), (86, 78, 16, 16))\n",
      "( 494 ) ------ shapes after removeal of totally hidden shapes ------\n",
      "[ ('tree', (255, 209, 51), (90, 55, 11, 11)),\n",
      "  ('car', (199, 182, 100), (97, 82, 21, 10)),\n",
      "  ('building', (218, 184, 250), (92, 82, 19, 28)),\n",
      "  ('person', (112, 79, 251), (74, 90, 4, 21)),\n",
      "  ('person', (194, 140, 211), (70, 91, 4, 21))]\n",
      "    Number of shapes now is :  5\n",
      " Add image --->  495\n",
      " Add image --->  496\n",
      " Add image --->  497\n",
      " Add image --->  498\n",
      " Add image --->  499\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pprint\n",
    "import keras.backend as KB\n",
    "sys.path.append('../')\n",
    "\n",
    "import mrcnn.model        as modellib\n",
    "import mrcnn.visualize    as visualize\n",
    "# import mrcnn.new_shapes   as shapes\n",
    "import mrcnn.new_shapes  as new_shapes\n",
    "# from mrcnn.new_shapes  import NewShapesDataset, NewShapesConfig\n",
    "from mrcnn.config      import Config\n",
    "from mrcnn.model       import log\n",
    "from mrcnn.dataset     import Dataset \n",
    "# from mrcnn.pc_prototype import PCTensor\n",
    "# from mrcnn.pcn_layer    import PCNLayer, PCILayer\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "MODEL_PATH = 'E:\\Models'\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(MODEL_PATH, \"mrcnn_logs\")\n",
    "# Path to COCO trained weights\n",
    "COCO_MODEL_PATH   = os.path.join(MODEL_PATH, \"mask_rcnn_coco.h5\")\n",
    "RESNET_MODEL_PATH = os.path.join(MODEL_PATH, \"resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n",
    "\n",
    "print(\"Tensorflow Version: {}   Keras Version : {} \".format(tf.__version__,keras.__version__))\n",
    "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
    "np.set_printoptions(linewidth=100)\n",
    "\n",
    "# Build configuration object -----------------------------------------------\n",
    "config = new_shapes.NewShapesConfig()\n",
    "config.BATCH_SIZE      = 2                    #Batch size is 2 (# GPUs * images/GPU).\n",
    "config.IMAGES_PER_GPU  = 2\n",
    "config.STEPS_PER_EPOCH = 7\n",
    "config.IMAGES_PER_GPU  = 1\n",
    "config.display() \n",
    "\n",
    "# Build shape dataset        -----------------------------------------------\n",
    "\n",
    "# from mrcnn.datagen import data_generator, load_image_gt\n",
    "\n",
    "# Training dataset generate 500 shapes \n",
    "dataset_test = new_shapes.NewShapesDataset()\n",
    "dataset_test.load_shapes(500, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_test.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "# dataset_val = shapes.NewShapesDataset()\n",
    "# dataset_val.load_shapes(50, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "# dataset_val.prepare()\n",
    "\n",
    "# Load and display random samples\n",
    "# image_ids = np.random.choice(dataset_train.image_ids, 3)\n",
    "# for image_id in [3]:\n",
    "#     image = dataset_train.load_image(image_id)\n",
    "#     mask, class_ids = dataset_train.load_mask(image_id)\n",
    "#     visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T10:33:05.652328Z",
     "start_time": "2018-05-10T10:33:05.440736Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T10:33:07.648444Z",
     "start_time": "2018-05-10T10:33:07.431870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Initialize config object - super\n",
      "(56, 56)\n",
      "\n",
      "Configuration Parameters:\n",
      "-------------------------\n",
      "BACKBONE_SHAPES                [[32 32]\n",
      " [16 16]\n",
      " [ 8  8]\n",
      " [ 4  4]\n",
      " [ 2  2]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "EPOCHS_TO_RUN                  0\n",
      "FCN_INPUT_SHAPE                [128 128]\n",
      "GPU_COUNT                      1\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [128 128   3]\n",
      "LAST_EPOCH_RAN                 0\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           shapes\n",
      "NUM_CLASSES                    7\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                100\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class InferenceConfig(new_shapes.NewShapesConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "inference_config.display() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T10:36:10.370835Z",
     "start_time": "2018-05-10T10:36:05.638246Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    set_log_dir: Checkpoint path set to : E:\\Models\\mrcnn_logs\\shapes20180510T1236\\mask_rcnn_shapes_{epoch:04d}.h5\n",
      "    set_log_dir: self.epoch set to 0 \n",
      "\n",
      ">>> Resnet Graph \n",
      "     Input_image shape : (?, 128, 128, 3)\n",
      "     After ZeroPadding2D  : (?, 134, 134, 3) (?, 134, 134, 3)\n",
      "     After Conv2D padding : (?, 64, 64, 64) (?, 64, 64, 64)\n",
      "     After BatchNorm      : (?, 64, 64, 64) (?, 64, 64, 64)\n",
      "     After MaxPooling2D   : (?, 32, 32, 64) (?, 32, 32, 64)\n",
      "\n",
      ">>> Feature Pyramid Network (FPN) Graph \n",
      "     FPN P2 shape : (None, 32, 32, 256)\n",
      "     FPN P3 shape : (None, 16, 16, 256)\n",
      "     FPN P4 shape : (None, 8, 8, 256)\n",
      "     FPN P5 shape : (None, 4, 4, 256)\n",
      "     FPN P6 shape : (None, 2, 2, 256)\n",
      "\n",
      ">>> RPN Layer \n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     depth                   : 256\n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     anchor_stride           : 1\n",
      "\n",
      ">>> RPN Outputs  <class 'list'>\n",
      "      rpn_class_logits/concat:0\n",
      "      rpn_class/concat:0\n",
      "      rpn_bbox/concat:0\n",
      "\n",
      ">>> Proposal Layer - generate  1000  proposals\n",
      "    Init complete. Size of anchors:  (4092, 4)\n",
      "     Scores :  (1, 4092)\n",
      "     Deltas :  (1, 4092, 4)\n",
      "     Anchors:  (1, 4092, 4)\n",
      "     Boxes shape / type after processing:  (1, 4092, 4) <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "     Output: Prposals shape :  (1, ?, ?) (1, None, None)\n",
      "\n",
      ">>> FPN Classifier Graph \n",
      "     rois shape          : (1, ?, ?)\n",
      "     feature_maps : 4\n",
      "     feature_maps shape  : (?, 32, 32, 256)\n",
      "     feature_maps shape  : (?, 16, 16, 256)\n",
      "     feature_maps shape  : (?, 8, 8, 256)\n",
      "     feature_maps shape  : (?, 4, 4, 256)\n",
      "     input_shape         : [128 128   3]\n",
      "     pool_size           : 7\n",
      "\n",
      ">>> Detection Layer (Inference Mode)\n",
      "    Detection Layer : call()  <class 'list'> 4\n",
      "     rpn_proposals_roi  : (1, ?, ?)\n",
      "     mrcnn_class.shape  : (?, 1000, 7)\n",
      "     mrcnn_bboxes.shape : (?, 1000, 7, 4)\n",
      "     input_image_meta   : (?, ?)\n",
      "<<<  shape of DETECTIONS :  (None, 100, 6)  Keras tensor  True\n",
      "<<<  shape of DETECTION_BOXES :  (None, 100, 4)  Keras tensor  True\n",
      "\n",
      ">>> FPN Mask Graph \n",
      "     rois shape          : <unknown>\n",
      "     feature_maps : 4\n",
      "     feature_maps shape  : (?, 32, 32, 256)\n",
      "     feature_maps shape  : (?, 16, 16, 256)\n",
      "     feature_maps shape  : (?, 8, 8, 256)\n",
      "     feature_maps shape  : (?, 4, 4, 256)\n",
      "     input_shape         : [128 128   3]\n",
      "     pool_size           : 14\n",
      "     FPN Mask Graph output shape : (?, 100, 28, 28, 7)\n",
      "\n",
      ">>> MaskRCNN build complete\n",
      ">>> MaskRCNN initialization complete\n"
     ]
    }
   ],
   "source": [
    "# Recreate the model in inference mode\n",
    "try :\n",
    "    del model\n",
    "    gc.collect()\n",
    "except: \n",
    "    pass\n",
    "KB.clear_session()\n",
    "\n",
    "\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T10:34:52.362026Z",
     "start_time": "2018-05-10T10:34:46.576685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " last weights file found: E:\\Models\\mrcnn_logs\\shapes20180509T1928\\mask_rcnn_shapes_2500.h5\n",
      " last weights to be used: E:\\Models\\mrcnn_logs\\shapes20180509T1928\\mask_rcnn_shapes_2192.h5\n",
      "Loading weights from  E:\\Models\\mrcnn_logs\\shapes20180509T1928\\mask_rcnn_shapes_2192.h5\n",
      ">>> load_weights()\n",
      "    load_weights: Loading weights from: E:\\Models\\mrcnn_logs\\shapes20180509T1928\\mask_rcnn_shapes_2192.h5\n",
      " layers to load \n",
      "----------------\n",
      ">layer 0 : name : input_image                               type: <keras.engine.topology.InputLayer object at 0x00000225A8EA9470>\n",
      ">layer 1 : name : zero_padding2d_1                          type: <keras.layers.convolutional.ZeroPadding2D object at 0x00000225A8EA9518>\n",
      ">layer 2 : name : conv1                                     type: <keras.layers.convolutional.Conv2D object at 0x00000225A8EA9BE0>\n",
      ">layer 3 : name : bn_conv1                                  type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000225A8EA95C0>\n",
      ">layer 4 : name : activation_1                              type: <keras.layers.core.Activation object at 0x00000225A8EA9E48>\n",
      ">layer 5 : name : max_pooling2d_1                           type: <keras.layers.pooling.MaxPooling2D object at 0x00000225A8EB9198>\n",
      ">layer 6 : name : res2a_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000225A8EC8CC0>\n",
      ">layer 7 : name : bn2a_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000225A8ED3CF8>\n",
      ">layer 8 : name : activation_2                              type: <keras.layers.core.Activation object at 0x00000225A8EDF630>\n",
      ">layer 9 : name : res2a_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000225A8F05978>\n",
      ">layer 10 : name : bn2a_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000225A8F2BAC8>\n",
      ">layer 11 : name : activation_3                              type: <keras.layers.core.Activation object at 0x00000225A8F5F8D0>\n",
      ">layer 12 : name : res2a_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000225A98C9DD8>\n",
      ">layer 13 : name : res2a_branch1                             type: <keras.layers.convolutional.Conv2D object at 0x00000225A98EDD68>\n",
      ">layer 14 : name : bn2a_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000225A98D7E10>\n",
      ">layer 15 : name : bn2a_branch1                              type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000225AA0B3EF0>\n",
      ">layer 16 : name : add_1                                     type: <keras.layers.merge.Add object at 0x00000225AA0C9B00>\n",
      ">layer 17 : name : res2a_out                                 type: <keras.layers.core.Activation object at 0x00000225AA10A6D8>\n",
      ">layer 18 : name : res2b_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000225AA10ABA8>\n",
      ">layer 19 : name : bn2b_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000225AA114828>\n",
      ">layer 20 : name : activation_4                              type: <keras.layers.core.Activation object at 0x00000225AA12DDA0>\n",
      ">layer 21 : name : res2b_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000225AA171710>\n",
      ">layer 22 : name : bn2b_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000225AA163240>\n",
      ">layer 23 : name : activation_5                              type: <keras.layers.core.Activation object at 0x00000225AA59B9B0>\n",
      ">layer 24 : name : res2b_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000225AA5B9588>\n",
      ">layer 25 : name : bn2b_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000225AA5AE3C8>\n",
      ">layer 26 : name : add_2                                     type: <keras.layers.merge.Add object at 0x00000225AA5F8F60>\n",
      ">layer 27 : name : res2b_out                                 type: <keras.layers.core.Activation object at 0x00000225AA620CF8>\n",
      ">layer 28 : name : res2c_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000225AA620C18>\n",
      ">layer 29 : name : bn2c_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000225AA62B898>\n",
      ">layer 30 : name : activation_6                              type: <keras.layers.core.Activation object at 0x00000225AA8EF7B8>\n",
      ">layer 31 : name : res2c_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000225AA8FED68>\n",
      ">layer 32 : name : bn2c_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000225AA925898>\n",
      ">layer 33 : name : activation_7                              type: <keras.layers.core.Activation object at 0x00000225AA957E10>\n",
      ">layer 34 : name : res2c_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000225AA975A20>\n",
      ">layer 35 : name : bn2c_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000225AA980AC8>\n",
      ">layer 36 : name : add_3                                     type: <keras.layers.merge.Add object at 0x00000225AC741E10>\n",
      ">layer 37 : name : res2c_out                                 type: <keras.layers.core.Activation object at 0x00000225AC75EA58>\n",
      ">layer 38 : name : res3a_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000225AC75EB70>\n",
      ">layer 39 : name : bn3a_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000225AC79CC18>\n",
      ">layer 40 : name : activation_8                              type: <keras.layers.core.Activation object at 0x00000225AC78EB70>\n",
      ">layer 41 : name : res3a_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000225AE3C4518>\n",
      ">layer 42 : name : bn3a_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000225AE3BA6A0>\n",
      ">layer 43 : name : activation_9                              type: <keras.layers.core.Activation object at 0x00000225AE403048>\n",
      ">layer 44 : name : res3a_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000225AEE20CF8>\n",
      ">layer 45 : name : res3a_branch1                             type: <keras.layers.convolutional.Conv2D object at 0x00000225AEE446D8>\n",
      ">layer 46 : name : bn3a_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000225AEE2F9B0>\n",
      ">layer 47 : name : bn3a_branch1                              type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000225AEE6AB38>\n",
      ">layer 48 : name : add_4                                     type: <keras.layers.merge.Add object at 0x00000225AEEC4B70>\n",
      ">layer 49 : name : res3a_out                                 type: <keras.layers.core.Activation object at 0x00000225AEEA8978>\n",
      ">layer 50 : name : res3b_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000225AF8017F0>\n",
      ">layer 51 : name : bn3b_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000225AF80BC18>\n",
      ">layer 52 : name : activation_10                             type: <keras.layers.core.Activation object at 0x00000225AF824EB8>\n",
      ">layer 53 : name : res3b_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x00000225B2F3CD68>\n",
      ">layer 54 : name : bn3b_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000225B2F49828>\n",
      ">layer 55 : name : activation_11                             type: <keras.layers.core.Activation object at 0x00000225B3314AC8>\n",
      ">layer 56 : name : res3b_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x00000225B3332278>\n",
      ">layer 57 : name : bn3b_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000225B33264E0>\n",
      ">layer 58 : name : add_5                                     type: <keras.layers.merge.Add object at 0x00000225B336EFD0>\n",
      ">layer 59 : name : res3b_out                                 type: <keras.layers.core.Activation object at 0x00000225B338AC50>\n",
      ">layer 60 : name : res3c_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x00000225B338A8D0>\n",
      ">layer 61 : name : bn3c_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000225B33C58D0>\n",
      ">layer 62 : name : activation_12                             type: <keras.layers.core.Activation object at 0x00000225B33D7EF0>\n",
      ">layer 63 : name : res3c_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000022648BB2630>\n",
      ">layer 64 : name : bn3c_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000022648BBC550>\n",
      ">layer 65 : name : activation_13                             type: <keras.layers.core.Activation object at 0x0000022648BEFF28>\n",
      ">layer 66 : name : res3c_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000022648C24940>\n",
      ">layer 67 : name : bn3c_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000022648C17BE0>\n",
      ">layer 68 : name : add_6                                     type: <keras.layers.merge.Add object at 0x0000022648C49780>\n",
      ">layer 69 : name : res3c_out                                 type: <keras.layers.core.Activation object at 0x0000022648C75CC0>\n",
      ">layer 70 : name : res3d_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x0000022648C590B8>\n",
      ">layer 71 : name : bn3d_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000022648CA5D30>\n",
      ">layer 72 : name : activation_14                             type: <keras.layers.core.Activation object at 0x0000022648C98668>\n",
      ">layer 73 : name : res3d_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000022648D337F0>\n",
      ">layer 74 : name : bn3d_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000022648D28E48>\n",
      ">layer 75 : name : activation_15                             type: <keras.layers.core.Activation object at 0x0000022648D5BF28>\n",
      ">layer 76 : name : res3d_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000022648DC6C88>\n",
      ">layer 77 : name : bn3d_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000022648DC6FD0>\n",
      ">layer 78 : name : add_7                                     type: <keras.layers.merge.Add object at 0x0000022648DE8898>\n",
      ">layer 79 : name : res3d_out                                 type: <keras.layers.core.Activation object at 0x0000022648E2C9B0>\n",
      ">layer 80 : name : res4a_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x0000022648E2C780>\n",
      ">layer 81 : name : bn4a_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000022648E1E588>\n",
      ">layer 82 : name : activation_16                             type: <keras.layers.core.Activation object at 0x0000022648E83BE0>\n",
      ">layer 83 : name : res4a_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x0000022648ECFBE0>\n",
      ">layer 84 : name : bn4a_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000022648EC8D68>\n",
      ">layer 85 : name : activation_17                             type: <keras.layers.core.Activation object at 0x0000022648EDE5F8>\n",
      ">layer 86 : name : res4a_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x0000022648F2CF98>\n",
      ">layer 87 : name : res4a_branch1                             type: <keras.layers.convolutional.Conv2D object at 0x0000022648F5FDD8>\n",
      ">layer 88 : name : bn4a_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x0000022648F21FD0>\n",
      ">layer 89 : name : bn4a_branch1                              type: <mrcnn.batchnorm_layer.BatchNorm object at 0x00000226490F7A90>\n",
      ">layer 90 : name : add_8                                     type: <keras.layers.merge.Add object at 0x000002264911CA90>\n",
      ">layer 91 : name : res4a_out                                 type: <keras.layers.core.Activation object at 0x0000022649111DD8>\n",
      ">layer 92 : name : res4b_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x000002264915EAC8>\n",
      ">layer 93 : name : bn4b_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x000002265D6C29E8>\n",
      ">layer 94 : name : activation_18                             type: <keras.layers.core.Activation object at 0x000002265D6CFE10>\n",
      ">layer 95 : name : res4b_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x000002265D6EB278>\n",
      ">layer 96 : name : bn4b_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x000002265D6E15C0>\n",
      ">layer 97 : name : activation_19                             type: <keras.layers.core.Activation object at 0x000002265D72ADA0>\n",
      ">layer 98 : name : res4b_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x000002265D75E978>\n",
      ">layer 99 : name : bn4b_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x000002265D754CF8>\n",
      ">layer 100 : name : add_9                                     type: <keras.layers.merge.Add object at 0x000002265D76A1D0>\n",
      ">layer 101 : name : res4b_out                                 type: <keras.layers.core.Activation object at 0x000002265D7AF080>\n",
      ">layer 102 : name : res4c_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x000002265D7AF908>\n",
      ">layer 103 : name : bn4c_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x000002265D7B8BA8>\n",
      ">layer 104 : name : activation_20                             type: <keras.layers.core.Activation object at 0x000002265D7D1F60>\n",
      ">layer 105 : name : res4c_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x000002265D806748>\n",
      ">layer 106 : name : bn4c_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x000002265D813F60>\n",
      ">layer 107 : name : activation_21                             type: <keras.layers.core.Activation object at 0x000002265D843748>\n",
      ">layer 108 : name : res4c_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x000002265D862278>\n",
      ">layer 109 : name : bn4c_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x000002265D8625F8>\n",
      ">layer 110 : name : add_10                                    type: <keras.layers.merge.Add object at 0x000002265D8AAA90>\n",
      ">layer 111 : name : res4c_out                                 type: <keras.layers.core.Activation object at 0x000002265D8D49E8>\n",
      ">layer 112 : name : res4d_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x000002265D8D48D0>\n",
      ">layer 113 : name : bn4d_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x000002265D8C8C18>\n",
      ">layer 114 : name : activation_22                             type: <keras.layers.core.Activation object at 0x000002265D8ECCF8>\n",
      ">layer 115 : name : res4d_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x000002265D92FF60>\n",
      ">layer 116 : name : bn4d_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x000002265D92FC88>\n",
      ">layer 117 : name : activation_23                             type: <keras.layers.core.Activation object at 0x000002265D953F28>\n",
      ">layer 118 : name : res4d_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x000002265D96DC18>\n",
      ">layer 119 : name : bn4d_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x000002265D980358>\n",
      ">layer 120 : name : add_11                                    type: <keras.layers.merge.Add object at 0x000002265D9C8EF0>\n",
      ">layer 121 : name : res4d_out                                 type: <keras.layers.core.Activation object at 0x000002265D9EFB70>\n",
      ">layer 122 : name : res4e_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x000002265D9EFBA8>\n",
      ">layer 123 : name : bn4e_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x000002265D9FB908>\n",
      ">layer 124 : name : activation_24                             type: <keras.layers.core.Activation object at 0x000002265DA21748>\n",
      ">layer 125 : name : res4e_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x000002266AC42E48>\n",
      ">layer 126 : name : bn4e_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x000002266AC507F0>\n",
      ">layer 127 : name : activation_25                             type: <keras.layers.core.Activation object at 0x000002266AC97DA0>\n",
      ">layer 128 : name : res4e_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x000002266ACB5550>\n",
      ">layer 129 : name : bn4e_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x000002266ACA97B8>\n",
      ">layer 130 : name : add_12                                    type: <keras.layers.merge.Add object at 0x000002266ACF3DA0>\n",
      ">layer 131 : name : res4e_out                                 type: <keras.layers.core.Activation object at 0x000002266BCEDF60>\n",
      ">layer 132 : name : res4f_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x000002266BCEDBE0>\n",
      ">layer 133 : name : bn4f_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x000002266BD1BBA8>\n",
      ">layer 134 : name : activation_26                             type: <keras.layers.core.Activation object at 0x000002266BD10860>\n",
      ">layer 135 : name : res4f_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x000002266BD44F28>\n",
      ">layer 136 : name : bn4f_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x000002266BD3B630>\n",
      ">layer 137 : name : activation_27                             type: <keras.layers.core.Activation object at 0x000002266BD84940>\n",
      ">layer 138 : name : res4f_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x000002266BDA1898>\n",
      ">layer 139 : name : bn4f_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x000002266BDAFEB8>\n",
      ">layer 140 : name : add_13                                    type: <keras.layers.merge.Add object at 0x000002266BDC3400>\n",
      ">layer 141 : name : res4f_out                                 type: <keras.layers.core.Activation object at 0x000002266BE11828>\n",
      ">layer 142 : name : res5a_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x000002266BE112B0>\n",
      ">layer 143 : name : bn5a_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x000002266BE11358>\n",
      ">layer 144 : name : activation_28                             type: <keras.layers.core.Activation object at 0x000002266BE2AA58>\n",
      ">layer 145 : name : res5a_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x000002266BE79A58>\n",
      ">layer 146 : name : bn5a_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x000002266BE6FE80>\n",
      ">layer 147 : name : activation_29                             type: <keras.layers.core.Activation object at 0x000002266BE86240>\n",
      ">layer 148 : name : res5a_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x000002266BECC978>\n",
      ">layer 149 : name : res5a_branch1                             type: <keras.layers.convolutional.Conv2D object at 0x000002266BF06C50>\n",
      ">layer 150 : name : bn5a_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x000002266BEADE10>\n",
      ">layer 151 : name : bn5a_branch1                              type: <mrcnn.batchnorm_layer.BatchNorm object at 0x000002266BF2EC88>\n",
      ">layer 152 : name : add_14                                    type: <keras.layers.merge.Add object at 0x000002266BF53908>\n",
      ">layer 153 : name : res5a_out                                 type: <keras.layers.core.Activation object at 0x000002266BF61940>\n",
      ">layer 154 : name : res5b_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x000002266BF61860>\n",
      ">layer 155 : name : bn5b_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x000002266BFAFE10>\n",
      ">layer 156 : name : activation_30                             type: <keras.layers.core.Activation object at 0x000002266BFA2B00>\n",
      ">layer 157 : name : res5b_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x000002266BFC8CC0>\n",
      ">layer 158 : name : bn5b_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x000002266BFD82E8>\n",
      ">layer 159 : name : activation_31                             type: <keras.layers.core.Activation object at 0x000002266C022EB8>\n",
      ">layer 160 : name : res5b_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x000002266C03C668>\n",
      ">layer 161 : name : bn5b_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x000002266C049B70>\n",
      ">layer 162 : name : add_15                                    type: <keras.layers.merge.Add object at 0x000002266C07A588>\n",
      ">layer 163 : name : res5b_out                                 type: <keras.layers.core.Activation object at 0x000002266C098240>\n",
      ">layer 164 : name : res5c_branch2a                            type: <keras.layers.convolutional.Conv2D object at 0x000002266C098B00>\n",
      ">layer 165 : name : bn5c_branch2a                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x000002266C0D7CC0>\n",
      ">layer 166 : name : activation_32                             type: <keras.layers.core.Activation object at 0x000002266C0CAA90>\n",
      ">layer 167 : name : res5c_branch2b                            type: <keras.layers.convolutional.Conv2D object at 0x000002266C0FF5C0>\n",
      ">layer 168 : name : bn5c_branch2b                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x000002266C0F4748>\n",
      ">layer 169 : name : activation_33                             type: <keras.layers.core.Activation object at 0x000002266C13CC50>\n",
      ">layer 170 : name : res5c_branch2c                            type: <keras.layers.convolutional.Conv2D object at 0x000002266C157D30>\n",
      ">layer 171 : name : bn5c_branch2c                             type: <mrcnn.batchnorm_layer.BatchNorm object at 0x000002266C165C50>\n",
      ">layer 172 : name : add_16                                    type: <keras.layers.merge.Add object at 0x000002266C17D780>\n",
      ">layer 173 : name : res5c_out                                 type: <keras.layers.core.Activation object at 0x000002266C1A1F98>\n",
      ">layer 174 : name : fpn_c5p5                                  type: <keras.layers.convolutional.Conv2D object at 0x000002266C1A1BE0>\n",
      ">layer 175 : name : fpn_p5upsampled                           type: <keras.layers.convolutional.UpSampling2D object at 0x000002266C1E3AC8>\n",
      ">layer 176 : name : fpn_c4p4                                  type: <keras.layers.convolutional.Conv2D object at 0x000002266C1E3B70>\n",
      ">layer 177 : name : fpn_p4add                                 type: <keras.layers.merge.Add object at 0x000002266C1CCE80>\n",
      ">layer 178 : name : fpn_p4upsampled                           type: <keras.layers.convolutional.UpSampling2D object at 0x000002266C23DC50>\n",
      ">layer 179 : name : fpn_c3p3                                  type: <keras.layers.convolutional.Conv2D object at 0x000002266C20D748>\n",
      ">layer 180 : name : fpn_p3add                                 type: <keras.layers.merge.Add object at 0x000002266C227E10>\n",
      ">layer 181 : name : fpn_p3upsampled                           type: <keras.layers.convolutional.UpSampling2D object at 0x000002266C24B5C0>\n",
      ">layer 182 : name : fpn_c2p2                                  type: <keras.layers.convolutional.Conv2D object at 0x000002266C24B6D8>\n",
      ">layer 183 : name : fpn_p2add                                 type: <keras.layers.merge.Add object at 0x000002266C259400>\n",
      ">layer 184 : name : fpn_p5                                    type: <keras.layers.convolutional.Conv2D object at 0x000002266C2EB8D0>\n",
      ">layer 185 : name : fpn_p2                                    type: <keras.layers.convolutional.Conv2D object at 0x000002266C29F5F8>\n",
      ">layer 186 : name : fpn_p3                                    type: <keras.layers.convolutional.Conv2D object at 0x000002266C296DD8>\n",
      ">layer 187 : name : fpn_p4                                    type: <keras.layers.convolutional.Conv2D object at 0x000002266C2BBE10>\n",
      ">layer 188 : name : fpn_p6                                    type: <keras.layers.pooling.MaxPooling2D object at 0x000002266C33EDD8>\n",
      ">layer 189 : name : rpn_model                                 type: <keras.engine.training.Model object at 0x0000022648FB7630>\n",
      ">layer 190 : name : rpn_class                                 type: <keras.layers.merge.Concatenate object at 0x00000225A7700470>\n",
      ">layer 191 : name : rpn_bbox                                  type: <keras.layers.merge.Concatenate object at 0x00000225A776F898>\n",
      ">layer 192 : name : rpn_proposal_rois                         type: <mrcnn.proposal_layer.ProposalLayer object at 0x000002264851F908>\n",
      ">layer 193 : name : roi_align_classifier                      type: <mrcnn.roialign_layer.PyramidROIAlign object at 0x00000226473EAC50>\n",
      ">layer 194 : name : mrcnn_class_conv1                         type: <keras.layers.wrappers.TimeDistributed object at 0x000002264723CD30>\n",
      ">layer 195 : name : mrcnn_class_bn1                           type: <keras.layers.wrappers.TimeDistributed object at 0x00000226472230F0>\n",
      ">layer 196 : name : activation_34                             type: <keras.layers.core.Activation object at 0x000002264722F7F0>\n",
      ">layer 197 : name : mrcnn_class_conv2                         type: <keras.layers.wrappers.TimeDistributed object at 0x000002264720DCF8>\n",
      ">layer 198 : name : mrcnn_class_bn2                           type: <keras.layers.wrappers.TimeDistributed object at 0x00000226471CD8D0>\n",
      ">layer 199 : name : activation_35                             type: <keras.layers.core.Activation object at 0x000002264741B400>\n",
      ">layer 200 : name : pool_squeeze                              type: <keras.layers.core.Lambda object at 0x00000226471E34E0>\n",
      ">layer 201 : name : mrcnn_class_logits                        type: <keras.layers.wrappers.TimeDistributed object at 0x00000226471B7668>\n",
      ">layer 202 : name : mrcnn_bbox_fc                             type: <keras.layers.wrappers.TimeDistributed object at 0x0000022647182390>\n",
      ">layer 203 : name : mrcnn_class                               type: <keras.layers.wrappers.TimeDistributed object at 0x00000226471BFD68>\n",
      ">layer 204 : name : mrcnn_bbox                                type: <keras.layers.core.Reshape object at 0x0000022647182550>\n",
      ">layer 205 : name : input_image_meta                          type: <keras.engine.topology.InputLayer object at 0x00000225A8EA95F8>\n",
      ">layer 206 : name : mrcnn_detection                           type: <mrcnn.detect_layer.DetectionLayer object at 0x00000226471945C0>\n",
      ">layer 207 : name : lambda_3                                  type: <keras.layers.core.Lambda object at 0x0000022647194C88>\n",
      ">layer 208 : name : roi_align_mask                            type: <mrcnn.roialign_layer.PyramidROIAlign object at 0x000002264716DDA0>\n",
      ">layer 209 : name : mrcnn_mask_conv1                          type: <keras.layers.wrappers.TimeDistributed object at 0x00000226470E0A90>\n",
      ">layer 210 : name : mrcnn_mask_bn1                            type: <keras.layers.wrappers.TimeDistributed object at 0x000002264709AF28>\n",
      ">layer 211 : name : activation_37                             type: <keras.layers.core.Activation object at 0x0000022647083128>\n",
      ">layer 212 : name : mrcnn_mask_conv2                          type: <keras.layers.wrappers.TimeDistributed object at 0x00000226471636A0>\n",
      ">layer 213 : name : mrcnn_mask_bn2                            type: <keras.layers.wrappers.TimeDistributed object at 0x0000022647030198>\n",
      ">layer 214 : name : activation_38                             type: <keras.layers.core.Activation object at 0x0000022647039588>\n",
      ">layer 215 : name : mrcnn_mask_conv3                          type: <keras.layers.wrappers.TimeDistributed object at 0x0000022647046B00>\n",
      ">layer 216 : name : mrcnn_mask_bn3                            type: <keras.layers.wrappers.TimeDistributed object at 0x00000226470219E8>\n",
      ">layer 217 : name : activation_39                             type: <keras.layers.core.Activation object at 0x0000022646FE36A0>\n",
      ">layer 218 : name : mrcnn_mask_conv4                          type: <keras.layers.wrappers.TimeDistributed object at 0x0000022646FDB8D0>\n",
      ">layer 219 : name : mrcnn_mask_bn4                            type: <keras.layers.wrappers.TimeDistributed object at 0x0000022646FA4B00>\n",
      ">layer 220 : name : activation_40                             type: <keras.layers.core.Activation object at 0x0000022646F9B780>\n",
      ">layer 221 : name : mrcnn_mask_deconv                         type: <keras.layers.wrappers.TimeDistributed object at 0x0000022646F90320>\n",
      ">layer 222 : name : mrcnn_mask                                type: <keras.layers.wrappers.TimeDistributed object at 0x0000022646FB3160>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    load_weights: Log directory set to : E:\\Models\\mrcnn_logs\\shapes20180509T1928\\mask_rcnn_shapes_2192.h5\n",
      "    set_log_dir: Checkpoint path set to : E:\\Models\\mrcnn_logs\\shapes20180509T1928\\mask_rcnn_shapes_{epoch:04d}.h5\n",
      "    set_log_dir: self.epoch set to 2193 \n",
      "    Load weights complete :  E:\\Models\\mrcnn_logs\\shapes20180509T1928\\mask_rcnn_shapes_2192.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'E:\\\\Models\\\\mrcnn_logs\\\\shapes20180509T1928\\\\mask_rcnn_shapes_2192.h5'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model_path = model.find_last()[1]\n",
    "print(' last weights file found:', model_path )\n",
    "model_path  = 'E:\\\\Models\\\\mrcnn_logs\\\\shapes20180509T1928\\\\mask_rcnn_shapes_2192.h5'\n",
    "print(' last weights to be used:', model_path )\n",
    "# Load trained weights (fill in path to trained weights here)\n",
    "assert model_path != \"\", \"Provide path to trained weights\"\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Print some information about the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T10:30:40.527077Z",
     "start_time": "2018-05-10T10:30:40.269505Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.compile_only(learning_rate=config.LEARNING_RATE, layers='heads')\n",
    "# print('\\n Metrics (_get_deduped_metrics_names():) ') \n",
    "# pp.pprint(mm._get_deduped_metrics_names())\n",
    "# print('\\n Losses (model.metrics_names): ') \n",
    "# pp.pprint(mm.metrics_names)\n",
    "KB.set_learning_phase(0)\n",
    "print(' Learning phase values is L ' ,KB.learning_phase())\n",
    "print('\\n Inputs: ') \n",
    "pp.pprint(model.keras_model.inputs)\n",
    "print('\\n Outputs: ') \n",
    "pp.pprint(model.keras_model.outputs)\n",
    "# print('\\Layers')\n",
    "# pp.pprint(model.keras_model.layers)\n",
    "# weights = model.keras_model.get_weights()\n",
    "# print(' Number of weights arrays: ',len(weights))\n",
    "print('\\n Weights: ') \n",
    "print('length of model.keras_model.weights', len(model.keras_model.weights))\n",
    "pp.pprint(model.keras_model.weights)\n",
    "# pp.pprint(dir(model.keras_model))\n",
    "print(model.keras_model.weights[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on a random image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T10:33:29.193117Z",
     "start_time": "2018-05-10T10:33:28.968610Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test on a random image\n",
    "# Validation dataset\n",
    "# dataset_val = shapes.ShapesDataset()\n",
    "# dataset_val.load_shapes(50, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "# dataset_val.prepare()\n",
    "from mrcnn.datagen import data_generator, load_image_gt\n",
    "image_id = random.choice(dataset_test.image_ids)\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    load_image_gt(dataset_test, inference_config, image_id, use_mini_mask=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T10:45:07.079399Z",
     "start_time": "2018-05-10T10:45:06.712923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Id : 146\n",
      "original_image           shape: (128, 128, 3)         min:    3.00000  max:  249.00000\n",
      "image_meta               shape: (15,)                 min:    0.00000  max:  146.00000\n",
      "[146 128 128   3   0   0 128 128   1   1   1   1   1   1   1]\n",
      "gt_class_id              shape: (4, 4)                min:    4.00000  max:  115.00000\n",
      "gt_bbox                  shape: (4, 4)                min:    4.00000  max:  115.00000\n",
      "gt_mask                  shape: (128, 128, 4)         min:    0.00000  max:    1.00000\n",
      " 1: person   2: car  3: sun  4: building  5: tree  6: cloud \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2266f6e47f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Image Id :', image_id)    \n",
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "print(image_meta)\n",
    "log(\"gt_class_id\", gt_bbox)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n",
    "print(\" 1: person   2: car  3: sun  4: building  5: tree  6: cloud \")\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                            dataset_test.class_names, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T10:39:59.930930Z",
     "start_time": "2018-05-10T10:39:59.099205Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 images\n",
      "image                    shape: (128, 128, 3)         min:    3.00000  max:  249.00000\n",
      "molded_images            shape: (1, 128, 128, 3)      min: -110.70000  max:  132.20000\n",
      "image_metas              shape: (1, 15)               min:    0.00000  max:  128.00000\n",
      "    Wrapper for Detection Layer : call()  <class 'list'> 4\n",
      "     rpn_proposals_roi  : (1, ?, ?) (1, 1000, 4) <class 'numpy.ndarray'>\n",
      "     mrcnn_class.shape  : (?, 1000, 7) (1, 1000, 7) <class 'numpy.ndarray'>\n",
      "     mrcnn_bboxes.shape : (?, 1000, 7, 4) (1, 1000, 7, 4) <class 'numpy.ndarray'>\n",
      "     image_meta         : (?, ?) (1, 15) <class 'numpy.ndarray'>\n",
      "       rois  : (1000, 4)\n",
      "      probs : (1000, 7)\n",
      "     deltas : (1000, 7, 4)\n",
      "     window : (4,)\n",
      "     window :: (4,) \n",
      " [  0.   0. 128. 128.]\n",
      " apply per class nms\n",
      "class_id :  1 pre_nms_rois.shape: (128, 4) pre_nms_scores.shape : (128,)\n",
      "class_id :  2 pre_nms_rois.shape: (90, 4) pre_nms_scores.shape : (90,)\n",
      "class_id :  5 pre_nms_rois.shape: (594, 4) pre_nms_scores.shape : (594,)\n",
      "class_id :  6 pre_nms_rois.shape: (1, 4) pre_nms_scores.shape : (1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\mrcnn\\utils.py:283: RuntimeWarning: invalid value encountered in true_divide\n",
      "  iou = intersection / union\n",
      "..\\mrcnn\\utils.py:343: RuntimeWarning: invalid value encountered in greater\n",
      "  remove_ixs = np.where(iou > threshold)[0] + 1\n"
     ]
    }
   ],
   "source": [
    "results = model.detect([original_image], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Simulation of `detect()` routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T21:08:38.958455Z",
     "start_time": "2018-05-09T21:08:38.670424Z"
    }
   },
   "outputs": [],
   "source": [
    "# print('>>> model detect()')\n",
    "verbose = 1\n",
    "images  = [original_image]\n",
    "assert model.mode   == \"inference\", \"Create model in inference mode.\"\n",
    "assert len(images) == model.config.BATCH_SIZE, \"len(images) must be equal to BATCH_SIZE\"\n",
    "\n",
    "if verbose:\n",
    "    log(\"Processing {} images\".format(len(images)))\n",
    "    for image in images:\n",
    "        log(\"image\", image)\n",
    "\n",
    "# Mold inputs to format expected by the neural network\n",
    "molded_images, image_metas, windows = model.mold_inputs(images)\n",
    "if verbose:\n",
    "    log(\"molded_images\", molded_images)\n",
    "    log(\"image_metas\"  , image_metas)\n",
    "\n",
    "## Run object detection pipeline\n",
    "# print('    call predict()')\n",
    "detections, rpn_rois, rpn_class, rpn_bbox,\\\n",
    "            mrcnn_class, mrcnn_bbox, mrcnn_mask \\\n",
    "                      =  model.keras_model.predict([molded_images, image_metas], verbose=0)\n",
    "\n",
    "print('    return from  predict()')\n",
    "print('    Length of detections : ', len(detections))\n",
    "print('    Length of rpn_rois   : ', len(rpn_rois   ))\n",
    "print('    Length of rpn_class  : ', len(rpn_class  ))\n",
    "print('    Length of rpn_bbox   : ', len(rpn_bbox   ))\n",
    "print('    Length of mrcnn_class: ', len(mrcnn_class))\n",
    "print('    Length of mrcnn_bbox : ', len(mrcnn_bbox ))\n",
    "print('    Length of mrcnn_mask : ', len(mrcnn_mask ))\n",
    "\n",
    "####  detection array layout is `[ y1, x1, y2, x2, class, score]`\n",
    "\n",
    "detections[0].shape\n",
    "print(detections[0])\n",
    "\n",
    "## Process detections\n",
    "results = []\n",
    "for i, image in enumerate(images):\n",
    "    final_rois, final_class_ids, final_scores, final_masks =\\\n",
    "        model.unmold_detections(detections[i], \n",
    "                               mrcnn_mask[i],\n",
    "                               image.shape  ,\n",
    "                               windows[i])\n",
    "    results.append({\n",
    "        \"rois\"     : final_rois,\n",
    "        \"class_ids\": final_class_ids,\n",
    "        \"scores\"   : final_scores,\n",
    "        \"masks\"    : final_masks,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T12:18:44.409946Z",
     "start_time": "2018-05-02T12:18:44.046503Z"
    }
   },
   "outputs": [],
   "source": [
    "r = results[0]\n",
    "print('  rois       : ', r['rois'])\n",
    "print('  masks      : ', r['masks'].shape)\n",
    "print('  class ids  : ', r['class_ids'])\n",
    "print('  class names: ', dataset_val.class_names)\n",
    "print('  scores     : ', r['scores'])\n",
    "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'], ax=get_ax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T12:23:46.071024Z",
     "start_time": "2018-05-02T12:23:33.887948Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute VOC-Style mAP @ IoU=0.5\n",
    "# Running on 10 images. Increase for better accuracy.\n",
    "from mrcnn.datagen     import data_generator, load_image_gt\n",
    "import  mrcnn.utils as utils \n",
    "\n",
    "image_ids = np.random.choice(dataset_val.image_ids, 75)\n",
    "APs = []\n",
    "for image_id in image_ids:\n",
    "    # Load image and ground truth data\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        load_image_gt(dataset_val, inference_config,\n",
    "                               image_id, use_mini_mask=False)\n",
    "    molded_images = np.expand_dims(utils.mold_image(image, inference_config), 0)\n",
    "    # Run object detection\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "    # Compute AP\n",
    "    AP, precisions, recalls, overlaps =\\\n",
    "        utils.compute_ap(gt_bbox, gt_class_id,\n",
    "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"])\n",
    "    APs.append(AP)\n",
    "    \n",
    "print(\"mAP: \", np.mean(APs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get next shapes from generator and display loaded shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "# Uncomment to save manually\n",
    "model_path = os.path.join(MODEL_DIR, \"mask_rcnn_shapes.h5\")\n",
    "model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras import backend as KB\n",
    "# if 'tensorflow' == KB.backend():\n",
    "#     import tensorflow as tf\n",
    "#     from keras.backend.tensorflow_backend import set_session\n",
    "#     # tfconfig = tf.ConfigProto(\n",
    "#         # gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.5),\n",
    "#         # device_count = {'GPU': 1}\n",
    "#     # )    \n",
    "#     tfconfig = tf.ConfigProto()\n",
    "#     tfconfig.gpu_options.allow_growth=True\n",
    "#     tfconfig.gpu_options.visible_device_list = \"0\"\n",
    "#     tfconfig.gpu_options.per_process_gpu_memory_fraction=0.5\n",
    "#     tf_sess = tf.Session(config=tfconfig)\n",
    "#     set_session(tf_sess)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:TF_gpu]",
   "language": "python",
   "name": "conda-env-TF_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
