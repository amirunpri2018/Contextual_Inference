{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "###  Simulate `build_gaussian_tf` function \n",
    "- Setup model, load weights and data generators \n",
    "- get items from data generator\n",
    "- pass through network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T13:40:41.370273Z",
     "start_time": "2018-05-05T13:40:40.993273Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Tensorflow Version: 1.6.0   Keras Version : 2.1.4 \n",
      " Initialize config object - super\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [1 0]\n",
      " starting ixs :  [1 0]  compare  1  with  [0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),)\n",
      " ending ixs :  [1 0]\n",
      " edning ixs (after deleing 0):  [0]  picked so far:  [1]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),)\n",
      " ending ixs :  [0]\n",
      " edning ixs (after deleing 0):  []  picked so far:  [1, 0]\n",
      "====> Final Picks:  [1, 0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [1 0]\n",
      " starting ixs :  [1 0]  compare  1  with  [0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),)\n",
      " ending ixs :  [1 0]\n",
      " edning ixs (after deleing 0):  [0]  picked so far:  [1]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),)\n",
      " ending ixs :  [0]\n",
      " edning ixs (after deleing 0):  []  picked so far:  [1, 0]\n",
      "====> Final Picks:  [1, 0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [2 1 0]\n",
      " starting ixs :  [2 1 0]  compare  2  with  [1 0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),)\n",
      " ending ixs :  [2 1 0]\n",
      " edning ixs (after deleing 0):  [1 0]  picked so far:  [2]\n",
      " starting ixs :  [1 0]  compare  1  with  [0]\n",
      " np.where( iou > threshold) :  (array([0], dtype=int64),)\n",
      " ending ixs :  [1]\n",
      " edning ixs (after deleing 0):  []  picked so far:  [2, 1]\n",
      "====> Final Picks:  [2, 1]\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import  gc\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import keras.backend as KB\n",
    "sys.path.append('../')\n",
    "\n",
    "import mrcnn.model     as modellib\n",
    "import mrcnn.visualize as visualize\n",
    "import mrcnn.shapes    as shapes\n",
    "from mrcnn.config      import Config\n",
    "from mrcnn.model       import log\n",
    "from mrcnn.dataset     import Dataset \n",
    "\n",
    "from mrcnn.utils       import stack_tensors, stack_tensors_3d\n",
    "from mrcnn.datagen     import data_generator, load_image_gt\n",
    "from mrcnn.callbacks   import get_layer_output_1,get_layer_output_2\n",
    "from mrcnn.visualize   import plot_gaussian\n",
    "# from mrcnn.pc_layer    import PCTensor\n",
    "# from mrcnn.pc_layer   import PCNLayer\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "MODEL_PATH = 'E:\\Models'\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(MODEL_PATH, \"mrcnn_logs\")\n",
    "# Path to COCO trained weights\n",
    "COCO_MODEL_PATH   = os.path.join(MODEL_PATH, \"mask_rcnn_coco.h5\")\n",
    "RESNET_MODEL_PATH = os.path.join(MODEL_PATH, \"resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n",
    "\n",
    "print(\"Tensorflow Version: {}   Keras Version : {} \".format(tf.__version__,keras.__version__))\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
    "np.set_printoptions(linewidth=100,precision=4)\n",
    "\n",
    "\n",
    "# Build configuration object -----------------------------------------------\n",
    "config = shapes.ShapesConfig()\n",
    "config.BATCH_SIZE      = 3                  # Batch size is 2 (# GPUs * images/GPU).\n",
    "config.IMAGES_PER_GPU  = 3                  # Must match BATCH_SIZE\n",
    "config.STEPS_PER_EPOCH = 2\n",
    "config.FCN_INPUT_SHAPE = config.IMAGE_SHAPE[0:2]\n",
    "# config.display() \n",
    "\n",
    "# Build shape dataset        -----------------------------------------------\n",
    "# Training dataset\n",
    "# generate 500 shapes \n",
    "dataset_train = shapes.ShapesDataset()\n",
    "dataset_train.load_shapes(3, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T13:51:01.102960Z",
     "start_time": "2018-05-05T13:50:52.236362Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " non_max_suppression \n",
      "====> Initial Ixs:  [2 1 0]\n",
      " starting ixs :  [2 1 0]  compare  2  with  [1 0]\n",
      " np.where( iou > threshold) :  (array([0, 1], dtype=int64),) tst[0] (index into ixs[1:]:  [0 1]  remove_ixs (index into ixs) :  [1 2]\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [2]\n",
      "====> Final Picks:  [2]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [1 0]\n",
      " starting ixs :  [1 0]  compare  1  with  [0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [0]  picked so far:  [1]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [1, 0]\n",
      "====> Final Picks:  [1, 0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [3 2 1 0]\n",
      " starting ixs :  [3 2 1 0]  compare  3  with  [2 1 0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [2 1 0]  picked so far:  [3]\n",
      " starting ixs :  [2 1 0]  compare  2  with  [1 0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [1 0]  picked so far:  [3, 2]\n",
      " starting ixs :  [1 0]  compare  1  with  [0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [0]  picked so far:  [3, 2, 1]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [3, 2, 1, 0]\n",
      "====> Final Picks:  [3, 2, 1, 0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [0]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [0]\n",
      "====> Final Picks:  [0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [0]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [0]\n",
      "====> Final Picks:  [0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [3 2 1 0]\n",
      " starting ixs :  [3 2 1 0]  compare  3  with  [2 1 0]\n",
      " np.where( iou > threshold) :  (array([2], dtype=int64),) tst[0] (index into ixs[1:]:  [2]  remove_ixs (index into ixs) :  [3]\n",
      " edning ixs (after deleting ixs[0]):  [2 1]  picked so far:  [3]\n",
      " starting ixs :  [2 1]  compare  2  with  [1]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [1]  picked so far:  [3, 2]\n",
      " starting ixs :  [1]  compare  1  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [3, 2, 1]\n",
      "====> Final Picks:  [3, 2, 1]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [2 1 0]\n",
      " starting ixs :  [2 1 0]  compare  2  with  [1 0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [1 0]  picked so far:  [2]\n",
      " starting ixs :  [1 0]  compare  1  with  [0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [0]  picked so far:  [2, 1]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [2, 1, 0]\n",
      "====> Final Picks:  [2, 1, 0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [0]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [0]\n",
      "====> Final Picks:  [0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [3 2 1 0]\n",
      " starting ixs :  [3 2 1 0]  compare  3  with  [2 1 0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [2 1 0]  picked so far:  [3]\n",
      " starting ixs :  [2 1 0]  compare  2  with  [1 0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [1 0]  picked so far:  [3, 2]\n",
      " starting ixs :  [1 0]  compare  1  with  [0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [0]  picked so far:  [3, 2, 1]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [3, 2, 1, 0]\n",
      "====> Final Picks:  [3, 2, 1, 0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [0]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [0]\n",
      "====> Final Picks:  [0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [0]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [0]\n",
      "====> Final Picks:  [0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [1 0]\n",
      " starting ixs :  [1 0]  compare  1  with  [0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [0]  picked so far:  [1]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [1, 0]\n",
      "====> Final Picks:  [1, 0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [0]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [0]\n",
      "====> Final Picks:  [0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [1 0]\n",
      " starting ixs :  [1 0]  compare  1  with  [0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [0]  picked so far:  [1]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [1, 0]\n",
      "====> Final Picks:  [1, 0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [2 1 0]\n",
      " starting ixs :  [2 1 0]  compare  2  with  [1 0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [1 0]  picked so far:  [2]\n",
      " starting ixs :  [1 0]  compare  1  with  [0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [0]  picked so far:  [2, 1]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [2, 1, 0]\n",
      "====> Final Picks:  [2, 1, 0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [0]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [0]\n",
      "====> Final Picks:  [0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [1 0]\n",
      " starting ixs :  [1 0]  compare  1  with  [0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [0]  picked so far:  [1]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [1, 0]\n",
      "====> Final Picks:  [1, 0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [0]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [0]\n",
      "====> Final Picks:  [0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [3 2 1 0]\n",
      " starting ixs :  [3 2 1 0]  compare  3  with  [2 1 0]\n",
      " np.where( iou > threshold) :  (array([2], dtype=int64),) tst[0] (index into ixs[1:]:  [2]  remove_ixs (index into ixs) :  [3]\n",
      " edning ixs (after deleting ixs[0]):  [2 1]  picked so far:  [3]\n",
      " starting ixs :  [2 1]  compare  2  with  [1]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [1]  picked so far:  [3, 2]\n",
      " starting ixs :  [1]  compare  1  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [3, 2, 1]\n",
      "====> Final Picks:  [3, 2, 1]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [2 1 0]\n",
      " starting ixs :  [2 1 0]  compare  2  with  [1 0]\n",
      " np.where( iou > threshold) :  (array([1], dtype=int64),) tst[0] (index into ixs[1:]:  [1]  remove_ixs (index into ixs) :  [2]\n",
      " edning ixs (after deleting ixs[0]):  [1]  picked so far:  [2]\n",
      " starting ixs :  [1]  compare  1  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [2, 1]\n",
      "====> Final Picks:  [2, 1]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [3 2 1 0]\n",
      " starting ixs :  [3 2 1 0]  compare  3  with  [2 1 0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [2 1 0]  picked so far:  [3]\n",
      " starting ixs :  [2 1 0]  compare  2  with  [1 0]\n",
      " np.where( iou > threshold) :  (array([1], dtype=int64),) tst[0] (index into ixs[1:]:  [1]  remove_ixs (index into ixs) :  [2]\n",
      " edning ixs (after deleting ixs[0]):  [1]  picked so far:  [3, 2]\n",
      " starting ixs :  [1]  compare  1  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [3, 2, 1]\n",
      "====> Final Picks:  [3, 2, 1]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [3 2 1 0]\n",
      " starting ixs :  [3 2 1 0]  compare  3  with  [2 1 0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [2 1 0]  picked so far:  [3]\n",
      " starting ixs :  [2 1 0]  compare  2  with  [1 0]\n",
      " np.where( iou > threshold) :  (array([0], dtype=int64),) tst[0] (index into ixs[1:]:  [0]  remove_ixs (index into ixs) :  [1]\n",
      " edning ixs (after deleting ixs[0]):  [0]  picked so far:  [3, 2]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [3, 2, 0]\n",
      "====> Final Picks:  [3, 2, 0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [2 1 0]\n",
      " starting ixs :  [2 1 0]  compare  2  with  [1 0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [1 0]  picked so far:  [2]\n",
      " starting ixs :  [1 0]  compare  1  with  [0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [0]  picked so far:  [2, 1]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [2, 1, 0]\n",
      "====> Final Picks:  [2, 1, 0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [0]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [0]\n",
      "====> Final Picks:  [0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [2 1 0]\n",
      " starting ixs :  [2 1 0]  compare  2  with  [1 0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [1 0]  picked so far:  [2]\n",
      " starting ixs :  [1 0]  compare  1  with  [0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [0]  picked so far:  [2, 1]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [2, 1, 0]\n",
      "====> Final Picks:  [2, 1, 0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [2 1 0]\n",
      " starting ixs :  [2 1 0]  compare  2  with  [1 0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [1 0]  picked so far:  [2]\n",
      " starting ixs :  [1 0]  compare  1  with  [0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [0]  picked so far:  [2, 1]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [2, 1, 0]\n",
      "====> Final Picks:  [2, 1, 0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [2 1 0]\n",
      " starting ixs :  [2 1 0]  compare  2  with  [1 0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [1 0]  picked so far:  [2]\n",
      " starting ixs :  [1 0]  compare  1  with  [0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [0]  picked so far:  [2, 1]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [2, 1, 0]\n",
      "====> Final Picks:  [2, 1, 0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [2 1 0]\n",
      " starting ixs :  [2 1 0]  compare  2  with  [1 0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [1 0]  picked so far:  [2]\n",
      " starting ixs :  [1 0]  compare  1  with  [0]\n",
      " np.where( iou > threshold) :  (array([0], dtype=int64),) tst[0] (index into ixs[1:]:  [0]  remove_ixs (index into ixs) :  [1]\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [2, 1]\n",
      "====> Final Picks:  [2, 1]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [0]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [0]\n",
      "====> Final Picks:  [0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [2 1 0]\n",
      " starting ixs :  [2 1 0]  compare  2  with  [1 0]\n",
      " np.where( iou > threshold) :  (array([0], dtype=int64),) tst[0] (index into ixs[1:]:  [0]  remove_ixs (index into ixs) :  [1]\n",
      " edning ixs (after deleting ixs[0]):  [0]  picked so far:  [2]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [2, 0]\n",
      "====> Final Picks:  [2, 0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [3 2 1 0]\n",
      " starting ixs :  [3 2 1 0]  compare  3  with  [2 1 0]\n",
      " np.where( iou > threshold) :  (array([1, 2], dtype=int64),) tst[0] (index into ixs[1:]:  [1 2]  remove_ixs (index into ixs) :  [2 3]\n",
      " edning ixs (after deleting ixs[0]):  [2]  picked so far:  [3]\n",
      " starting ixs :  [2]  compare  2  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [3, 2]\n",
      "====> Final Picks:  [3, 2]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [3 2 1 0]\n",
      " starting ixs :  [3 2 1 0]  compare  3  with  [2 1 0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [2 1 0]  picked so far:  [3]\n",
      " starting ixs :  [2 1 0]  compare  2  with  [1 0]\n",
      " np.where( iou > threshold) :  (array([0], dtype=int64),) tst[0] (index into ixs[1:]:  [0]  remove_ixs (index into ixs) :  [1]\n",
      " edning ixs (after deleting ixs[0]):  [0]  picked so far:  [3, 2]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [3, 2, 0]\n",
      "====> Final Picks:  [3, 2, 0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [1 0]\n",
      " starting ixs :  [1 0]  compare  1  with  [0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [0]  picked so far:  [1]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [1, 0]\n",
      "====> Final Picks:  [1, 0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [1 0]\n",
      " starting ixs :  [1 0]  compare  1  with  [0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [0]  picked so far:  [1]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [1, 0]\n",
      "====> Final Picks:  [1, 0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [2 1 0]\n",
      " starting ixs :  [2 1 0]  compare  2  with  [1 0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [1 0]  picked so far:  [2]\n",
      " starting ixs :  [1 0]  compare  1  with  [0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [0]  picked so far:  [2, 1]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [2, 1, 0]\n",
      "====> Final Picks:  [2, 1, 0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [1 0]\n",
      " starting ixs :  [1 0]  compare  1  with  [0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [0]  picked so far:  [1]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [1, 0]\n",
      "====> Final Picks:  [1, 0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [1 0]\n",
      " starting ixs :  [1 0]  compare  1  with  [0]\n",
      " np.where( iou > threshold) :  (array([0], dtype=int64),) tst[0] (index into ixs[1:]:  [0]  remove_ixs (index into ixs) :  [1]\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [1]\n",
      "====> Final Picks:  [1]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [2 1 0]\n",
      " starting ixs :  [2 1 0]  compare  2  with  [1 0]\n",
      " np.where( iou > threshold) :  (array([0, 1], dtype=int64),) tst[0] (index into ixs[1:]:  [0 1]  remove_ixs (index into ixs) :  [1 2]\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [2]\n",
      "====> Final Picks:  [2]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [1 0]\n",
      " starting ixs :  [1 0]  compare  1  with  [0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [0]  picked so far:  [1]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [1, 0]\n",
      "====> Final Picks:  [1, 0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [0]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [0]\n",
      "====> Final Picks:  [0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [3 2 1 0]\n",
      " starting ixs :  [3 2 1 0]  compare  3  with  [2 1 0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [2 1 0]  picked so far:  [3]\n",
      " starting ixs :  [2 1 0]  compare  2  with  [1 0]\n",
      " np.where( iou > threshold) :  (array([0, 1], dtype=int64),) tst[0] (index into ixs[1:]:  [0 1]  remove_ixs (index into ixs) :  [1 2]\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [3, 2]\n",
      "====> Final Picks:  [3, 2]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [0]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [0]\n",
      "====> Final Picks:  [0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [2 1 0]\n",
      " starting ixs :  [2 1 0]  compare  2  with  [1 0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [1 0]  picked so far:  [2]\n",
      " starting ixs :  [1 0]  compare  1  with  [0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [0]  picked so far:  [2, 1]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [2, 1, 0]\n",
      "====> Final Picks:  [2, 1, 0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [1 0]\n",
      " starting ixs :  [1 0]  compare  1  with  [0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [0]  picked so far:  [1]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [1, 0]\n",
      "====> Final Picks:  [1, 0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [1 0]\n",
      " starting ixs :  [1 0]  compare  1  with  [0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [0]  picked so far:  [1]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [1, 0]\n",
      "====> Final Picks:  [1, 0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [1 0]\n",
      " starting ixs :  [1 0]  compare  1  with  [0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [0]  picked so far:  [1]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [1, 0]\n",
      "====> Final Picks:  [1, 0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [0]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [0]\n",
      "====> Final Picks:  [0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [0]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [0]\n",
      "====> Final Picks:  [0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [1 0]\n",
      " starting ixs :  [1 0]  compare  1  with  [0]\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  [0]  picked so far:  [1]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [1, 0]\n",
      "====> Final Picks:  [1, 0]\n",
      " non_max_suppression \n",
      "====> Initial Ixs:  [0]\n",
      " starting ixs :  [0]  compare  0  with  []\n",
      " np.where( iou > threshold) :  (array([], dtype=int64),) tst[0] (index into ixs[1:]:  []  remove_ixs (index into ixs) :  []\n",
      " edning ixs (after deleting ixs[0]):  []  picked so far:  [0]\n",
      "====> Final Picks:  [0]\n",
      " COCO Model Path       :  E:\\Models\\mask_rcnn_coco.h5\n",
      " Checkpoint folder Path:  E:\\Models\\mrcnn_logs\n",
      "E:\\Models\n",
      "E:\\Models\\mask_rcnn_coco.h5\n",
      "E:\\Models\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "E:\\Models\\mrcnn_logs\n",
      "    set_log_dir: Checkpoint path set to : E:\\Models\\mrcnn_logs\\shapes20180505T1550\\mask_rcnn_shapes_{epoch:04d}.h5\n",
      "    set_log_dir: self.epoch set to 0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Resnet Graph \n",
      "     Input_image shape : (?, 128, 128, 3)\n",
      "     After ZeroPadding2D  : (?, 134, 134, 3) (?, 134, 134, 3)\n",
      "     After Conv2D padding : (?, 64, 64, 64) (?, 64, 64, 64)\n",
      "     After BatchNorm      : (?, 64, 64, 64) (?, 64, 64, 64)\n",
      "     After MaxPooling2D   : (?, 32, 32, 64) (?, 32, 32, 64)\n",
      "\n",
      ">>> Feature Pyramid Network (FPN) Graph \n",
      "     FPN P2 shape : (None, 32, 32, 256)\n",
      "     FPN P3 shape : (None, 16, 16, 256)\n",
      "     FPN P4 shape : (None, 8, 8, 256)\n",
      "     FPN P5 shape : (None, 4, 4, 256)\n",
      "     FPN P6 shape : (None, 2, 2, 256)\n",
      "\n",
      ">>> RPN Layer \n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     depth                   : 256\n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     anchor_stride           : 1\n",
      "\n",
      ">>> RPN Outputs  <class 'list'>\n",
      "      rpn_class_logits/concat:0\n",
      "      rpn_class/concat:0\n",
      "      rpn_bbox/concat:0\n",
      "\n",
      ">>> Proposal Layer - generate  2000  proposals\n",
      "    Init complete. Size of anchors:  (4092, 4)\n",
      "     Scores :  (3, 4092)\n",
      "     Deltas :  (3, 4092, 4)\n",
      "     Anchors:  (3, 4092, 4)\n",
      "     Boxes shape / type after processing:  (3, 4092, 4) <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "     Output: Prposals shape :  (3, ?, ?) (3, None, None)\n",
      "\n",
      ">>> Detection Target Layer \n",
      "    Detection Target Layer : call()  <class 'list'> 4\n",
      "     proposals.shape    : (3, ?, ?) (3, ?, ?) (None, 2000, 4)\n",
      "     gt_class_ids.shape : (?, ?) (?, ?) (None, None)\n",
      "     gt_bboxes.shape    : (?, ?, 4) (?, ?, 4) (None, None, 4)\n",
      "     gt_masks.shape     : (?, 56, 56, ?) (?, 56, 56, ?) (None, 56, 56, None)\n",
      ">>> detection_targets_graph \n",
      "     propsals.shape        : (?, ?) (?, ?) (None, None)\n",
      "     gt_boxes.shape        : (?, 4) (None, 4)\n",
      "     gt_class_ids.shape    : (?,) (None,)\n",
      "     gt_masks.shape        : (56, 56, ?) (56, 56, None)\n",
      "\t>>> detection_targets_graph - calculate Overlaps_graph\n",
      "\t     overlaps_graph: shape of boxes1 before reshape:  (?, ?) (None, None)\n",
      "\t     overlaps_graph: shape of boxes2 before reshape:  (?, 4) (None, None)\n",
      "\t>>> detection_targets_graph - calculate Overlaps_graph\n",
      "\t     overlaps_graph: shape of boxes1 before reshape:  (?, ?) (None, None)\n",
      "\t     overlaps_graph: shape of boxes2 before reshape:  (?, 4) (None, None)\n",
      ">>> detection_targets_graph \n",
      "     propsals.shape        : (?, ?) (?, ?) (None, None)\n",
      "     gt_boxes.shape        : (?, 4) (None, 4)\n",
      "     gt_class_ids.shape    : (?,) (None,)\n",
      "     gt_masks.shape        : (56, 56, ?) (56, 56, None)\n",
      "\t>>> detection_targets_graph - calculate Overlaps_graph\n",
      "\t     overlaps_graph: shape of boxes1 before reshape:  (?, ?) (None, None)\n",
      "\t     overlaps_graph: shape of boxes2 before reshape:  (?, 4) (None, None)\n",
      "\t>>> detection_targets_graph - calculate Overlaps_graph\n",
      "\t     overlaps_graph: shape of boxes1 before reshape:  (?, ?) (None, None)\n",
      "\t     overlaps_graph: shape of boxes2 before reshape:  (?, 4) (None, None)\n",
      ">>> detection_targets_graph \n",
      "     propsals.shape        : (?, ?) (?, ?) (None, None)\n",
      "     gt_boxes.shape        : (?, 4) (None, 4)\n",
      "     gt_class_ids.shape    : (?,) (None,)\n",
      "     gt_masks.shape        : (56, 56, ?) (56, 56, None)\n",
      "\t>>> detection_targets_graph - calculate Overlaps_graph\n",
      "\t     overlaps_graph: shape of boxes1 before reshape:  (?, ?) (None, None)\n",
      "\t     overlaps_graph: shape of boxes2 before reshape:  (?, 4) (None, None)\n",
      "\t>>> detection_targets_graph - calculate Overlaps_graph\n",
      "\t     overlaps_graph: shape of boxes1 before reshape:  (?, ?) (None, None)\n",
      "\t     overlaps_graph: shape of boxes2 before reshape:  (?, 4) (None, None)\n",
      "\n",
      "    Detection Target Layer : return  <class 'list'> 5\n",
      "     output 0  shape (3, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 1  shape (3, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 2  shape (3, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 3  shape (3, ?, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 4  shape (3, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "\n",
      ">>> FPN Classifier Graph \n",
      "     rois shape          : (3, ?, ?)\n",
      "     feature_maps : 4\n",
      "     feature_maps shape  : (?, 32, 32, 256)\n",
      "     feature_maps shape  : (?, 16, 16, 256)\n",
      "     feature_maps shape  : (?, 8, 8, 256)\n",
      "     feature_maps shape  : (?, 4, 4, 256)\n",
      "     input_shape         : [128 128   3]\n",
      "     pool_size           : 7\n",
      "\n",
      ">>> FPN Mask Graph \n",
      "     rois shape          : (3, ?, ?)\n",
      "     feature_maps : 4\n",
      "     feature_maps shape  : (?, 32, 32, 256)\n",
      "     feature_maps shape  : (?, 16, 16, 256)\n",
      "     feature_maps shape  : (?, 8, 8, 256)\n",
      "     feature_maps shape  : (?, 4, 4, 256)\n",
      "     input_shape         : [128 128   3]\n",
      "     pool_size           : 14\n",
      "     FPN Mask Graph output shape : (?, 32, 28, 28, 4)\n",
      "\n",
      ">>> PCN Layer TF \n",
      "   > PCNLayerTF Call()  5\n",
      "     mrcnn_class.shape    : (?, 32, 4) (None, 32, 4)\n",
      "     mrcnn_bbox.shape     : (?, 32, 4, 4) (None, 32, 4, 4)\n",
      "     output_rois.shape    : (3, ?, ?) (None, 32, 4)\n",
      "     gt_class_ids.shape   : (?, ?) (None, None)\n",
      "     gt_bboxes.shape      : (?, ?, 4) (None, None, 4)\n",
      "\n",
      "  > BUILD_PREDICTIONS_TF()\n",
      "    num_rois          :  32\n",
      "    mrcnn_class shape :  Tensor(\"cntxt_layer/Shape:0\", shape=(3,), dtype=int32) (None, 32, 4)\n",
      "    mrcnn_bbox.shape  :  Tensor(\"cntxt_layer/Shape_1:0\", shape=(4,), dtype=int32) (None, 32, 4, 4) (?, 32, 4, 4)\n",
      "    output_rois.shape :  Tensor(\"cntxt_layer/Shape_2:0\", shape=(3,), dtype=int32) (3, None, 4)\n",
      "    pred_classes     :  (?, 32)\n",
      "    pred_classes_exp :  (?, 32, 1)\n",
      "    pred_scores      :  (?, 32, 1)\n",
      "    batch_grid       :  (3, 32)\n",
      "    roi_grid         :  (3, 32)\n",
      "    bbox_idx         :  (3, 32, 1)\n",
      "\n",
      "    -- pred_tensor tf ------------------------------\n",
      "    pred_array shape: (3, 32, 6)\n",
      "    pred_scatter shape is  (3, 4, 32, 6) Tensor(\"cntxt_layer/ScatterNd:0\", shape=(3, 4, 32, 6), dtype=float32)\n",
      "    sort inds shape :  (3, 4, 32)\n",
      "    class_grid   <class 'tensorflow.python.framework.ops.Tensor'> shape (3, 4, 32)\n",
      "    batch_grid   <class 'tensorflow.python.framework.ops.Tensor'> shape (3, 4, 32)\n",
      "    roi_grid shape (3, 4, 32) roi_grid_exp shape  (3, 4, 32, 1)\n",
      "    gather_inds  <class 'tensorflow.python.framework.ops.Tensor'> shape (3, 4, 32, 3)\n",
      "    pred_tensor (gathered)  :  (3, 4, 32, 6)\n",
      "    -- pred_tensor results (bboxes sorted by score) ----\n",
      "    final pred_tensor shape  :  (3, 4, 32, 6)\n",
      "    final pred_cls_cnt shape :  (3, 4)\n",
      "    complete\n",
      "\n",
      "\n",
      "  > BUILD_GROUND TRUTH_TF()\n",
      "    gt_class_ids shape :  (?, ?)     notm_gt_bbox.shape  :  (?, ?, 4)\n",
      "    gt_classes_exp shape  (?, ?, 1)\n",
      "    pred_ scores shape  (?, ?)\n",
      "    bbox_idx shape     (3, 100, 1)\n",
      "    gt_array shape     (?, ?, 6)\n",
      "    bbox_grid  shape   (3, 100)\n",
      "    batch_grid shape   (3, 100)\n",
      "    scatter_ind shape  (3, 100, 3)\n",
      "    gt_scatter shape  (3, 4, 100, 6)\n",
      "    build gathering indexes to use in sorting -------\n",
      "    sort inds shape :  (3, 4, 100)\n",
      "    class_grid  shape  (3, 4, 100)\n",
      "    batch_grid  shape  (3, 4, 100)\n",
      "    bbox_grid   shape  (3, 4, 100)  bbox_grid_exp shape  (3, 4, 100, 1)\n",
      "    gather_inds shape      :  (3, 4, 100, 3)\n",
      "    gt_tensor (gathered)   :  (3, 4, 100, 6)\n",
      "    final gt_tensor shape  :  (3, 4, 100, 6)\n",
      "    final gt_cls_cnt shape :  (3, 4)\n",
      "    complete\n",
      "\n",
      " \n",
      "  > BUILD_GAUSSIAN_TF() for  ['pred_gaussian']\n",
      "    orignal in_tensor shape :  (3, 4, 32, 6)\n",
      "    modified in_tensor shape :  (3, 4, 32, 6)\n",
      "    num of bboxes per class is :  Tensor(\"cntxt_layer/ToInt32_1/x:0\", shape=(), dtype=int32)\n",
      "    after transpose  (128, 128, 3, 32, 2)\n",
      "    pt2_sum shape  (3, 4, 32)\n",
      "    dense shape  (?, 6)\n",
      "    Build Stacked output from dynamically partitioned lists --------------\n",
      "    >> input to MVN.PROB: pos_grid (meshgrid) shape:  (128, 128, 3, 32, 2)\n",
      "    << output probabilities shape: (3, 32, 128, 128)\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    gaussian_grid      :  (3, 32, 128, 128)\n",
      "    class shape        :  (3, ?)\n",
      "    roi_grid shape     :  (3, 32)\n",
      "    batch_grid shape   :  (3, 32)\n",
      "    scatter_classes    :  (3, 32, 3)\n",
      "    gaussian scattered :  (3, 4, 32, 128, 128)\n",
      "\n",
      "    Reduce sum based on class ---------------------------------------------\n",
      "    gaussian sum type/name :  <class 'tensorflow.python.framework.ops.Tensor'> cntxt_layer/pred_gaussian_1:0 pred_gaussian\n",
      "    gaussian_sum shape     :  (3, 128, 128, 4) Keras tensor  False\n",
      "\n",
      " \n",
      "  > BUILD_GAUSSIAN_TF() for  ['gt_gaussian']\n",
      "    orignal in_tensor shape :  (3, 4, 100, 6)\n",
      "    modified in_tensor shape :  (3, 4, 100, 6)\n",
      "    num of bboxes per class is :  Tensor(\"cntxt_layer/ToInt32_4/x:0\", shape=(), dtype=int32)\n",
      "    after transpose  (128, 128, 3, 100, 2)\n",
      "    pt2_sum shape  (3, 4, 100)\n",
      "    dense shape  (?, 6)\n",
      "    Build Stacked output from dynamically partitioned lists --------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    >> input to MVN.PROB: pos_grid (meshgrid) shape:  (128, 128, 3, 100, 2)\n",
      "    << output probabilities shape: (3, 100, 128, 128)\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    gaussian_grid      :  (3, 100, 128, 128)\n",
      "    class shape        :  (3, ?)\n",
      "    roi_grid shape     :  (3, 100)\n",
      "    batch_grid shape   :  (3, 100)\n",
      "    scatter_classes    :  (3, 100, 3)\n",
      "    gaussian scattered :  (3, 4, 100, 128, 128)\n",
      "\n",
      "    Reduce sum based on class ---------------------------------------------\n",
      "    gaussian sum type/name :  <class 'tensorflow.python.framework.ops.Tensor'> cntxt_layer/gt_gaussian:0 gt_gaussian\n",
      "    gaussian_sum shape     :  (3, 128, 128, 4) Keras tensor  False\n",
      "\n",
      "    Output build_gaussian_tf \n",
      "     pred_gaussian :  (3, 128, 128, 4) Keras tensor  False\n",
      "     gt_gaussian   :  (3, 128, 128, 4) Keras tensor  False\n",
      "<<<  shape of pred_gaussian   :  (3, 128, 128, 4)  Keras tensor  True\n",
      "<<<  shape of gt_gaussian     :  (3, 128, 128, 4)  Keras tensor  True\n",
      "\n",
      ">>> rpn_bbox_loss_graph\n",
      "    rpn_match size : (?, ?)\n",
      "    rpn_bbox  size : (?, ?, 4)\n",
      "    tf default session:  None\n",
      "\n",
      ">>> rpn_bbox_loss_graph\n",
      "    rpn_match size : (?, ?)\n",
      "    rpn_bbox  size : (?, ?, 4)\n",
      "    tf default session:  None\n",
      "\n",
      ">>> mrcnn_class_loss_graph \n",
      "    target_class_ids  size : (3, ?)\n",
      "    pred_class_logits size : (?, 32, 4)\n",
      "    active_class_ids  size : (?, ?)\n",
      "\n",
      ">>> mrcnn_class_loss_graph \n",
      "    target_class_ids  size : (?, 1)\n",
      "    pred_class_logits size : (?, 32, 4)\n",
      "    active_class_ids  size : (?, ?)\n",
      "\n",
      ">>> mrcnn_bbox_loss_graph \n",
      "    target_class_ids  size : (3, ?)\n",
      "    pred_bbox size         : (?, 32, 4, 4)\n",
      "    target_bbox size       : (3, ?, ?)\n",
      "\n",
      ">>> mrcnn_bbox_loss_graph \n",
      "    target_class_ids  size : (?, 1)\n",
      "    pred_bbox size         : (?, 32, 4, 4)\n",
      "    target_bbox size       : (?, 32, 4)\n",
      "\n",
      ">>> mrcnn_mask_loss_graph \n",
      "    target_class_ids shape : (3, ?)\n",
      "    target_masks     shape : (3, ?, ?, ?)\n",
      "    pred_masks       shape : (?, 32, 28, 28, 4)\n",
      "    target_class_ids shape : (?,)\n",
      "    target_shape       shape : (4,)\n",
      "    target_masks     shape : (?, ?, ?)\n",
      "    pred_shape       shape : (5,)\n",
      "    pred_masks       shape : (?, ?, ?, ?)\n",
      "     y_true shape: (?, ?, ?)\n",
      "     y_pred shape: (?, ?, ?)\n",
      "     final loss shape: (1, 1) <class 'tensorflow.python.framework.ops.Tensor'> False\n",
      "\n",
      ">>> mrcnn_mask_loss_graph \n",
      "    target_class_ids shape : (?, 1)\n",
      "    target_masks     shape : (?, 32, 28, 28)\n",
      "    pred_masks       shape : (?, 32, 28, 28, 4)\n",
      "    target_class_ids shape : (?,)\n",
      "    target_shape       shape : (4,)\n",
      "    target_masks     shape : (?, ?, ?)\n",
      "    pred_shape       shape : (5,)\n",
      "    pred_masks       shape : (?, ?, ?, ?)\n",
      "     y_true shape: (?, ?, ?)\n",
      "     y_pred shape: (?, ?, ?)\n",
      "     final loss shape: (1, 1) <class 'tensorflow.python.framework.ops.Tensor'> False\n",
      "\n",
      "\n",
      "---------------------------------------------------\n",
      "    building fcn_loss\n",
      "---------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---------------------------------------------------\n",
      "    building fcn_norm_loss\n",
      "---------------------------------------------------\n",
      "\n",
      " Keras Tensors?? \n",
      " output_rois       : True\n",
      " pred_gaussian     : True\n",
      " gt_gaussian       : True\n",
      " mask_loss         : True\n",
      " rpn_proposal_rois : True\n",
      ">>> MaskRCNN build complete\n",
      ">>> MaskRCNN initialization complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = shapes.ShapesDataset()\n",
    "dataset_val.load_shapes(50, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_val.prepare()\n",
    "\n",
    "try :\n",
    "    del model, train_generator, val_generator, mm\n",
    "    gc.collect()\n",
    "except: \n",
    "    pass\n",
    "# Load and display random samples\n",
    "# image_ids = np.random.choice(dataset_train.image_ids, 3)\n",
    "# for image_id in [3]:\n",
    "#     image = dataset_train.load_image(image_id)\n",
    "#     mask, class_ids = dataset_train.load_mask(image_id)\n",
    "#     visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "print(' COCO Model Path       : ', COCO_MODEL_PATH)\n",
    "print(' Checkpoint folder Path: ', MODEL_DIR)\n",
    "print(MODEL_PATH)\n",
    "print(COCO_MODEL_PATH)\n",
    "print(RESNET_MODEL_PATH)\n",
    "print(MODEL_DIR)\n",
    "\n",
    "\n",
    "np.set_printoptions(linewidth=100, precision=4)\n",
    "\n",
    "try :\n",
    "    del model\n",
    "    print('delete model is successful')\n",
    "    gc.collect()\n",
    "except: \n",
    "    pass\n",
    "KB.clear_session()\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T17:09:16.646684Z",
     "start_time": "2018-05-04T17:09:08.066051Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(model.find_last())\n",
    "# Which weights to start with?\n",
    "init_with = \"coco\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "#     loc=model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "    loc=model.load_weights(RESNET_MODEL_PATH, by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    \n",
    "    # See README for instructions to download the COCO weights\n",
    "    loc=model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    loc= model.load_weights(model.find_last()[1], by_name=True)\n",
    "print('Load weights complete')\n",
    "\n",
    "train_generator = data_generator(dataset_train, model.config, shuffle=True,\n",
    "                                 batch_size=model.config.BATCH_SIZE,\n",
    "                                 augment = False)\n",
    "val_generator = data_generator(dataset_val, model.config, shuffle=True, \n",
    "                                batch_size=model.config.BATCH_SIZE,\n",
    "                                augment=False)\n",
    "\n",
    "print('\\n Outputs: ') \n",
    "for i, out in enumerate(model.keras_model.outputs):\n",
    "    print(i , '    ', out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T17:04:40.906164Z",
     "start_time": "2018-05-04T17:04:40.663520Z"
    }
   },
   "outputs": [],
   "source": [
    "print('\\n Outputs: ') \n",
    "for i, out in enumerate(model.keras_model.outputs):\n",
    "    print(i , '    ', out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T17:11:25.520861Z",
     "start_time": "2018-05-04T17:11:25.269193Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "train_batch_x, train_batch_y = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T17:11:27.784525Z",
     "start_time": "2018-05-04T17:11:26.670564Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# train_batch_x, train_batch_y = next(train_generator)\n",
    "imgmeta_idx = model.keras_model.input_names.index('input_image_meta')\n",
    "img_meta    = train_batch_x[imgmeta_idx]\n",
    "\n",
    "for img_idx in range(config.BATCH_SIZE):\n",
    "    image_id = img_meta[img_idx,0]\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    print('Image id: ',image_id)\n",
    "    print('Image meta', img_meta[img_idx])\n",
    "    print('Classes (1: circle, 2: square, 3: triangle ): ',class_ids)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T17:11:35.430102Z",
     "start_time": "2018-05-04T17:11:30.198156Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "model_output = get_layer_output_2(model.keras_model, train_batch_x, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T17:41:18.844878Z",
     "start_time": "2018-05-04T17:41:18.581178Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "mrcnn_bbox  = model_output[11]\n",
    "mrcnn_class = model_output[10]\n",
    "pred_tensor = model_output[20]\n",
    "output_rois = model_output[4]\n",
    "sess = KB.get_session()\n",
    "print(sess)\n",
    "# KB.set_session(sess)\n",
    "print(len(model_output))\n",
    "KB.set_session(sess)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T17:46:29.363119Z",
     "start_time": "2018-05-04T17:46:29.108444Z"
    }
   },
   "outputs": [],
   "source": [
    "print(output_rois[1]*[128,128,128,128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T17:47:24.043695Z",
     "start_time": "2018-05-04T17:47:23.788452Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(mrcnn_class.shape)\n",
    "max_score = np.max(mrcnn_class, axis = -1)\n",
    "max_class = np.argmax(mrcnn_class, axis = -1)\n",
    "print(max_class.shape, max_score.shape)\n",
    "print(max_class[1])\n",
    "print(max_score[1])\n",
    "print(mrcnn_class[1,:])\n",
    "# print(output_rois[1])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "###  Test `means`, `covar`, `gauss_grid`, and `gauss_sum ` between development version and final version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "\n",
    "###  Display for visual check - `pred_tensor` is the final result which is passed on to  `build_gaussian_tf()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T17:44:42.300078Z",
     "start_time": "2018-05-04T17:44:42.012777Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    np.set_printoptions(linewidth=150, precision=6)\n",
    "    # print('scatter shape is ', pred_scatt.get_shape())\n",
    "    print('pred_tensor shape is ', pred_tensor.shape)\n",
    "    img = 1\n",
    "    print('Image ', img , '/ Class 0 ------------')\n",
    "    print(pred_tensor[img,0])\n",
    "    print('Image ', img , '/ Class 1 ------------')\n",
    "    print(pred_tensor[img,1])\n",
    "    print('Image ', img , '/ Class 2 ------------')\n",
    "    print(pred_tensor[img,2])\n",
    "    print('Image ', img , '/ Class 3 ------------')\n",
    "    print(pred_tensor[img,3])\n",
    " \n",
    "# cls = 3\n",
    "# print('Image 0 / Class ', cls ,' ------------')\n",
    "# print(pred_tensor[0, cls].eval())\n",
    "# print('Image 1 / Class ', cls ,' ------------')\n",
    "# print(pred_tensor[1, cls].eval())\n",
    "# print('Image 2 / Class ', cls ,' ------------')\n",
    "# print(pred_tensor[2, cls].eval())\n",
    "\n",
    "\n",
    "\n",
    "# print(pred_tensor_out.shape)\n",
    "# print(pred_tensor_out[2,2, :].eval())\n",
    "# print(pred_tensor.shape)\n",
    "# pred_tensor_tst = pred_tensor *[128, 128, 128,128,1,1]\n",
    "# print(pred_tensor_tst[2,2,:].eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "##  `development build_gaussian_tf ()` \n",
    "\n",
    "### Generate Multivariate Normal Distribution from Pred_Tensor\n",
    "\n",
    "`pred_tensor[:,:,:,1:7]`  == `[116.9736  21.8213  36.2715  45.6026   0.    0.9139   ]`\n",
    "\n",
    "\n",
    "Detections returned by `detect()` routine:\n",
    "\n",
    "`[[ 25.          18.          80.          72.           2.           0.99936014]\n",
    "  [ 51.           3.         106.          71.           3.           0.99924326]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Copy of `build_gaussian_tf()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T17:49:34.106011Z",
     "start_time": "2018-05-04T17:49:33.084725Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_gaussian_tf(in_tensor, config, names = None):\n",
    "\n",
    "    num_detections  = config.DETECTION_MAX_INSTANCES\n",
    "    img_h, img_w    = config.IMAGE_SHAPE[:2]\n",
    "    batch_size      = config.BATCH_SIZE\n",
    "    num_classes     = config.NUM_CLASSES  \n",
    "    print('\\n ')\n",
    "    print('  > BUILD_GAUSSIAN_TF() for ', names )\n",
    "    \n",
    "    # rois per image is determined by size of input tensor \n",
    "    #   detection mode:   config.TRAIN_ROIS_PER_IMAGE \n",
    "    #   ground_truth  :   config.DETECTION_MAX_INSTANCES\n",
    "    \n",
    "    print('    orignal in_tensor shape : ', in_tensor.shape)   \n",
    "    # in_tensor = in_tensor[:,:,:,2:7]\n",
    "    print('    modified in_tensor shape : ', in_tensor.get_shape())\n",
    "    \n",
    "    rois_per_image  = tf.to_int32(in_tensor.shape[2])\n",
    "    # strt_cls        = 0 if rois_per_image == 32 else 1\n",
    "    print('    num of bboxes per class is : ', rois_per_image)\n",
    "\n",
    "    #-----------------------------------------------------------------------------\n",
    "    ## Build mesh-grid to hold pixel coordinates  \n",
    "    #-----------------------------------------------------------------------------\n",
    "    X = tf.range(img_w, dtype=tf.int32)\n",
    "    Y = tf.range(img_h, dtype=tf.int32)\n",
    "    X, Y = tf.meshgrid(X, Y)\n",
    "    # print('    X/Y shapes :',  X.get_shape(), Y.get_shape())\n",
    "    # print('    X : \\n',X.eval())\n",
    "    # print('    Y : \\n',Y.eval())\n",
    "\n",
    "    # repeat X and Y  batch_size x rois_per_image times\n",
    "    ones = tf.ones([batch_size, rois_per_image,1, 1], dtype = tf.int32)\n",
    "    rep_X = ones * X\n",
    "    rep_Y = ones * Y \n",
    "    # print('    Ones: ',ones.shape)                \n",
    "    # print(' ones_exp * X', ones.shape, '*', X.shape, '= ',rep_X.shape)\n",
    "    # print(' ones_exp * Y', ones.shape, '*', Y.shape, '= ',rep_Y.shape)\n",
    "\n",
    "    # # stack the X and Y grids \n",
    "    bef_pos = tf.to_float(tf.stack([rep_X,rep_Y], axis = -1))\n",
    "    # print(' before transpse ', bef_pos.get_shape())\n",
    "    pos_grid = tf.transpose(bef_pos,[2,3,0,1,4])\n",
    "    print('    after transpose ', pos_grid.get_shape())    \n",
    "\n",
    "    # pt2_reshape = tf.reshape( in_tensor , [batch_size, num_classes * rois_per_image ,8])\n",
    "    # print('    pt2_reshape shape is : ', pt2_reshape.get_shape())\n",
    "    # print(pt2_reshape[0].eval())\n",
    "    # print(pt2_reshape[1].eval())\n",
    "    # print(pt2_reshape[2].eval())\n",
    "\n",
    "    #-----------------------------------------------------------------------------    \n",
    "    ## Stack non_zero bboxes from in_tensor into pt2_dense \n",
    "    #-----------------------------------------------------------------------------\n",
    "    pt2_sum = tf.reduce_sum(tf.abs(in_tensor[:,:,:,:-2]), axis=-1)\n",
    "    print('    pt2_sum shape ',pt2_sum.shape)\n",
    "    # print(pt2_sum[0].eval())\n",
    "\n",
    "    pt2_mask = tf.greater(pt2_sum , 0)\n",
    "    # print(' pt2_mask shape ', pt2_mask.get_shape())\n",
    "    # print(pt2_mask.eval())\n",
    "\n",
    "    # pt2_ind shape is [?, 3]. \n",
    "    #   pt2_ind[0] corresponds to image_index \n",
    "    #   pt2_ind[1] corresponds to class_index \n",
    "    #   pt2_ind[2] corresponds to roi row_index \n",
    "    pt2_ind  = tf.where(pt2_mask)\n",
    "    # print('    pt2_ind shape ', pt2_ind.get_shape())\n",
    "    # print(pt2_ind.eval())\n",
    "    # pt2_ind_float  =  tf.to_float(pt2_ind[:,0:1])\n",
    "\n",
    "    # pt2_dense shape is [?, 6]\n",
    "    #    pt2_dense[0] is image index\n",
    "    #    pt2_dense[1:4]  roi cooridnaytes \n",
    "    #    pt2_dense[5]    is class id \n",
    "    pt2_dense = tf.gather_nd( in_tensor, pt2_ind)\n",
    "\n",
    "    # append image index to front of rows - REMOVED 1-5-2018\n",
    "    #  pt2_dense = tf.concat([tf.to_float(pt2_ind[:,0:1]), pt2_dense],axis=1)\n",
    "    print('    dense shape ',pt2_dense.get_shape())\n",
    "    # print(dense.eval())\n",
    "\n",
    "    ## split pt2_dense by pt2_ind[:,0], which identifies the image \n",
    "    stacked_list = tf.dynamic_partition(pt2_dense, tf.to_int32(pt2_ind[:,0]), num_partitions = batch_size )\n",
    "\n",
    "    \n",
    "    #-----------------------------------------------------------------------------\n",
    "    ##  Build Stacked output from dynamically partitioned lists \n",
    "    #-----------------------------------------------------------------------------\n",
    "    print('    Build Stacked output from dynamically partitioned lists --------------')  \n",
    "\n",
    "    stacked_output=[]\n",
    "    for img, item  in enumerate(stacked_list) : \n",
    "        rois_in_image  = tf.shape(item)[0]\n",
    "        pad_item =  tf.pad(item,[[0, rois_per_image - rois_in_image ],[0,0]])\n",
    "        stacked_output.append(pad_item)\n",
    "    stacked_tensor = tf.stack(stacked_output)\n",
    "\n",
    "    # print()    \n",
    "    # print('   -- Stacked output contents --------------')    \n",
    "    # print('    stacked_output shape : ', len(stacked_output))\n",
    "    # for img, item  in enumerate(stacked_output) :\n",
    "        # print('   img ', img, ' stacked_list[img] ', tf.shape(item).eval() ) \n",
    "    # print('   stacked_tensor shape : ', tf.shape(stacked_tensor).eval())\n",
    "    \n",
    "    #-----------------------------------------------------------------------------\n",
    "    ##  Build mean and convariance tensors for Multivariate Normal Distribution \n",
    "    #-----------------------------------------------------------------------------\n",
    "    width  = stacked_tensor[:,:,3] - stacked_tensor[:,:,1]      # x2 - x1\n",
    "    height = stacked_tensor[:,:,2] - stacked_tensor[:,:,0]\n",
    "    cx     = stacked_tensor[:,:,1] + ( width  / 2.0)\n",
    "    cy     = stacked_tensor[:,:,0] + ( height / 2.0)\n",
    "    means  = tf.stack((cx,cy),axis = -1)\n",
    "    covar  = tf.stack((width * 0.5 , height * 0.5), axis = -1)\n",
    "    covar  = tf.sqrt(covar)\n",
    "\n",
    "    tfd = tf.contrib.distributions\n",
    "    mvn = tfd.MultivariateNormalDiag( loc  = means,  scale_diag = covar)\n",
    "    prob_grid = mvn.prob(pos_grid)\n",
    "    prob_grid = tf.transpose(prob_grid,[2,3,0,1])\n",
    "\n",
    "    # print('    means shape :', means.get_shape(),' covar shape ', covar.get_shape())\n",
    "    # print('    from MVN    : mns shape      : ', means.shape, means.get_shape())\n",
    "    # print('    from MVN    : cov shape      : ', covar.shape, covar.get_shape())\n",
    "    # print('    from MVN    : mean shape     : ', mvn.mean().get_shape(), '\\t stddev shape', mvn.stddev().get_shape())\n",
    "    # print('    from MVN    : mvn.batch_shape: ', mvn.batch_shape , '\\t mvn.event_shape ',  mvn.event_shape)\n",
    "    # print('    from Linear : op shape       : ', mvn.scale.shape, ' Linear Op batch shape ',mvn.scale.batch_shape)\n",
    "    # print('    from Linear : op Range Dim   : ', mvn.scale.range_dimension)\n",
    "    # print('    from Linear : op Domain Dim  : ', mvn.scale.domain_dimension) \n",
    "    print('    >> input to MVN.PROB: pos_grid (meshgrid) shape: ', pos_grid.get_shape())\n",
    "    print('    << output probabilities shape:' , prob_grid.get_shape())\n",
    "    # print(prob_grid.eval())\n",
    "    \n",
    "    #--------------------------------------------------------------------------------\n",
    "    # kill distributions of NaN boxes (resulting from bboxes with height/width of zero\n",
    "    # which cause singular sigma cov matrices\n",
    "    #--------------------------------------------------------------------------------\n",
    "    gauss_grid = tf.where(tf.is_nan(prob_grid),  tf.zeros_like(prob_grid), prob_grid)\n",
    "\n",
    "    \n",
    "    #--------------------------------------------------------------------------------\n",
    "    ## scatter out the probability distributions based on class\n",
    "    #--------------------------------------------------------------------------------\n",
    "    print('\\n    Scatter out the probability distributions based on class --------------')     \n",
    "    class_inds      = tf.to_int32(stacked_tensor[:,:,-2])   # - should be -2 since class moved to that postion\n",
    "    batch_grid, roi_grid = tf.meshgrid( tf.range(batch_size, dtype=tf.int32), tf.range(rois_per_image, dtype=tf.int32),\n",
    "                                        indexing = 'ij' )\n",
    "    scatter_classes = tf.stack([batch_grid, class_inds, roi_grid ],axis = -1)\n",
    "    gauss_scatt     = tf.scatter_nd(scatter_classes, gauss_grid, [batch_size, num_classes, rois_per_image, img_w, img_h])\n",
    "\n",
    "    print('    gaussian_grid      : ', gauss_grid.shape)    \n",
    "    print('    class shape        : ', class_inds.shape)\n",
    "    print('    roi_grid shape     : ', roi_grid.get_shape() )\n",
    "    print('    batch_grid shape   : ', batch_grid.get_shape())\n",
    "    print('    scatter_classes    : ', scatter_classes.get_shape())\n",
    "    print('    gaussian scattered : ', gauss_scatt.shape)   \n",
    "    \n",
    "    ## sum based on class -----------------------------------------------------------------\n",
    "    print('\\n    Reduce sum based on class ---------------------------------------------')         \n",
    "    gauss_sum = tf.reduce_sum(gauss_scatt, axis=2, name='pred_gaussian')\n",
    "    gauss_sum = tf.where(gauss_sum > 1e-6, gauss_sum,tf.zeros_like(gauss_sum))\n",
    "    gauss_sum = tf.transpose(gauss_sum,[0,2,3,1], name = names[0])\n",
    "    print('    gaussian sum type/name : ', type(gauss_sum), gauss_sum.name, names[0])\n",
    "    print('    gaussian_sum shape     : ', gauss_sum.get_shape(), 'Keras tensor ', KB.is_keras_tensor(gauss_sum) )    \n",
    "\n",
    "    # L2 normalization  -----------------------------------------------------------------\n",
    "    # print('\\n    L2 normalization ------------------------------------------------------')         \n",
    "    \n",
    "    # gauss_flatten = KB.reshape(gauss_sum, [tf.shape(gauss_sum)[0], -1, tf.shape(gauss_sum)[-1]] )\n",
    "    # gauss_norm    = KB.l2_normalize(gauss_flatten, axis = 1)\n",
    "    # gauss_norm    = KB.reshape(gauss_norm, KB.shape(gauss_sum))\n",
    "    # print('    Shape of guassian_flattened  : ', KB.int_shape(gauss_flatten), 'Keras tensor ', KB.is_keras_tensor(gauss_flatten) )\n",
    "    # print('    Shape of L2 normalized tensor: ', KB.int_shape(gauss_norm), 'Keras tensor ', KB.is_keras_tensor(gauss_norm) )\n",
    "    print('    complete')\n",
    "\n",
    "    return  gauss_sum    # [gauss_sum, gauss_scatt, means, covar]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T17:19:42.006304Z",
     "start_time": "2018-05-04T17:19:41.197152Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gauss_sum2 =  build_gaussian_tf(pred_tensor, model.config, names = 'Kevin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T17:17:43.422404Z",
     "start_time": "2018-05-04T17:17:43.148121Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_mask2(input):\n",
    "    # row = input.eval()\n",
    "    print(row)\n",
    "    y_extent = tf.range(row[0], row[2])\n",
    "    x_extent = tf.range(row[1], row[3])\n",
    "    print('y_extent', y_extent.eval())\n",
    "    Y,X   = tf.meshgrid(y_extent, x_extent)\n",
    "    print(Y.shape, X.shape)\n",
    "    bbox_mask    = tf.stack([Y,X],axis=2)\n",
    "    print(' bbox_mask shapoe: ',bbox_mask.shape)\n",
    "\n",
    "    mask_indices = tf.reshape(bbox_mask,[-1,2])\n",
    "    print('  size of mask_indices: ', mask_indices.shape)\n",
    "\n",
    "    mask_size = mask_indices.get_shape()[0]\n",
    "    mask_updates = tf.ones([mask_size], dtype = tf.int32)\n",
    "    print('  size of bbox_mask: ', mask_size)\n",
    "    res = tf.scatter_nd_add(ref2, mask_indices, mask_updates)\n",
    "    print( ' ref shape: ', res.shape)\n",
    "    print( ' indices shape: ', mask_indices.shape)\n",
    "    print( ' updates shape: ', mask_updates.shape)\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T18:47:43.054780Z",
     "start_time": "2018-05-04T18:47:41.949826Z"
    }
   },
   "outputs": [],
   "source": [
    "def development_build_gaussian_tf(in_tensor, config, names = None):\n",
    "\n",
    "    num_detections  = config.DETECTION_MAX_INSTANCES\n",
    "    img_h, img_w    = config.IMAGE_SHAPE[:2]\n",
    "    batch_size      = config.BATCH_SIZE\n",
    "    num_classes     = config.NUM_CLASSES  \n",
    "    print('\\n ')\n",
    "    print('  > BUILD_GAUSSIAN_TF() for ', names )\n",
    "    \n",
    "    # rois per image is determined by size of input tensor \n",
    "    #   detection mode:   config.TRAIN_ROIS_PER_IMAGE \n",
    "    #   ground_truth  :   config.DETECTION_MAX_INSTANCES\n",
    "    \n",
    "    print('    orignal in_tensor shape : ', in_tensor.shape)   \n",
    "    # in_tensor = in_tensor[:,:,:,2:7]\n",
    "    print('    modified in_tensor shape : ', in_tensor.get_shape())\n",
    "    \n",
    "    rois_per_image  = tf.to_int32(in_tensor.shape[2])\n",
    "    # strt_cls        = 0 if rois_per_image == 32 else 1\n",
    "    print('    num of bboxes per class is : ', rois_per_image)\n",
    "\n",
    "    #-----------------------------------------------------------------------------\n",
    "    ## Build mesh-grid to hold pixel coordinates  \n",
    "    #-----------------------------------------------------------------------------\n",
    "    X = tf.range(img_w, dtype=tf.int32)\n",
    "    Y = tf.range(img_h, dtype=tf.int32)\n",
    "    X, Y = tf.meshgrid(X, Y)\n",
    "    # print('    X/Y shapes :',  X.get_shape(), Y.get_shape())\n",
    "    # print('    X : \\n',X.eval())\n",
    "    # print('    Y : \\n',Y.eval())\n",
    "\n",
    "    # repeat X and Y  batch_size x rois_per_image times\n",
    "    ones = tf.ones([batch_size, rois_per_image,1, 1], dtype = tf.int32)\n",
    "    rep_X = ones * X\n",
    "    rep_Y = ones * Y \n",
    "    # print('    Ones: ',ones.shape)                \n",
    "    # print(' ones_exp * X', ones.shape, '*', X.shape, '= ',rep_X.shape)\n",
    "    # print(' ones_exp * Y', ones.shape, '*', Y.shape, '= ',rep_Y.shape)\n",
    "\n",
    "    # # stack the X and Y grids \n",
    "    bef_pos = tf.to_float(tf.stack([rep_X,rep_Y], axis = -1))\n",
    "    # print(' before transpse ', bef_pos.get_shape())\n",
    "    pos_grid = tf.transpose(bef_pos,[2,3,0,1,4])\n",
    "    print('    after transpose ', pos_grid.get_shape())    \n",
    "\n",
    "    # pt2_reshape = tf.reshape( in_tensor , [batch_size, num_classes * rois_per_image ,8])\n",
    "    # print('    pt2_reshape shape is : ', pt2_reshape.get_shape())\n",
    "    # print(pt2_reshape[0].eval())\n",
    "    # print(pt2_reshape[1].eval())\n",
    "    # print(pt2_reshape[2].eval())\n",
    "\n",
    "    #-----------------------------------------------------------------------------    \n",
    "    ## Stack non_zero bboxes from in_tensor into pt2_dense \n",
    "    ##  identify rows that have a non_zero bbox (pt2_sum > 0)\n",
    "    ##  get the indices  pt2_ind \n",
    "    #-----------------------------------------------------------------------------\n",
    "    pt2_sum = tf.reduce_sum(tf.abs(in_tensor[:,:,:,:-2]), axis=-1)\n",
    "    print('    pt2_sum shape ',pt2_sum.shape)\n",
    "    # print(pt2_sum[0].eval())\n",
    "\n",
    "    pt2_mask = tf.greater(pt2_sum , 0)\n",
    "    # print(' pt2_mask shape ', pt2_mask.get_shape())\n",
    "    # print(pt2_mask.eval())\n",
    "\n",
    "    # pt2_ind shape is [?, 3]. \n",
    "    #   pt2_ind[0] corresponds to image_index \n",
    "    #   pt2_ind[1] corresponds to class_index \n",
    "    #   pt2_ind[2] corresponds to roi row_index \n",
    "    pt2_ind  = tf.where(pt2_mask)\n",
    "    print('    pt2_ind shape ', pt2_ind.get_shape())\n",
    "    print(pt2_ind.eval())\n",
    "    # pt2_ind_float  =  tf.to_float(pt2_ind[:,0:1])\n",
    "\n",
    "    # pt2_dense shape is [?, 6]\n",
    "    #    pt2_dense[0] is image index\n",
    "    #    pt2_dense[1:4]  roi cooridnaytes \n",
    "    #    pt2_dense[5]    is class id \n",
    "    pt2_dense = tf.gather_nd( in_tensor, pt2_ind)\n",
    "\n",
    "    # append image index to front of rows - REMOVED 1-5-2018\n",
    "    #  pt2_dense = tf.concat([tf.to_float(pt2_ind[:,0:1]), pt2_dense],axis=1)\n",
    "    print('    dense shape ',pt2_dense.get_shape())\n",
    "    print(pt2_dense.eval())\n",
    "\n",
    "    ## split pt2_dense by pt2_ind[:,0], which identifies the image \n",
    "    stacked_list = tf.dynamic_partition(pt2_dense, tf.to_int32(pt2_ind[:,0]), num_partitions = batch_size )\n",
    "\n",
    "    \n",
    "    #-----------------------------------------------------------------------------\n",
    "    ##  Build Stacked output from dynamically partitioned lists \n",
    "    #-----------------------------------------------------------------------------\n",
    "    print('    Build Stacked output from dynamically partitioned lists --------------')  \n",
    "\n",
    "    stacked_output=[]\n",
    "    for img, item  in enumerate(stacked_list) : \n",
    "        rois_in_image  = tf.shape(item)[0]\n",
    "        pad_item =  tf.pad(item,[[0, rois_per_image - rois_in_image ],[0,0]])\n",
    "        stacked_output.append(pad_item)\n",
    "    stacked_tensor = tf.stack(stacked_output)\n",
    "\n",
    "    # print()    \n",
    "    # print('   -- Stacked output contents --------------')    \n",
    "    # print('    stacked_output shape : ', len(stacked_output))\n",
    "    # for img, item  in enumerate(stacked_output) :\n",
    "        # print('   img ', img, ' stacked_list[img] ', tf.shape(item).eval() ) \n",
    "    # print('   stacked_tensor shape : ', tf.shape(stacked_tensor).eval())\n",
    "    rnd_tensor = tf.floor(stacked_tensor[:,:,:4])    \n",
    "\n",
    "    #-----------------------------------------------------------------------------\n",
    "    ##  Build mean and convariance tensors for Multivariate Normal Distribution \n",
    "    #-----------------------------------------------------------------------------\n",
    "    width  = stacked_tensor[:,:,3] - stacked_tensor[:,:,1]      # x2 - x1\n",
    "    height = stacked_tensor[:,:,2] - stacked_tensor[:,:,0]\n",
    "    cx     = stacked_tensor[:,:,1] + ( width  / 2.0)\n",
    "    cy     = stacked_tensor[:,:,0] + ( height / 2.0)\n",
    "    means  = tf.stack((cx,cy),axis = -1)\n",
    "    covar  = tf.stack((width * 0.5 , height * 0.5), axis = -1)\n",
    "    covar  = tf.sqrt(covar)\n",
    "\n",
    "    tfd = tf.contrib.distributions\n",
    "    mvn = tfd.MultivariateNormalDiag( loc  = means,  scale_diag = covar)\n",
    "    prob_grid = mvn.prob(pos_grid)\n",
    "    prob_grid = tf.transpose(prob_grid,[2,3,0,1])\n",
    "\n",
    "    # print('    means shape :', means.get_shape(),' covar shape ', covar.get_shape())\n",
    "    # print('    from MVN    : mns shape      : ', means.shape, means.get_shape())\n",
    "    # print('    from MVN    : cov shape      : ', covar.shape, covar.get_shape())\n",
    "    # print('    from MVN    : mean shape     : ', mvn.mean().get_shape(), '\\t stddev shape', mvn.stddev().get_shape())\n",
    "    # print('    from MVN    : mvn.batch_shape: ', mvn.batch_shape , '\\t mvn.event_shape ',  mvn.event_shape)\n",
    "    # print('    from Linear : op shape       : ', mvn.scale.shape, ' Linear Op batch shape ',mvn.scale.batch_shape)\n",
    "    # print('    from Linear : op Range Dim   : ', mvn.scale.range_dimension)\n",
    "    # print('    from Linear : op Domain Dim  : ', mvn.scale.domain_dimension) \n",
    "    print('    >> input to MVN.PROB: pos_grid (meshgrid) shape: ', pos_grid.get_shape())\n",
    "    print('    << output probabilities shape:' , prob_grid.get_shape())\n",
    "    # print(prob_grid.eval())\n",
    "    \n",
    "    #--------------------------------------------------------------------------------\n",
    "    # kill distributions of NaN boxes (resulting from bboxes with height/width of zero\n",
    "    # which cause singular sigma cov matrices\n",
    "    #--------------------------------------------------------------------------------\n",
    "    gauss_grid = tf.where(tf.is_nan(prob_grid),  tf.zeros_like(prob_grid), prob_grid)\n",
    "\n",
    "    \n",
    "    #--------------------------------------------------------------------------------\n",
    "    ## scatter out the probability distributions based on class\n",
    "    #--------------------------------------------------------------------------------\n",
    "    print('\\n    Scatter out the probability distributions based on class --------------')     \n",
    "    class_inds      = tf.to_int32(stacked_tensor[:,:,-2])   # - should be -2 since class moved to that postion\n",
    "    batch_grid, roi_grid = tf.meshgrid( tf.range(batch_size, dtype=tf.int32), tf.range(rois_per_image, dtype=tf.int32),\n",
    "                                        indexing = 'ij' )\n",
    "    scatter_classes = tf.stack([batch_grid, class_inds, roi_grid ],axis = -1)\n",
    "    gauss_scatt     = tf.scatter_nd(scatter_classes, gauss_grid, [batch_size, num_classes, rois_per_image, img_w, img_h])\n",
    "\n",
    "    print('    gaussian_grid      : ', gauss_grid.shape)    \n",
    "    print('    class shape        : ', class_inds.shape)\n",
    "    print('    roi_grid shape     : ', roi_grid.get_shape() )\n",
    "    print('    batch_grid shape   : ', batch_grid.get_shape())\n",
    "    print('    scatter_classes    : ', scatter_classes.get_shape())\n",
    "    print('    gaussian scattered : ', gauss_scatt.shape)   \n",
    "    \n",
    "    ## sum based on class -----------------------------------------------------------------\n",
    "    print('\\n    Reduce sum based on class ---------------------------------------------')         \n",
    "    gauss_sum = tf.reduce_sum(gauss_scatt, axis=2, name='pred_gaussian')\n",
    "    gauss_sum = tf.where(gauss_sum > 1e-6, gauss_sum,tf.zeros_like(gauss_sum))\n",
    "    gauss_sum = tf.transpose(gauss_sum,[0,2,3,1], name = names[0])\n",
    "    print('    gaussian sum type/name : ', type(gauss_sum), gauss_sum.name, names[0])\n",
    "    print('    gaussian_sum shape     : ', gauss_sum.get_shape(), 'Keras tensor ', KB.is_keras_tensor(gauss_sum) )    \n",
    "\n",
    "    # L2 normalization  -----------------------------------------------------------------\n",
    "    # print('\\n    L2 normalization ------------------------------------------------------')         \n",
    "    \n",
    "    # gauss_flatten = KB.reshape(gauss_sum, [tf.shape(gauss_sum)[0], -1, tf.shape(gauss_sum)[-1]] )\n",
    "    # gauss_norm    = KB.l2_normalize(gauss_flatten, axis = 1)\n",
    "    # gauss_norm    = KB.reshape(gauss_norm, KB.shape(gauss_sum))\n",
    "    # print('    Shape of guassian_flattened  : ', KB.int_shape(gauss_flatten), 'Keras tensor ', KB.is_keras_tensor(gauss_flatten) )\n",
    "    # print('    Shape of L2 normalized tensor: ', KB.int_shape(gauss_norm), 'Keras tensor ', KB.is_keras_tensor(gauss_norm) )\n",
    "    # print('    complete')\n",
    "\n",
    "    return  gauss_sum    # [gauss_sum, gauss_scatt, means, covar]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T18:47:45.295315Z",
     "start_time": "2018-05-04T18:47:43.522731Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    gauss_sum = development_build_gaussian_tf(KB.constant(pred_tensor), model.config, names = ['Dev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T18:45:24.329314Z",
     "start_time": "2018-05-04T18:45:24.062578Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    print(pred_tensor[1])\n",
    "#     rnd = tf.floor(pred_tensor)\n",
    "#     print(rnd[1].eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    rnd_tensor = tf.floor(stacked_tensor)    \n",
    "    sum_tensor = tf.reduce_sum(tf.abs(rnd_tensor[:,:,:4]), axis=-1)\n",
    "    non_zero   = tf.cast(sum_tensor, tf.bool)\n",
    "    non_zero_exp = tf.expand_dims(non_zero, axis =-1)\n",
    "    \n",
    "    print(' rnd_tensor :', tf.shape(rnd_tensor).eval())\n",
    "    print(' sum_tensor :', tf.shape(sum_tensor).eval())\n",
    "    print(' non_zero   :', tf.shape(non_zero).eval())\n",
    "    print(' non_zero_exp:', tf.shape(non_zero_exp).eval())\n",
    "    non_zero_exp = KB.repeat_elements(non_zero_exp, 6, axis=-1)\n",
    "    print(' non_zero_exp:', tf.shape(non_zero_exp).eval())\n",
    "    nz_tensor  = tf.boolean_mask(rnd_tensor, non_zero_exp, axis = -1)\n",
    "    print(' nz_tensor  :', tf.shape(nz_tensor).eval())\n",
    "\n",
    "#     print(stacked_tensor[0].eval())\n",
    "    print(rnd_tensor[0].eval())\n",
    "    print()\n",
    "#     print(stacked_tensor[1].eval())\n",
    "    print(rnd_tensor[1].eval())\n",
    "    print()\n",
    "#     print(stacked_tensor[2].eval())\n",
    "    print(rnd_tensor[2].eval())\n",
    "    \n",
    "    print(sum_tensor[1].eval())    \n",
    "    print(non_zero[1].eval())    \n",
    "#     non_zeros = tf.cast(tf.reduce_sum(tf.abs(rnd_tensor), axis=1), tf.bool)\n",
    "    print(non_zero_exp[1].eval())    \n",
    "\n",
    "    print(nz_tensor[1].eval())\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "###  Test `means`, `covar`, `gauss_grid`, and `gauss_sum ` between development version and final version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:10:10.133108Z",
     "start_time": "2018-05-02T11:10:09.386212Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "print(means.get_shape(), means.get_shape())\n",
    "tst1 = means.eval()\n",
    "tst2 = means2.eval()\n",
    "print(tst1.shape, tst2.shape)\n",
    "\n",
    "print(tst1[0,:10])\n",
    "print()\n",
    "print(tst2[0,:10])\n",
    "print(np.all(tst1 == tst2))\n",
    "print()\n",
    "del tst1, tst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:10:14.482950Z",
     "start_time": "2018-05-02T11:10:14.205020Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tst1 = st.eval()\n",
    "tst2 = st2.eval()\n",
    "print(tst1.shape, tst2.shape)\n",
    "\n",
    "print(tst1[0,:10])\n",
    "print()\n",
    "print(tst2[0,:10])\n",
    "print(np.all(tst1 == tst2))\n",
    "print()\n",
    "del tst1, tst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:10:18.158709Z",
     "start_time": "2018-05-02T11:10:17.474806Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tst1 = gauss_grid.eval()\n",
    "tst2 = gauss_grid2.eval()\n",
    "print(tst1.shape, tst2.shape)\n",
    "\n",
    "print(tst1[0,0,:10])\n",
    "print()\n",
    "print(tst2[0,0,:10])\n",
    "print(np.all(tst1 == tst2))\n",
    "# print()\n",
    "del tst1, tst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:10:23.859635Z",
     "start_time": "2018-05-02T11:10:23.164182Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tst1 = gauss_sum.eval()\n",
    "tst2 = gauss_sum2.eval()\n",
    "print(tst1.shape, tst2.shape)\n",
    "\n",
    "# print(tst1[0,0,:10])\n",
    "# print()\n",
    "# print(tst2[0,0,:10])\n",
    "print(np.all(tst1 == tst2))\n",
    "# print()\n",
    "del tst1, tst2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "###  Compute mean and max OF `gauss_grid()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T10:04:30.778443Z",
     "start_time": "2018-05-02T10:04:08.500Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(gauss_grid.shape)\n",
    "for img in [0,1,2]:\n",
    "    for bbx in range(32):\n",
    "        gauss_mean = KB.mean(gauss_grid[img, bbx,:,:]).eval()\n",
    "        gauss_min  = KB.min(gauss_grid[img, bbx,:,:]).eval()\n",
    "        gauss_max  = KB.max(gauss_grid[img, bbx,:,:]).eval()\n",
    "#         prob    = stacked_tensor[img,bbx,-1].eval() 'prob: ',prob ,\n",
    "        print('Img/bbx: {}/{}     Mean:  {:6e}  \\t Max: {:6e}  \\t Min : {:6e}'.format(img, bbx, gauss_mean, gauss_max, gauss_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "###  Compute mean and max OF `gauss_grid2()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T10:04:30.776944Z",
     "start_time": "2018-05-02T10:03:27.542792Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(gauss_grid2.shape)\n",
    "for img in [0,1,2]:\n",
    "    for bbx in range(32):\n",
    "        gauss_mean = KB.mean(gauss_grid2[img, bbx,:,:]).eval()\n",
    "        gauss_min  = KB.min(gauss_grid2[img, bbx,:,:]).eval()\n",
    "        gauss_max  = KB.max(gauss_grid2[img, bbx,:,:]).eval()\n",
    "#         prob    = stacked_tensor[img,bbx,-1].eval() 'prob: ',prob ,\n",
    "        print('Img/bbx: {}/{}     Mean:  {:6e}  \\t Max: {:6e}  \\t Min : {:6e}'.format(img, bbx, gauss_mean, gauss_max, gauss_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "###  Compute `gauss_grid()` and   `gauss_grid2()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:10:39.307514Z",
     "start_time": "2018-05-02T11:10:38.603585Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(gauss_grid2.shape)\n",
    "gauss_max  = KB.max(gauss_grid, axis = [2,3]).eval()\n",
    "gauss_max2  = KB.max(gauss_grid2, axis = [2,3]).eval()\n",
    "\n",
    "for img in [0,1,2]:\n",
    "    for bbx in range(32):\n",
    "\n",
    "#         prob    = stacked_tensor[img,bbx,-1].eval() 'prob: ',prob ,\n",
    "        print('Img/bbx: {}/{}     MAX:  {:6e}  \\t MAX2: {:6e}  \\t Equal : {}'.format(img, bbx, gauss_max[img, bbx],gauss_max2[img,bbx],(gauss_max[img,bbx]== gauss_max2[img,bbx])))\n",
    "del gauss_max, gauss_max2    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Compute `gauss_sum()` and  `gauss_sum2()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:10:52.883112Z",
     "start_time": "2018-05-02T11:10:52.154331Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "print(gauss_sum.shape, gauss_sum2.shape)\n",
    "# print(gauss_grid2.shape)\n",
    "tst1 = tf.transpose(gauss_sum, [0,3,1,2])\n",
    "tst2 = tf.transpose(gauss_sum2, [0,3,1,2])\n",
    "print(tst1.shape, tst2.shape)\n",
    "\n",
    "gauss_max1 = KB.max(tst1, axis = [2,3]).eval()\n",
    "gauss_max2 = KB.max(tst2, axis = [2,3]).eval()\n",
    "print(gauss_max1.shape, gauss_max2.shape)\n",
    "\n",
    "# gauss_max2  = KB.max(gauss_grid2, axis = [2,3]).eval()\n",
    "\n",
    "for img in [0,1,2]:\n",
    "    for bbx in range(4):\n",
    "        print('Img/bbx: {}/{}     MAX:  {:6e}  \\t MAX2: {:6e}  \\t Equal : {}'.format(img, bbx, gauss_max1[img, bbx],gauss_max2[img,bbx],(gauss_max1[img,bbx]== gauss_max2[img,bbx])))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T10:58:45.332214Z",
     "start_time": "2018-05-02T10:58:44.117193Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "for img in [0,1,2]:\n",
    "    for bbx in range(4):\n",
    "        print('Img/bbx: {}/{}    Equal : {}'.format(img, bbx, (tst1[img,bbx]==  tst2[img,bbx])))\n",
    "del gauss_max1, gauss_max2    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "\n",
    "###  Compute mean and max OF `gauss_sum2()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T09:55:59.702691Z",
     "start_time": "2018-05-02T09:55:42.231847Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(gauss_sum2.shape)\n",
    "for img in [0,1,2]:\n",
    "    for cls in range(4):\n",
    "        gauss_mean = KB.mean(gauss_sum2[img,:,:,cls]).eval()\n",
    "        gauss_min  = KB.min(gauss_sum2[img, :,:,cls]).eval()\n",
    "        gauss_max  = KB.max(gauss_sum2[img, :,:,cls]).eval()\n",
    "        print('Img/bbx: ', img, '/',cls ,'   Mean: ', gauss_mean, '\\t Max: ' , gauss_max, '\\t Min :', gauss_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Compute min and max of `gauss_sum()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T09:57:11.807587Z",
     "start_time": "2018-05-02T09:56:55.286325Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "print(gauss_sum.shape)\n",
    "for img in [0,1,2]:\n",
    "    for cls in range(4):\n",
    "        gauss_mean = KB.mean(gauss_sum[img,:,:,cls]).eval()\n",
    "        gauss_min  =  KB.min(gauss_sum[img, :,:,cls]).eval()\n",
    "        gauss_max  =  KB.max(gauss_sum[img, :,:,cls]).eval()\n",
    "        print('Img/bbx: ', img, '/',cls ,'   Mean: ', gauss_mean, '\\t Max: ' , gauss_max, '\\t Min :', gauss_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T08:44:41.071788Z",
     "start_time": "2018-05-02T08:44:33.434419Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "pred_gauss = tf.constant(layers_out[19])\n",
    "print(pred_gauss.shape)\n",
    "for img in [0,1,2]:\n",
    "    for cls in range(4):\n",
    "        gauss_mean = KB.mean(pred_gauss[img,:,:,cls]).eval()\n",
    "        gauss_min  = KB.min(pred_gauss[img, :,:,cls]).eval()\n",
    "        gauss_max  = KB.max(pred_gauss[img, :,:,cls]).eval()\n",
    "        print('Img/bbx: ', img, '/',cls ,'   Mean: ', gauss_mean, '\\t Max: ' , gauss_max, '\\t Min :', gauss_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "\n",
    "## Plot Predicted  Heatmaps `pred_gaussian` \n",
    "\n",
    "`pred_gaussian2` and `gt_gaussian2` from Tensorflow PCN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:14:01.486755Z",
     "start_time": "2018-05-02T11:13:59.680438Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# gt_heatmap  = layers_out[27]     # gt_gaussiam \n",
    "# pred_heatmap= layers_out[24]  # pred_gaussian\n",
    "# gt_heatmap  = gauss_sum.eval()    # gt_gaussiam \n",
    "gt_heatmap  = layers_out[18]     # gt_gaussiam \n",
    "\n",
    "pred_heatmap= gauss_sum2.eval()  # pred_gaussian\n",
    "print('gt_gaussian heatmap shape : ', gt_heatmap.shape, ' pred_gaussian heatmap shape: ', pred_heatmap.shape)\n",
    "num_images = 1 # config.IMAGES_PER_GPU\n",
    "num_classes = config.NUM_CLASSES\n",
    "\n",
    "img = 0\n",
    "\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "print('Classes (1: circle, 2: square, 3: triangle ): ')\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "\n",
    "for cls in range(1,num_classes):\n",
    "    ttl = 'GROUND TRUTH HEATMAP - image :  {} class: {} '.format(img,cls)\n",
    "    print(' *** Zout  ', gt_heatmap[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian( gt_heatmap[img,:,:,cls], title = ttl)\n",
    "    \n",
    "    ttl = 'PREDICTED heatmap  - image :  {} class: {} '.format(img,cls)     \n",
    "    print(' *** pred_heatmap ', pred_heatmap[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian(pred_heatmap[img,:,:,cls], title = ttl)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "\n",
    "## Plot Predicted  Heatmaps `pred_gaussian` \n",
    "\n",
    "`pred_gaussian2` and `gt_gaussian2` from Tensorflow PCN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# gt_heatmap  = layers_out[27]     # gt_gaussiam \n",
    "# pred_heatmap= layers_out[24]  # pred_gaussian\n",
    "gt_heatmap  = layers_out[19]     # gt_gaussiam \n",
    "pred_heatmap= layers_out[18]  # pred_gaussian\n",
    "print('gt_gaussian heatmap shape : ', gt_heatmap.shape, ' pred_gaussian heatmap shape: ', pred_heatmap.shape)\n",
    "num_images = 1 # config.IMAGES_PER_GPU\n",
    "num_classes = config.NUM_CLASSES\n",
    "\n",
    "img = 0\n",
    "\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "print('Classes (1: circle, 2: square, 3: triangle ): ')\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "\n",
    "for cls in range(1,num_classes):\n",
    "    ttl = 'GROUND TRUTH HEATMAP - image :  {} class: {} '.format(img,cls)\n",
    "    print(' *** Zout  ', gt_heatmap[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian( gt_heatmap[img,:,:,cls], title = ttl)\n",
    "    \n",
    "    ttl = 'PREDICTED heatmap  - image :  {} class: {} '.format(img,cls)     \n",
    "    print(' *** pred_heatmap ', pred_heatmap[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian(pred_heatmap[img,:,:,cls], title = ttl)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "\n",
    "## Plot Predicted and Ground Truth Probability Heatmaps `pred_gaussian` and `gt_gaussian` (Tensorflow)\n",
    "\n",
    "`pred_gaussian2` and `gt_gaussian2` from Tensorflow PCN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# gt_heatmap  = layers_out[27]     # gt_gaussiam \n",
    "# pred_heatmap= layers_out[24]  # pred_gaussian\n",
    "gt_heatmap  = layers_out[19]     # gt_gaussiam \n",
    "pred_heatmap= layers_out[18]  # pred_gaussian\n",
    "print('gt_gaussian heatmap shape : ', gt_heatmap.shape, ' pred_gaussian heatmap shape: ', pred_heatmap.shape)\n",
    "num_images = 1 # config.IMAGES_PER_GPU\n",
    "num_classes = config.NUM_CLASSES\n",
    "\n",
    "img = 0\n",
    "\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "print('Classes (1: circle, 2: square, 3: triangle ): ')\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "\n",
    "for cls in range(1,num_classes):\n",
    "    ttl = 'GROUND TRUTH HEATMAP - image :  {} class: {} '.format(img,cls)\n",
    "    print(' *** Zout  ', gt_heatmap[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian( gt_heatmap[img,:,:,cls], title = ttl)\n",
    "    \n",
    "    ttl = 'PREDICTED heatmap  - image :  {} class: {} '.format(img,cls)     \n",
    "    print(' *** pred_heatmap ', pred_heatmap[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian(pred_heatmap[img,:,:,cls], title = ttl)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "###  Softmax Sparse Cross Entropy Ignoring Last Label -- Used in Keras FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T07:53:31.114036Z",
     "start_time": "2018-04-27T07:53:30.853311Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K \n",
    "\n",
    "y_pred = tf.placeholder(dtype=tf.float32, shape=(16,320,320,20))\n",
    "y_true = tf.placeholder(dtype=tf.float32, shape=(16,320,320,1))\n",
    "print(K.int_shape(y_pred), K.int_shape(y_true))\n",
    "y_pred = K.reshape(y_pred, (-1, K.int_shape(y_pred)[-1]))\n",
    "print(K.int_shape(y_pred))\n",
    "log_softmax = tf.nn.log_softmax(y_pred)\n",
    "print(K.int_shape(log_softmax))\n",
    "\n",
    "y_true = K.flatten(y_true)\n",
    "print(K.int_shape(y_true))\n",
    "\n",
    "y_true = K.one_hot(tf.to_int32(y_true), K.int_shape(y_pred)[-1]+1)\n",
    "print(K.int_shape(y_true))\n",
    "\n",
    "unpacked = tf.unstack(y_true, axis=-1)\n",
    "print(len(unpacked), unpacked[0].shape)\n",
    "\n",
    "y_true = tf.stack(unpacked[:-1], axis=-1)\n",
    "print(K.int_shape(y_true))\n",
    "\n",
    "\n",
    "cross_entropy = -K.sum(y_true * log_softmax, axis=1)\n",
    "print(K.int_shape(cross_entropy))\n",
    "\n",
    "cross_entropy_mean = K.mean(cross_entropy)\n",
    "print(K.int_shape(cross_entropy_mean))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import keras.backend as K\n",
    "# print(K.int_shape(bef_pos)[-1])\n",
    "# unpacked  = K.flatten(test)\n",
    "# unpacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T08:11:57.244128Z",
     "start_time": "2018-04-27T08:11:57.021539Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# pos_grid_1[:,:,0,0,:].eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T23:19:54.102900Z",
     "start_time": "2018-04-16T23:19:53.889289Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Experimental code to Create mask for class bounding boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T08:37:04.047619Z",
     "start_time": "2018-04-17T08:37:03.810018Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "print(gauss_scatt.shape)\n",
    "print(gauss_grid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T08:44:16.866844Z",
     "start_time": "2018-04-17T08:44:16.635221Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "mask_arr = tf.zeros_like(gauss_grid)\n",
    "mask = mask_arr[0]\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T08:44:30.822194Z",
     "start_time": "2018-04-17T08:44:30.147674Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "boxes = tf.round(stacked_tensor[0,:,1:5]).eval()\n",
    "boxes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T08:42:48.813538Z",
     "start_time": "2018-04-17T08:42:48.588945Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "##-----------------------------------------------------------------------------\n",
    "## Build mesh-grid to hold pixel coordinates \n",
    "##-----------------------------------------------------------------------------\n",
    "X = tf.range(img_w, dtype=tf.int32)\n",
    "Y = tf.range(img_h, dtype=tf.int32)\n",
    "X, Y = tf.meshgrid(X, Y)\n",
    "# grid1 = tf.stack([X,Y], axis=-1)\n",
    "# print('grid1 shape ', grid1.shape)\n",
    "# print(grid1[0,:,:].eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "###  Comparing Scipy / Tensorflow Multivar normal distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T10:10:11.958301Z",
     "start_time": "2018-04-16T10:10:10.121532Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "tfd        = tf.contrib.distributions\n",
    "grid       = pos_grid_1[:,:,0,0,:]\n",
    "covar      = np.array([27.7818, 26.6678],dtype = np.float32)\n",
    "covar_sqrt = np.sqrt(covar)\n",
    "covar_sqrd = covar ** 2\n",
    "full_covar = np.array([[27.7818, 0],[0, 26.6678]],dtype = np.float32)\n",
    "mean       = np.array([48.8926, 36.101 ],dtype = np.float32)\n",
    "\n",
    "print('   grid :', grid.dtype, grid.shape)\n",
    "print('   Covar sqrt :', covar_sqrt)\n",
    "print('   Covar sqrd :', covar_sqrd)\n",
    "\n",
    "mvn1  = tfd.MultivariateNormalDiag(loc=mean,scale_diag=covar_sqrt)\n",
    "prob1 = mvn1.prob(grid2)\n",
    "print()\n",
    "print('   mvn1 mean             ', mvn1.mean().eval())\n",
    "print('   mvn1 std deviation    ', mvn1.stddev().eval())\n",
    "print('   mvn1 covariance:      ', '\\n', mvn1.covariance().eval())\n",
    "print('   mvn1 location         ', mvn1.loc.eval())\n",
    "print('   Linear OP shape       ', mvn1.scale.shape)\n",
    "print('   Linear Op batch shape ', mvn1.scale.batch_shape)\n",
    "print('   Linear op Range Dim   ', mvn1.scale.range_dimension)\n",
    "print('   Linear op Domain Dim  ', mvn1.scale.domain_dimension) \n",
    "print('   Linear op Domain Dim  ', mvn1.scale.diag_part().eval()) \n",
    "\n",
    "mvn2  = tfd.MultivariateNormalDiag(loc=mean,scale_diag=covar)\n",
    "prob2 = mvn2.prob(grid2)\n",
    "print()\n",
    "print('   mvn2 mean             ', mvn2.mean().eval())\n",
    "print('   mvn2 std deviation    ', mvn2.stddev().eval())\n",
    "print('   mvn2 covariance:      ', '\\n', mvn2.covariance().eval())\n",
    "print('   mvn2 location         ', mvn2.loc.eval())\n",
    "print('   Linear OP shape       ', mvn2.scale.shape)\n",
    "print('   Linear Op batch shape ', mvn2.scale.batch_shape)\n",
    "print('   Linear op Range Dim   ', mvn2.scale.range_dimension)\n",
    "print('   Linear op Domain Dim  ', mvn2.scale.domain_dimension) \n",
    "print('   Linear op Domain Dim  ', mvn2.scale.diag_part().eval()) \n",
    "\n",
    "\n",
    "mvn3  = tfd.MultivariateNormalFullCovariance( loc = mean, covariance_matrix = full_covar)\n",
    "prob3 = mvn3.prob(grid2)\n",
    "print()\n",
    "print('   mvn3 mean             ', mvn3.mean().eval())\n",
    "print('   mvn3 std deviation    ', mvn3.stddev().eval())\n",
    "print('   mvn3 covariance:      ', '\\n', mvn3.covariance().eval())\n",
    "print('   mvn3 location         ', mvn3.loc.eval())\n",
    "print('   Linear OP shape       ', mvn3.scale.shape)\n",
    "print('   Linear Op batch shape ', mvn3.scale.batch_shape)\n",
    "print('   Linear op Range Dim   ', mvn3.scale.range_dimension)\n",
    "print('   Linear op Domain Dim  ', mvn3.scale.domain_dimension) \n",
    "print('   Linear op Domain Dim  ', mvn3.scale.diag_part().eval()) \n",
    "\n",
    "print('   << output probabilities shape:' )\n",
    "print(' prob1 ', prob1.get_shape())\n",
    "print(prob1.eval())\n",
    "print(' prob2 ', prob2.get_shape())\n",
    "print(prob2.eval())\n",
    "print(' prob3 ', prob3.get_shape())\n",
    "print(prob3.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T09:59:30.850107Z",
     "start_time": "2018-04-16T09:59:30.182014Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, threshold=10000)\n",
    "from scipy.stats import  multivariate_normal\n",
    "# Build mesh-grid to hold pixel coordinates ----------------------------------\n",
    "XX = np.arange(0, img_w, 1)\n",
    "YY = np.arange(0, img_h, 1)\n",
    "XX, YY = np.meshgrid(XX, YY)\n",
    "pos  = np.empty(XX.shape + (2,))   # concatinate shape of x to make ( x.rows, x.cols, 2)\n",
    "pos[:,:,0] = XX;\n",
    "pos[:,:,1] = YY;\n",
    "# print(XX)\n",
    "# print(YY)\n",
    "# print(pos[0,:,:])\n",
    "# print(pos[0])\n",
    "# print(grid[0].eval())\n",
    "print(' pos type    ', type(pos), type(grid))\n",
    "print(' grid shape ', pos.shape, grid.shape)\n",
    "print(np.all(pos == grid.eval()))\n",
    "print(' mean  ', mean)\n",
    "print(' covar ', covar)\n",
    "mvna    = multivariate_normal(mean, covar)\n",
    "prob_a = mvna.pdf(pos)\n",
    "\n",
    "mvnb = multivariate_normal(mean, covar_sqrd)\n",
    "prob_b = mvnb.pdf(pos)\n",
    "\n",
    "print(prob_a[35:50, 45:54])\n",
    "max_a = np.max(prob_a)\n",
    "print(np.unravel_index(np.argmax(prob_a) , prob_a.shape) )\n",
    "\n",
    "print()\n",
    "\n",
    "print(' covar ', covar_sqrd)\n",
    "print(prob_b[35:50, 45:54])\n",
    "max_b = np.max(prob_b)\n",
    "print(np.unravel_index(np.argmax(prob_b) , prob_b.shape) )\n",
    "\n",
    "print('max a , max_b ', max_a, max_b, max_a/max_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "###  Build indicies to gather bounding boxes from bboxes_4d corrsponding to predicted class\n",
    "#### Only used if we want to use mrcnn_bboxes (batch_size, num_rois, num_classes, 4)\n",
    "\n",
    "batch_size x nuum_detections x 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "###  Build indicies to gather bounding boxes from bboxes_4d corrsponding to predicted class\n",
    "###  Only used if we want to use mrcnn_bboxes (batch_size, num_rois, num_classes, 4)\n",
    "\n",
    "# gather_boxes = tf.stack([batch_grid, roi_grid, pred_classes, ], axis = -1)\n",
    "\n",
    "# print('-- gather_boxes  ----')\n",
    "# print('gather_boxes inds', type(gather_boxes), 'shape',tf.shape(gather_boxes).eval())\n",
    "# print(gather_boxes.eval())\n",
    "\n",
    "# mrcnn_bboxes_selected = tf.gather_nd(mrcnn_bboxes, gather_boxes)\n",
    "# print(' padding required for output_rois : ', mrcnn_bboxes_selected.get_shape())\n",
    "# print(mrcnn_bboxes_selected[0].eval())\n",
    "\n",
    "# print(' output_rois shape ', output_rois.get_shape())\n",
    "# print(pred_classes[0].eval())\n",
    "# print(output_rois[0].eval())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Experimental Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "###  Experiment for sort ordering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indices = tf.constant([\n",
    "            [[0,2],[0,1],[0,0]],\n",
    "            [[1,2],[1,1],[1,0]],\n",
    "            [[2,0],[2,1],[2,1]],\n",
    "          ])\n",
    "params = tf.constant( [\n",
    "          [['0-00', '0-01', '0-02', '0-03'], \n",
    "           ['0-10', '0-11', '0-12', '0-13'],\n",
    "           ['0-20', '0-21', '0-22', '0-23'],\n",
    "           ['0-30', '0-31', '0-32', '0-33']],\n",
    "    \n",
    "          [['1-00', '1-01', '1-02', '1-03'], \n",
    "           ['1-10', '1-11', '1-12', '1-13'],\n",
    "           ['1-20', '1-21', '1-22', '1-23'],\n",
    "           ['1-30', '1-31', '1-32', '1-33']],\n",
    "    \n",
    "          [['2-00', '2-01', '2-02', '2-03'], \n",
    "           ['2-10', '2-11', '2-12', '2-13'],\n",
    "           ['2-20', '2-21', '2-22', '2-23'],\n",
    "           ['2-30', '2-31', '2-32', '2-33']]    \n",
    "         ])\n",
    "print(params.shape, '   ', indices.shape)\n",
    "res = tf.gather_nd(params, indices)\n",
    "res.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "###  Experiment with GATHER() for splitting into classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# indices = tf.constant([\n",
    "#             [0,2,2],[0,1,1],[0,0,0],\n",
    "#             [1,2,2],[1,1,1],[1,0,0],\n",
    "#             [2,0,0],[2,1,1],[2,1,1],\n",
    "#            ])\n",
    "# indices = tf.constant([ [0,2],[0,1],[0,0],[1,2],[1,1],[1,0],[1,2],[1,3], [2,3]] ) # 9 x 2\n",
    "indices = tf.constant([\n",
    "           [\n",
    "            [[0,2],[0,1],[0,0],[1,2],[2,3]],\n",
    "            [[1,1],[1,0],[1,2],[1,3],[1,1]]\n",
    "           ]\n",
    "           ])\n",
    "params = tf.constant( [\n",
    "          [['0-00', '0-01', '0-02', '0-03', '0-04', '0-05', '0-06'], \n",
    "           ['0-10', '0-11', '0-12', '0-13', '0-14', '0-15', '0-16'],\n",
    "           ['0-20', '0-21', '0-22', '0-23', '0-24', '0-25', '0-26'],\n",
    "           ['0-30', '0-31', '0-32', '0-33', '0-34', '0-35', '0-36'],\n",
    "           ['0-40', '0-41', '0-42', '0-43', '0-44', '0-45', '0-46']],\n",
    "                                                          \n",
    "          [['1-00', '1-01', '1-02', '1-03', '1-04', '1-05', '1-06'], \n",
    "           ['1-10', '1-11', '1-12', '1-13', '1-14', '1-15', '1-16'],\n",
    "           ['1-20', '1-21', '1-22', '1-23', '1-24', '1-25', '1-26'],\n",
    "           ['1-30', '1-31', '1-32', '1-33', '1-34', '1-35', '1-36'],\n",
    "           ['1-40', '1-41', '1-42', '1-43', '1-44', '1-45', '1-46']],\n",
    "                                                          \n",
    "          [['2-00', '2-01', '2-02', '2-03', '2-04', '2-05', '2-06'], \n",
    "           ['2-10', '2-11', '2-12', '2-13', '2-14', '2-15', '2-16'],\n",
    "           ['2-20', '2-21', '2-22', '2-23', '2-24', '2-25', '2-26'],\n",
    "           ['2-30', '2-31', '2-32', '2-33', '2-34', '2-35', '2-36'],\n",
    "           ['2-40', '2-41', '2-42', '2-43', '2-44', '2-45', '2-46']]    \n",
    "         ])\n",
    "print(' params sahape: ', params.shape, ' parms[:axis]', params.shape[:0], params.shape[:1], params.shape[:2], params.shape[:3])\n",
    "print(' params sahape: ', params.shape, ' parms[:axis]', params.shape[0:], params.shape[1:], params.shape[2:], params.shape[3:])\n",
    "print(' indices.shape  ', indices.shape)\n",
    "res = tf.gather_nd(params, indices)\n",
    "print('result shape   ', res.get_shape())\n",
    "res.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "###  Experiment with SCATTER() for splitting into classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# del indices, updates, shape\n",
    "\n",
    "indices =  tf.constant([\n",
    "                         #|\n",
    "                         #| \n",
    "                        [[0,0,0], [0,3,0], [0,2,0], [0,1,0],[0,1,1],[0,1,2],[0,2,1],[0,3,2] ],\n",
    "                        [[1,0,0], [1,3,0], [1,2,0], [1,1,0],[1,1,1],[1,1,2],[1,2,1],[1,3,2] ],\n",
    "                        [[2,0,0], [2,3,0], [2,2,0], [2,1,0],[2,1,1],[2,1,2],[2,2,1],[2,3,2] ]\n",
    "])\n",
    "                            #<--- each one corrsponds to an entry in  the updates array [row , position in resulting array]\n",
    "    \n",
    "#                        [[1,1], [3,1], [2,1], [1,1],[1,1],[1,2],[2,1],[3,2] ],\n",
    "#                        [[0,0], [3,0], [2,0], [1,0],[1,1],[1,2],[2,1],[3,2] ]\n",
    "    \n",
    "###----------------------------------------------------\n",
    "### Our bounding box array\n",
    "###---------------------------------------------------\n",
    "updates = tf.constant( [\n",
    "          [[1000, 1001, 1002, 1003, 1004, 1005, 1006], \n",
    "           [1010, 1011, 1012, 1013, 1014, 1015, 1016],\n",
    "           [1020, 1021, 1022, 1023, 1024, 1025, 1026],\n",
    "           [1030, 1031, 1032, 1033, 1034, 1035, 1036],\n",
    "           [1040, 1041, 1042, 1043, 1044, 1045, 1046],\n",
    "           [1050, 1051, 1052, 1053, 1054, 1055, 1056],\n",
    "           [1060, 1061, 1062, 1063, 1064, 1065, 1066],\n",
    "           [1070, 1071, 1072, 1073, 1074, 1075, 1076] ],\n",
    "          \n",
    "          [[2000, 2001, 2002, 2003, 2004, 2005, 2006], \n",
    "           [2010, 2011, 2012, 2013, 2014, 2015, 2016],\n",
    "           [2020, 2021, 2022, 2023, 2024, 2025, 2026],\n",
    "           [2030, 2031, 2032, 2033, 2034, 2035, 2036],\n",
    "           [2040, 2041, 2042, 2043, 2044, 2045, 2046],\n",
    "           [2050, 2051, 2052, 2053, 2054, 2055, 2056],\n",
    "           [2060, 2061, 2062, 2063, 2064, 2065, 2066],\n",
    "           [2070, 2071, 2072, 2073, 2074, 2075, 2076]] , \n",
    "\n",
    "          [[3000, 3001, 3002, 3003, 3004, 3005, 3006], \n",
    "           [3010, 3011, 3012, 3013, 3014, 3015, 3016],\n",
    "           [3020, 3021, 3022, 3023, 3024, 3025, 3026],\n",
    "           [3030, 3031, 3032, 3033, 3034, 3035, 3036],\n",
    "           [3040, 3041, 3042, 3043, 3044, 3045, 3046],\n",
    "           [3050, 3051, 3052, 3053, 3054, 3055, 3056],\n",
    "           [3060, 3061, 3062, 3063, 3064, 3065, 3066],\n",
    "           [3070, 3071, 3072, 3073, 3074, 3075, 3076] ]    \n",
    "         ])                       \n",
    "\n",
    "zeros = tf.zeros([3,4,8,7], dtype=tf.int32)\n",
    "ref   = tf.Variable(zeros)\n",
    "scatt1= tf.Variable(zeros)\n",
    "shape = tf.constant([3,4, 8, 7])\n",
    " \n",
    "# init = tf.global_variables_initializer().run()\n",
    "# print('indices shape ', indices.shape,  'indices_shape [-1]', indices.shape[-1],  'indices_shape [:-1]', indices.shape[:-1])\n",
    "# print('updates.shape ', updates.shape)\n",
    "# print('ref     shape ', ref.get_shape(), ref)\n",
    "# print('scatt1  shape ', scatt1.get_shape(), scatt)\n",
    "\n",
    "scatt1 = tf.scatter_nd(indices, updates, shape)\n",
    "# print('scatt1  shape ', scatt1.get_shape(), scatt)\n",
    "# print(scatt1[0].eval())\n",
    "# print('------------')\n",
    "# print(scatt1[1].eval())\n",
    "# print('------------')\n",
    "# print(scatt1[2].eval())\n",
    "\n",
    "# scatt = tf.scatter_nd_update(ref, indices, updates)\n",
    "# print('scatter shape is ', scatt.get_shape(), scatt)\n",
    "# print(scatt.eval())\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "indices = tf.constant([\n",
    "                        [[0,0], [3,0], [2,0], [1,0]]\n",
    "#                     ,[[1,3], [1,3], [1,2], [1,0]]\n",
    "                      ])\n",
    "updates = tf.constant([\n",
    "                       [[5, 5, 5, 5, 0], \n",
    "                        [6, 6, 6, 6, 3],\n",
    "                        [7, 7, 7, 7, 2], \n",
    "                        [8, 8, 8, 8, 1]]\n",
    "                       \n",
    "#                      , [[5, 5, 5, 3], \n",
    "#                         [6, 6, 6, 3],\n",
    "#                         [7, 7, 7, 2], \n",
    "#                         [8, 8, 8, 0]]\n",
    "                       ])\n",
    "shape = tf.constant([4, 4, 5])\n",
    "print(indices.shape, 'inputs shape', updates.shape, shape.shape)\n",
    "scatter = tf.scatter_nd(indices, updates, shape)\n",
    "print('scatter shape is ', scatter.get_shape())\n",
    "print(scatter.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "num_detections = 8\n",
    "# batch_size is  3\n",
    "gt_class_ids = tf.constant([[1,2,3,0,0,0,0,0],[3,3,3,0,0,0,0,0],[1,2,2,0,0,2,0,0]])\n",
    "gt_bboxes    = tf.random_uniform([batch_size,3,4], maxval = 127, dtype=tf.int32)\n",
    "\n",
    "\n",
    "gt_classes_exp = tf.to_float(tf.expand_dims(gt_class_ids ,axis=-1))\n",
    "print('    gt_classes_exp: ' ,gt_classes_exp.get_shape())\n",
    "print(gt_classes_exp.eval())\n",
    "\n",
    "\n",
    "zeros        = tf.zeros([batch_size,5,4], dtype = tf.int32)\n",
    "gt_bboxes    = tf.concat([gt_bboxes, zeros], axis = 1)\n",
    "gt_bboxes    = tf.to_float(gt_bboxes)\n",
    "print('\\n    gt_bboxes: ' ,gt_bboxes.get_shape())\n",
    "print(gt_bboxes.eval())\n",
    "\n",
    "mask = tf.greater(gt_class_ids,0)\n",
    "print(mask.eval())\n",
    "\n",
    "gt_scores     = tf.where(mask, tf.ones_like(gt_class_ids), tf.zeros_like(gt_class_ids))\n",
    "gt_scores_exp = tf.to_float(tf.expand_dims(gt_scores, axis=-1))\n",
    "print('\\n    gt_scores ', gt_scores_exp.get_shape())\n",
    "print(gt_scores_exp.eval())\n",
    "\n",
    "batch_grid, bbox_grid = tf.meshgrid( tf.range(batch_size    , dtype=tf.int32), \n",
    "                                    tf.range(num_detections , dtype=tf.int32), indexing = 'ij' )\n",
    "\n",
    "print('\\n    bbox_grid   ', type(bbox_grid)  , 'shape', bbox_grid.get_shape())\n",
    "print(bbox_grid.eval())\n",
    "print('\\n    batch_grid ', type(batch_grid), 'shape', batch_grid.get_shape())\n",
    "print(batch_grid.eval())\n",
    " \n",
    "bbox_idx_zeros  = tf.zeros_like(bbox_grid)\n",
    "bbox_idx        = tf.where(mask, bbox_grid , bbox_idx_zeros)\n",
    "bbox_idx        = tf.to_float(tf.expand_dims(bbox_idx, axis = -1))    \n",
    "print('    bbox_idx', type(bbox_idx), 'shape', bbox_idx.get_shape())\n",
    "print(bbox_idx.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "gt_array        = tf.concat([bbox_idx, gt_scores_exp , gt_bboxes, gt_classes_exp], axis=2)\n",
    "print('    gt_array  ',  type(gt_array), gt_array.shape)\n",
    "print(gt_array.eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "scatter_classes = tf.stack([batch_grid , gt_class_ids, bbox_grid],axis = -1)\n",
    "print('\\n    -- stack results ----')\n",
    "print('\\n    scatter_classes', type(scatter_classes), 'shape',tf.shape(scatter_classes).eval())\n",
    "print(scatter_classes.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "gt_scatter = tf.scatter_nd(scatter_classes, gt_array, [batch_size, num_classes, num_detections,7])\n",
    "print('    gt_tensor shape is ', gt_scatter.get_shape(), gt_scatter)\n",
    "gt_scatter.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "sort_vals, sort_inds = tf.nn.top_k(gt_scatter[:,:,:,0], k=gt_scatter.shape[2])\n",
    "print('    sort vals shape : ', sort_vals.get_shape())\n",
    "print(sort_vals.eval())\n",
    "print('    sort inds shape : ', sort_inds.get_shape())\n",
    "print(sort_inds.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# build gathering indexes to use in sorting \n",
    "class_grid, batch_grid, bbox_grid = tf.meshgrid(tf.range(num_classes),tf.range(batch_size), tf.range(num_detections))\n",
    "\n",
    "print('    class_grid  ', type(class_grid) , 'shape', class_grid.get_shape())\n",
    "print(class_grid.eval())\n",
    "print('    batch_grid  ', type(batch_grid) , 'shape', batch_grid.get_shape())\n",
    "print(class_grid.eval())\n",
    "print('    bbox_grid    ', type(bbox_grid) , 'shape', bbox_grid.get_shape())\n",
    "print(bbox_grid.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "gather_inds = tf.stack([batch_grid , class_grid, sort_inds],axis = -1)\n",
    "print('    -- pred_tensor results (A-boxes sorted by score ----')\n",
    "print('    gatehr_inds ', gather_inds.get_shape())\n",
    "print(gather_inds.eval())\n",
    "\n",
    "gt_tensor = tf.gather_nd(gt_scatter, gather_inds)\n",
    "print('    -- pred_tensor results (A-boxes sorted by score ----')\n",
    "print('    pred_tensor ', gt_tensor.get_shape())\n",
    "print(gt_tensor.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false
   },
   "source": [
    "###  Split Box/ Class info for each Image dim(0) by class and place into new tensor using tf.scatter_nd_update\n",
    "###  obsolete -- use tf.scatter_nd instead\n",
    "    Output is converted to NUMN_BATCHES x NUM_CLASSES x num_rois x columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scatt1 = tf.scatter_nd(scatter_inds, pred_array, [batch_size, num_classes, num_rois])\n",
    "# print('scatt1  shape ', scatt1.get_shape(), scatt)\n",
    "\n",
    "# zeros = tf.zeros([batch_size,num_classes, num_rois,7], dtype=tf.float32)\n",
    "# ref   = tf.Variable(zeros)\n",
    "# init = tf.global_variables_initializer().run()\n",
    "\n",
    "# pred_scatt_old = tf.scatter_nd_update(ref, scatter_classes, pred_array)\n",
    "\n",
    "\n",
    "# print('scatter shape is ', pred_scatt.get_shape(), pred_scatt)\n",
    "# print(pred_scatt[0].eval())\n",
    "# print('------------')\n",
    "# print(pred_scatt[1].eval())\n",
    "# print('------------')\n",
    "# print(pred_scatt[2].eval())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false
   },
   "source": [
    "###  Stack non-zero bbox infromaton from pred_array into stacked_array --- method 2 (obsolete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# sep = tf.unstack(pred_tensor)\n",
    "# print(len(sep))\n",
    "# all_boxes = []\n",
    "# for sub_sep in sep:\n",
    "#     p_reduced = tf.reduce_sum(tf.abs(sub_sep), axis=-1)\n",
    "#     print(' p_redcued shape ',p_reduced.shape)\n",
    "# #     print(p_reduced.eval())\n",
    "#     non_zeros = tf.cast(p_reduced, tf.bool)\n",
    "#     print(' mask shape' ,non_zeros.shape) \n",
    "#     # print(non_zeros.eval())\n",
    "#     boxes = tf.boolean_mask(sub_sep, non_zeros,axis = 0)\n",
    "#     print(' boxes shape ',boxes.get_shape())\n",
    "#     print(boxes.eval())\n",
    "\n",
    "#     all_boxes.append(boxes)\n",
    "# print(len(all_boxes))\n",
    "# stacked_tensor = tf.stack(all_boxes)\n",
    "# print('stacked shape',stacked_tensor.get_shape())\n",
    "\n",
    "# p_reduced = tf.reduce_sum(tf.abs(pred_tensor), axis=-1)\n",
    "# print(' p_redcued shape ',p_reduced.shape)\n",
    "# print(p_reduced.eval())\n",
    "# non_zeros = tf.cast(p_reduced, tf.bool)\n",
    "# print(' mask shape' ,non_zeros.shape) \n",
    "# print(non_zeros.eval())\n",
    "# boxes = tf.boolean_mask(pred_tensor, non_zeros,axis = 0)\n",
    "# print(boxes.shape)\n",
    "# print(boxes.eval())\n",
    "# print(keepers[1].eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T08:39:08.799869Z",
     "start_time": "2018-04-27T08:39:08.370702Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "boxes1 = tf.Variable(tf.random_uniform([32, 4], minval=0, maxval=128, dtype=tf.float32, seed=1234), name = 'var')\n",
    "boxes2 = tf.Variable(tf.random_uniform([100, 4], minval=0, maxval=128, dtype=tf.float32, seed=1234), name = 'var')\n",
    "\n",
    "init = tf.global_variables_initializer().run()\n",
    "\n",
    "# boxes1 = tf.placeholder(tf.float32,(32,4))\n",
    "# boxes2 = tf.placeholder(tf.float32,(100,4))\n",
    "\n",
    "print(boxes1.get_shape(), boxes2.get_shape())\n",
    "aa = tf.expand_dims(boxes1, 1)\n",
    "print(tf.shape(aa).eval())\n",
    "aa = tf.tile(tf.expand_dims(boxes1, 1), [1, 1, tf.shape(boxes2)[0]])\n",
    "print(tf.shape(aa).eval())                          \n",
    "\n",
    "b1 = tf.reshape(tf.tile(tf.expand_dims(boxes1, 1), [1, 1, tf.shape(boxes2)[0]]), [-1, 4])\n",
    "print('b1 : ', tf.shape(b1).eval())\n",
    "b2 = tf.tile(boxes2, [tf.shape(boxes1)[0], 1])\n",
    "print('b2 : ', tf.shape(b1).eval())\n",
    "print('     overlaps_graph: shape of boxes1 after reshape: ',b1.shape)  # (?,4)\n",
    "print('     overlaps_graph: shape of boxes2 after reshape: ',b2.shape)  # (?,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T17:15:11.333768Z",
     "start_time": "2018-05-04T17:15:09.950026Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "May 03\n",
    "'''\n",
    "\n",
    "\n",
    "def development_build_gaussian_tf(in_tensor, config, names = None):    \n",
    "    # def build_gaussian_tf(in_tensor) :   #, pred_cls_cnt, config):\n",
    "    ## rois per image is determined by size of input tensor \n",
    "    ##   detection mode:   config.TRAIN_ROIS_PER_IMAGE \n",
    "    ##   ground_truth  :   config.DETECTION_MAX_INSTANCES    \n",
    "    '''\n",
    "    in_tensor :     [N, num_rois, 8 { index, ]\n",
    "    '''\n",
    "    in_tensor = pred_tensor\n",
    "\n",
    "    # num_detections  = config.DETECTION_MAX_INSTANCES\n",
    "\n",
    "    num_detections  = 32          # config.DETECTION_MAX_INSTANCES\n",
    "    num_cols        = 6\n",
    "    img_h, img_w    = [128, 128]  # config.IMAGE_SHAPE[:2]\n",
    "    batch_size      = config.BATCH_SIZE\n",
    "    num_classes     = config.NUM_CLASSES  \n",
    "\n",
    "    print('\\n ')\n",
    "    print('  > BUILD_GAUSSIAN_TF() for ' )\n",
    "\n",
    "    # rois per image is determined by size of input tensor \n",
    "    #   detection mode:   config.TRAIN_ROIS_PER_IMAGE \n",
    "    #   ground_truth  :   config.DETECTION_MAX_INSTANCES\n",
    "\n",
    "    print('    orignal in_tensor shape : ', in_tensor.shape)   \n",
    "    # in_tensor = in_tensor[:,:,:,2:7]\n",
    "    # in_tensor = in_tensor[:,:,:,]\n",
    "    print('    modified in_tensor shape : ', in_tensor.get_shape())\n",
    "\n",
    "    rois_per_image  = tf.to_int32(in_tensor.shape[2])\n",
    "    strt_cls        = 0 if rois_per_image == 32 else 1\n",
    "    print('    num of bboxes per class is : ', rois_per_image.eval())\n",
    "    # print(in_tensor[0].eval())\n",
    "\n",
    "    '''\n",
    "    ### Build Position meshgird\n",
    "    '''\n",
    "\n",
    "    ##-----------------------------------------------------------------------------\n",
    "    ## Build mesh-grid to hold pixel coordinates \n",
    "    ##-----------------------------------------------------------------------------\n",
    "    X = tf.range(img_w, dtype=tf.int32)\n",
    "    Y = tf.range(img_h, dtype=tf.int32)\n",
    "    X, Y = tf.meshgrid(X, Y)\n",
    "    # grid1 = tf.stack([X,Y], axis=-1)\n",
    "    # print('grid1 shape ', grid1.shape)\n",
    "    # print(grid1[0,:,:].eval())\n",
    "\n",
    "    print('   -- build meshgrid -----')\n",
    "    print('   X and Y meshgrid shapes ', X.get_shape(), Y.get_shape())\n",
    "    # print( ' X : \\n',X.eval())\n",
    "    # print( ' Y : \\n',Y.eval())\n",
    "\n",
    "    # ## hear we repeat X and Y  batch_size x rois_per_image times\n",
    "    ones = tf.ones([batch_size, rois_per_image,1, 1], dtype = tf.int32)\n",
    "    print('   ones: ',ones.shape)                \n",
    "    # # ones = tf.expand_dims(ones,-1)\n",
    "    # print(' ones with exp dims ',ones.shape)\n",
    "\n",
    "    rep_X = ones * X\n",
    "    rep_Y = ones * Y \n",
    "    # print(' ones_exp * X', ones.shape, '*', X.shape, '= ',rep_X.shape)\n",
    "    # print(' ones_exp * Y', ones.shape, '*', Y.shape, '= ',rep_Y.shape)\n",
    "\n",
    "    # # stack the X and Y grids \n",
    "    bef_pos = tf.to_float(tf.stack([rep_X,rep_Y], axis = -1))\n",
    "    print('   before transpse ', bef_pos.get_shape())\n",
    "    pos_grid = tf.transpose(bef_pos,[2,3,0,1,4])\n",
    "    print('   after transpose ', pos_grid.get_shape())    \n",
    "\n",
    "    # print(pos_grid_1[:,:,0,0,:].eval())\n",
    "\n",
    "    '''\n",
    "    ### Build stacked_list\n",
    "    For each image reduce the roi per class arrays into one array\n",
    "    List of stacked tensors (one per image) - each stacked tensor shape is `[? , 6]`\n",
    "    '''\n",
    "    ##-----------------------------------------------------------------------------\n",
    "    ## Stack non_zero bboxes from in_tensor into pt2_dense \n",
    "    ##-----------------------------------------------------------------------------\n",
    "    pt2_sum = tf.reduce_sum(tf.abs(in_tensor[:,:,:,:-2]) ,axis =-1)\n",
    "    print('   pt2_sum shape ',pt2_sum.shape)\n",
    "    print(pt2_sum[0].eval())\n",
    "\n",
    "    pt2_mask = tf.greater(pt2_sum , 0)\n",
    "    print('   pt2_mask shape ', pt2_mask.get_shape())\n",
    "    # print(pt2_mask.eval())\n",
    "\n",
    "    pt2_ind  = tf.where(pt2_mask)\n",
    "    print('   pt2_ind shape  ', pt2_ind.get_shape())\n",
    "    print(pt2_ind[1].eval())\n",
    "    # pt2_ind_float  =  tf.to_float(pt2_ind[:,0:1])\n",
    "\n",
    "    pt2_dense = tf.gather_nd( in_tensor, pt2_ind)\n",
    "\n",
    "    # concatinate image id to front of ROI rows \n",
    "    dense1 = tf.concat([tf.to_float(pt2_ind[:,0:1]), pt2_dense ],axis=1)\n",
    "    print('   dense1 shape ', pt2_dense .get_shape())\n",
    "    #     print(pt2_dense .eval())\n",
    "\n",
    "    stacked_list = tf.dynamic_partition(pt2_dense , tf.to_int32(pt2_ind[:,0]),num_partitions = batch_size )\n",
    "\n",
    "    ''' \n",
    "    ### Build stacked tensor\n",
    "    Convert stacked_list into a tensor by adding necessary padding to each item and stacking them all together.\n",
    "\n",
    "    '''\n",
    "    print('   -- Build Stacked output from dynamically partitioned lists --------------')  \n",
    "\n",
    "    stacked_output=[]\n",
    "    for img, item  in enumerate(stacked_list) :\n",
    "        # rois_in_image, cols  = tf.shape(stacked_list[img]).eval()\n",
    "        rois_in_image  = tf.shape(item).eval()[0]\n",
    "\n",
    "        print('\\n   ===> list item #', img)       \n",
    "        print('   img ', img, ' stacked_list[img] ', tf.shape(item).eval(), ' rois_in_image : ', rois_in_image)\n",
    "        #     print(stacked_list[img].eval())            \n",
    "        pad_item =  tf.pad(item,[[0, rois_per_image - rois_in_image ],[0,0]])\n",
    "        stacked_output.append(pad_item)\n",
    "        print('   tensor_list item pos padding :', tf.shape(pad_item).eval())\n",
    "        #     print(stacked_list[img].eval())\n",
    "    stacked_tensor = tf.stack(stacked_output)\n",
    "    print()    \n",
    "    print('   -- Stacked output contents --------------')    \n",
    "    print('    stacked_output shape : ', len(stacked_output))\n",
    "    for img, item  in enumerate(stacked_output) :\n",
    "        print('   img ', img, ' stacked_list[img] ', tf.shape(item).eval() ) \n",
    "    print('   stacked tensor : ', tf.shape(stacked_tensor).eval(), stacked_tensor.shape, stacked_tensor.get_shape())\n",
    "    # print(stacked_tensor[0].eval())\n",
    "    # print()\n",
    "    # print(stacked_tensor[1].eval())\n",
    "    print()\n",
    "    print(stacked_tensor[2].eval())\n",
    "\n",
    "    '''\n",
    "    ###  Build mean and covar components for Multivariate normal and execute\n",
    "    '''\n",
    "\n",
    "    ##-----------------------------------------------------------------------------\n",
    "    ##  Build mean and convariance tensors for Multivariate Normal Distribution\n",
    "    ##-----------------------------------------------------------------------------\n",
    "    width  = stacked_tensor[:,:,3] - stacked_tensor[:,:,1]\n",
    "    height = stacked_tensor[:,:,2] - stacked_tensor[:,:,0]\n",
    "    cx     = stacked_tensor[:,:,1] + ( width  / 2.0)\n",
    "    cy     = stacked_tensor[:,:,0] + ( height / 2.0)\n",
    "    means  = tf.stack((cx,cy),axis = -1)\n",
    "    covar_orig  = tf.stack((width * 0.5 , height * 0.5), axis = -1)\n",
    "    covar  = tf.sqrt(covar_orig)\n",
    "    \n",
    "    # print(means.eval())\n",
    "    # print(covar.eval())\n",
    "\n",
    "    # print('width shape ',width.get_shape()) \n",
    "    # print(mns.eval())\n",
    "    tfd = tf.contrib.distributions\n",
    "    mvn = tfd.MultivariateNormalDiag(\n",
    "        loc  = means,\n",
    "        scale_diag = covar)\n",
    "\n",
    "    print('   means shape ',means.get_shape(), '  ', means.get_shape())\n",
    "    print('   covar shape ',covar.get_shape(), '  ', covar.get_shape())\n",
    "    print('   from MVN :  \\t mean shape     :', mvn.mean().shape, '\\t stddev shape', mvn.stddev().shape )\n",
    "    print('   from MVN :  \\t mean shape     :', mvn.mean().get_shape(), '\\t stddev shape', mvn.stddev().get_shape())\n",
    "    print('   from MVN :  \\t mvn.batch_shape:', mvn.batch_shape , '\\t mvn.event_shape ',  mvn.event_shape)\n",
    "    print('   Linear OP shape      ', mvn.scale.shape, ' Linear Op batch shape ',mvn.scale.batch_shape)\n",
    "    print('   Linear op Range Dim  ', mvn.scale.range_dimension)\n",
    "    print('   Linear op Domain Dim ', mvn.scale.domain_dimension) \n",
    "\n",
    "    prob_grid = mvn.prob(pos_grid)\n",
    "    # print(prob.eval())\n",
    "    #     eq = tf.equal(grid, pos)\n",
    "    #     print( ' pos and grid probabalitiy matricies equal  -->', tf.reduce_all(eq).eval())\n",
    "    prob_grid = tf.transpose(prob_grid,[2,3,0,1])\n",
    "\n",
    "    print('    >> input to MVN.PROB: pos_grid (meshgrid) shape: ', pos_grid.get_shape())\n",
    "    print('    << output probabilities shape:' , prob_grid.get_shape())\n",
    "\n",
    "    #--------------------------------------------------------------------------------\n",
    "    # kill distributions of NaN boxes (resulting from bboxes with height/width of zero\n",
    "    # which cause singular sigma cov matrices\n",
    "    #--------------------------------------------------------------------------------\n",
    "    gauss_grid = tf.where(tf.is_nan(prob_grid),  tf.zeros_like(prob_grid), prob_grid)\n",
    "\n",
    "    #--------------------------------------------------------------------------------\n",
    "    ## scatter out the probability distributions based on class\n",
    "    #--------------------------------------------------------------------------------\n",
    "    print('    Scatter out the probability distributions based on class --------------')     \n",
    "    '''\n",
    "    class_inds      = tf.to_int32(stacked_tensor[:,:,-1])\n",
    "    '''\n",
    "    class_inds      = tf.to_int32(stacked_tensor[:,:,-2])\n",
    "    batch_grid, roi_grid = tf.meshgrid( tf.range(batch_size, dtype=tf.int32), tf.range(rois_per_image, dtype=tf.int32),\n",
    "                                        indexing = 'ij' )\n",
    "    scatter_classes = tf.stack([batch_grid, class_inds, roi_grid ],axis = -1)\n",
    "    gauss_scatt     = tf.scatter_nd(scatter_classes, gauss_grid, [batch_size, num_classes, rois_per_image, img_w, img_h])\n",
    "\n",
    "    print('    gaussian_grid      : ', gauss_grid.shape)    \n",
    "    print('    class shape        : ', class_inds.shape)\n",
    "    # print(class_inds.eval())\n",
    "    print('    roi_grid shape     : ', roi_grid.get_shape() )\n",
    "    print('    batch_grid shape   : ', batch_grid.get_shape())\n",
    "    print('    scatter_classes    : ', scatter_classes.get_shape())\n",
    "    print('    gaussian scattered : ', gauss_scatt.shape)   \n",
    "\n",
    "    print('   means shape ',means.get_shape())\n",
    "    # print(means.eval())\n",
    "    print('   covar orig shape ',covar_orig.get_shape())\n",
    "    # print(covar_orig.eval())\n",
    "\n",
    "\n",
    "    #--------------------------------------------------------------------------------\n",
    "    ## sum based on class\n",
    "    #--------------------------------------------------------------------------------\n",
    "    print('    Reduce sum based on class ---------------------------------------------')         \n",
    "    gauss_sum = tf.reduce_sum(gauss_scatt, axis=2, name='pred_gaussian')\n",
    "    print('    gaussian_sum shape : ', gauss_sum.get_shape())    \n",
    "\n",
    "    gauss_sum = tf.where(gauss_sum > 1e-6, gauss_sum,tf.zeros_like(gauss_sum))\n",
    "    gauss_sum = tf.transpose(gauss_sum,[0,2,3,1])\n",
    "    print('    gaussian_sum shape : ', gauss_sum.get_shape())    \n",
    "    print('    complete')    \n",
    "    \n",
    "    \n",
    "    return stacked_tensor,covar, means, gauss_grid, gauss_sum"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python [conda env:TF_gpu]",
   "language": "python",
   "name": "conda-env-TF_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
