{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Mask R-CNN - Train modified model on Shapes Dataset\n",
    "\n",
    "### the modified model does not include any mask related heads or losses \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T09:08:24.306134Z",
     "start_time": "2018-05-14T09:08:01.078317Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import  gc\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as KB\n",
    "sys.path.append('../')\n",
    "\n",
    "import mrcnn.model_mod as modellib\n",
    "import mrcnn.visualize as visualize\n",
    "import mrcnn.shapes    as shapes\n",
    "from mrcnn.config      import Config\n",
    "from mrcnn.model       import log\n",
    "from mrcnn.dataset     import Dataset \n",
    "\n",
    "from mrcnn.utils       import stack_tensors, stack_tensors_3d\n",
    "from mrcnn.datagen     import data_generator, load_image_gt\n",
    "from mrcnn.callbacks   import get_layer_output_1,get_layer_output_2\n",
    "from mrcnn.visualize   import plot_gaussian\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "MODEL_PATH = 'E:\\Models'\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(MODEL_PATH, \"mrcnn_development_logs\")\n",
    "\n",
    "# Path to COCO trained weights\n",
    "COCO_MODEL_PATH   = os.path.join(MODEL_PATH, \"mask_rcnn_coco.h5\")\n",
    "RESNET_MODEL_PATH = os.path.join(MODEL_PATH, \"resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n",
    "print(\"Tensorflow Version: {}   Keras Version : {} \".format(tf.__version__,keras.__version__))\n",
    "\n",
    "\n",
    "# Build configuration object -----------------------------------------------\n",
    "config = shapes.ShapesConfig()\n",
    "config.BATCH_SIZE      = 5                  # Batch size is 2 (# GPUs * images/GPU).\n",
    "config.IMAGES_PER_GPU  = 5                  # Must match BATCH_SIZE\n",
    "config.STEPS_PER_EPOCH = 2\n",
    "config.FCN_INPUT_SHAPE = config.IMAGE_SHAPE[0:2]\n",
    "\n",
    "# config.LAST_EPOCH_RAN  = 5784\n",
    "config.display() \n",
    "\n",
    "# Build shape dataset        -----------------------------------------------\n",
    "# Training dataset\n",
    "# generate 500 shapes \n",
    "dataset_train = shapes.ShapesDataset()\n",
    "dataset_train.load_shapes(500, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = shapes.ShapesDataset()\n",
    "dataset_val.load_shapes(50, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_val.prepare()\n",
    "\n",
    "# Load and display random samples\n",
    "# image_ids = np.random.choice(dataset_train.image_ids, 3)\n",
    "# for image_id in [3]:\n",
    "#     image = dataset_train.load_image(image_id)\n",
    "#     mask, class_ids = dataset_train.load_mask(image_id)\n",
    "#     visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "print(' COCO Model Path       : ', COCO_MODEL_PATH)\n",
    "print(' Checkpoint folder Path: ', MODEL_DIR)\n",
    "print(' Model Parent Path     : ', MODEL_PATH)\n",
    "print(' Resent Model Path     : ', RESNET_MODEL_PATH)\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
    "np.set_printoptions(linewidth=100,precision=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T09:16:24.197113Z",
     "start_time": "2018-05-14T09:16:13.640048Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try :\n",
    "    del model\n",
    "    gc.collect()\n",
    "except: \n",
    "    pass\n",
    "KB.clear_session()\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T17:46:09.656227Z",
     "start_time": "2018-05-13T17:46:09.414622Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(' COCO Model Path       : ', COCO_MODEL_PATH)\n",
    "print(' Checkpoint folder Path: ', MODEL_DIR)\n",
    "print(' Model Parent Path     : ', MODEL_PATH)\n",
    "print(' Resent Model Path     : ', RESNET_MODEL_PATH)\n",
    "print(model.find_last())\n",
    "\n",
    "# model.compile_only(learning_rate=config.LEARNING_RATE, layers='all')\n",
    "# tst = model.keras_model.to_json()\n",
    "# save_model(MODEL_DIR, 'my_saved_model')\n",
    "# print(model.find_last())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T09:16:51.595478Z",
     "start_time": "2018-05-14T09:16:33.869829Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#model.keras_model.summary(line_length = 120) \n",
    "# model.compile_only(learning_rate=config.LEARNING_RATE, layers='heads')\n",
    "# KB.set_learning_phase(1)\n",
    "'''\n",
    "methods to load weights\n",
    "1 - load a specific file\n",
    "2 - find a last checkpoint in a specific folder \n",
    "3 - use init_with keyword \n",
    "'''\n",
    "## 1- look for a specific weights file \n",
    "## Load trained weights (fill in path to trained weights here)\n",
    "# model_path  = 'E:\\\\Models\\\\mrcnn_logs\\\\shapes20180428T1819\\\\mask_rcnn_shapes_5784.h5'\n",
    "# print(' model_path : ', model_path )\n",
    "# assert model_path != \"\", \"Provide path to trained weights\"\n",
    "# print(\"Loading weights from \", model_path)\n",
    "# model.load_weights(model_path, by_name=True)    \n",
    "# print('Load weights complete')\n",
    "\n",
    "# ## 2- look for last checkpoint file in a specific folder (not working correctly)\n",
    "# model.config.LAST_EPOCH_RAN = 5784\n",
    "# model.model_dir = 'E:\\\\Models\\\\mrcnn_logs\\\\shapes20180428T1819'\n",
    "# last_model_found = model.find_last()\n",
    "# print(' last model in MODEL_DIR: ', last_model_found)\n",
    "# # loc= model.load_weights(model.find_last()[1], by_name=True)\n",
    "# # print('Load weights complete :', loc)\n",
    "\n",
    "\n",
    "## 3- Use init_with keyword\n",
    "## Which weights to start with?\n",
    "init_with = \"last\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "#     loc=model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "    loc=model.load_weights(RESNET_MODEL_PATH, by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    \n",
    "    # See README for instructions to download the COCO weights\n",
    "    loc=model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    loc= model.load_weights(model.find_last()[1], by_name=True)\n",
    "print('Load weights complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false
   },
   "source": [
    "###  Print some model information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T17:46:29.174422Z",
     "start_time": "2018-05-13T17:46:28.918743Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('\\n Inputs: ') \n",
    "for i, out in enumerate(model.keras_model.inputs):\n",
    "    print(i , '    ', out)\n",
    "\n",
    "print('\\n Outputs: ') \n",
    "for i, out in enumerate(model.keras_model.outputs):\n",
    "    print(i , '    ', out)\n",
    "\n",
    "# print('\\n Losses (model.metrics_names): ') \n",
    "# pp.pprint(model.get_deduped_metrics_names())\n",
    "# model.keras_model.summary(line_length = 150) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Training\n",
    "\n",
    "Train in two stages:\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
    "\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Training head using  Keras.model.fit_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T15:45:17.278598Z",
     "start_time": "2018-05-11T15:45:17.036444Z"
    }
   },
   "outputs": [],
   "source": [
    "print(config.BATCH_SIZE)\n",
    "print(model.config.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T11:31:23.442842Z",
     "start_time": "2018-05-14T11:16:17.000837Z"
    },
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "\n",
    "# model.train(dataset_train, dataset_val, \n",
    "#             learning_rate=config.LEARNING_RATE, \n",
    "# #             epochs = 69,\n",
    "#             epochs_to_run =2, \n",
    "#             layers='heads')\n",
    "\n",
    "train_layers = ['mrcnn', 'fpn','rpn']\n",
    "loss_names   = [  \"rpn_class_loss\", \"rpn_bbox_loss\" , \"mrcnn_class_loss\", \"mrcnn_bbox_loss\"]\n",
    "model.epoch = 3648\n",
    "model.config.LEARNING_RATE = 1.0e-3\n",
    "model.config.STEPS_PER_EPOCH = 7\n",
    "\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=model.config.LEARNING_RATE, \n",
    "            epochs_to_run =352, \n",
    "#             epochs = 25,            \n",
    "#             batch_size = 0\n",
    "#             steps_per_epoch = 0 \n",
    "            layers = train_layers,\n",
    "            losses = loss_names,\n",
    "            min_LR = 1.0e-6,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T09:35:29.109031Z",
     "start_time": "2018-05-14T09:35:28.542576Z"
    }
   },
   "outputs": [],
   "source": [
    "model.config.LEARNING_RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## - Training heads using train_in_batches ()\n",
    "\n",
    "We need to use this method for the time being as the fit generator does not have provide EASY access to the output in Keras call backs. By training in batches, we pass a batch through the network, pick up the generated RoI detections and bounding boxes and generate our semantic / gaussian tensors ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-28T15:03:53.709099Z",
     "start_time": "2018-04-28T15:02:36.185321Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.train_in_batches(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE/6, \n",
    "            epochs_to_run = 3,\n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Fine Tuning\n",
    "Fine tune all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also \n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=211,\n",
    "            layers=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "# Uncomment to save manually\n",
    "model_path = os.path.join(MODEL_DIR, \"mask_rcnn_shapes.h5\")\n",
    "model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Define Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T13:21:37.008439Z",
     "start_time": "2018-05-13T13:21:36.759257Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_generator = data_generator(dataset_train, model.config, shuffle=True,\n",
    "                                 batch_size=model.config.BATCH_SIZE,\n",
    "                                 augment = False)\n",
    "val_generator = data_generator(dataset_val, model.config, shuffle=True, \n",
    "                                batch_size=model.config.BATCH_SIZE,\n",
    "                                augment=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Get next shapes from generator and display loaded shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T13:21:38.648279Z",
     "start_time": "2018-05-13T13:21:38.383075Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_batch_x, train_batch_y = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T13:21:41.601482Z",
     "start_time": "2018-05-13T13:21:39.496536Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train_batch_x, train_batch_y = next(train_generator)\n",
    "imgmeta_idx = model.keras_model.input_names.index('input_image_meta')\n",
    "img_meta    = train_batch_x[imgmeta_idx]\n",
    "\n",
    "for img_idx in range(config.BATCH_SIZE):\n",
    "    image_id = img_meta[img_idx,0]\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    print('Image id: ',image_id)\n",
    "    print('Image meta', img_meta[img_idx])\n",
    "    print('Classes (1: circle, 2: square, 3: triangle ): ',class_ids)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Push Data thru model using get_layer_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T13:21:52.971580Z",
     "start_time": "2018-05-13T13:21:43.214787Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "model_output = get_layer_output_2(model.keras_model, train_batch_x, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0      Tensor(\"input_image:0\", shape=(?, 128, 128, 3), dtype=float32)\n",
    "# 1      Tensor(\"input_image_meta:0\", shape=(?, ?), dtype=float32)\n",
    "# 2      Tensor(\"input_rpn_match:0\", shape=(?, ?, 1), dtype=int32)\n",
    "# 3      Tensor(\"input_rpn_bbox:0\", shape=(?, ?, 4), dtype=float32)\n",
    "# 4      Tensor(\"input_gt_class_ids:0\", shape=(?, ?), dtype=int32)\n",
    "# 5      Tensor(\"input_gt_boxes:0\", shape=(?, ?, 4), dtype=float32)\n",
    "# 6      Tensor(\"input_gt_masks:0\", shape=(?, 56, 56, ?), dtype=bool)\n",
    "\n",
    "input_image_meta =  train_batch_x[1]\n",
    "input_rpn_match  =  train_batch_x[2]\n",
    "input_rpn_bbox   =  train_batch_x[3]\n",
    "input_gt_class_ids = train_batch_x[4]\n",
    "input_gt_bboxes = train_batch_x[5]\n",
    "# gt_masks   =  train_batch_x[6]\n",
    "print(' input_rpn_match    ', input_rpn_match.shape)\n",
    "print(' input_rpn_bbox     ', input_rpn_bbox.shape)\n",
    "print(' input_gt_class_ids ', input_gt_class_ids.shape)\n",
    "print(' input_gt_bboxes    ', input_gt_bboxes.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T13:22:48.349621Z",
     "start_time": "2018-05-13T13:22:48.086415Z"
    }
   },
   "outputs": [],
   "source": [
    "# KB.set_session(sess)\n",
    "print(len(model_output))\n",
    "# rpn_class_logits   = model_output[0]\n",
    "# rpn_class          = model_output[1]\n",
    "# rpn_bbox           = model_output[2]\n",
    "# rpn_proposal_rois  = model_output[3]\n",
    "output_rois        = model_output[4]\n",
    "target_class_ids   = model_output[5]\n",
    "target_bbox_deltas = model_output[6]\n",
    "roi_gt_boxes       = model_output[7]\n",
    "mrcnn_class_logits = model_output[8]\n",
    "mrcnn_class        = model_output[9]\n",
    "mrcnn_bbox         = model_output[10]\n",
    "# rpn_class_loss   = model_output[11]\n",
    "# rpn_bbox_loss    = model_output[12]\n",
    "# mrcnn_class_loss = model_output[13]\n",
    "# mrcnn_bbox_loss  = model_output[14]\n",
    "fcn_bbox_loss      = model_output[15]\n",
    "pred_hm            = model_output[16]\n",
    "gt_hm              = model_output[17]\n",
    "pred_hm_norm       = model_output[18]\n",
    "gt_hm_norm         = model_output[19]\n",
    "pred_tensor        = model_output[20]\n",
    "gt_tensor          = model_output[21]\n",
    "gt_deltas          = model_output[22]\n",
    "fcn_heatmap        = model_output[23]\n",
    "fcn_class_logits   = model_output[24]\n",
    "fcn_scores         = model_output[25]\n",
    "fcn_bbox_deltas    = model_output[26]\n",
    "# print(type(model_output[4]))\n",
    "# print(type(output_rois))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T13:25:09.473058Z",
     "start_time": "2018-05-13T13:25:09.230439Z"
    }
   },
   "outputs": [],
   "source": [
    "print(gt_deltas.shape, fcn_bbox_deltas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T13:26:41.382012Z",
     "start_time": "2018-05-13T13:26:41.135397Z"
    }
   },
   "outputs": [],
   "source": [
    "img = 0\n",
    "cls = 3\n",
    "print(gt_deltas[img,cls])\n",
    "print(fcn_bbox_deltas[img,cls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T16:04:16.108798Z",
     "start_time": "2018-05-11T16:04:15.859069Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.keras_model.summary(line_length=132, positions=[0.30,0.75, .83, 1. ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T15:57:13.903381Z",
     "start_time": "2018-05-11T15:57:13.676279Z"
    }
   },
   "outputs": [],
   "source": [
    "print(model.keras_model.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python [conda env:TF_gpu]",
   "language": "python",
   "name": "conda-env-TF_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
