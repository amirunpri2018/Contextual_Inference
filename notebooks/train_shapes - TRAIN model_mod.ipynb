{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Mask R-CNN - Train on Shapes Dataset\n",
    "\n",
    "### Notes from implementation\n",
    "\n",
    "This notebook shows how to train Mask R-CNN on your own dataset. To keep things simple we use a synthetic dataset of shapes (squares, triangles, and circles) which enables fast training. You'd still need a GPU, though, because the network backbone is a Resnet101, which would be too slow to train on a CPU. On a GPU, you can start to get okay-ish results in a few minutes, and good results in less than an hour.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T17:45:41.957194Z",
     "start_time": "2018-05-13T17:45:37.631793Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 1.6.0   Keras Version : 2.1.4 \n",
      " Initialize config object - super\n",
      "(56, 56)\n",
      "\n",
      "Configuration Parameters:\n",
      "-------------------------\n",
      "BACKBONE_SHAPES                [[32 32]\n",
      " [16 16]\n",
      " [ 8  8]\n",
      " [ 4  4]\n",
      " [ 2  2]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     5\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "EPOCHS_TO_RUN                  0\n",
      "FCN_INPUT_SHAPE                [128 128]\n",
      "GPU_COUNT                      1\n",
      "IMAGES_PER_GPU                 5\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [128 128   3]\n",
      "LAST_EPOCH_RAN                 0\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           shapes\n",
      "NUM_CLASSES                    4\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                2\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      " COCO Model Path       :  E:\\Models\\mask_rcnn_coco.h5\n",
      " Checkpoint folder Path:  E:\\Models\\mrcnn_development_logs\n",
      " Model Parent Path     :  E:\\Models\n",
      " Resent Model Path     :  E:\\Models\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import  gc\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as KB\n",
    "sys.path.append('../')\n",
    "\n",
    "import mrcnn.model_mod as modellib\n",
    "import mrcnn.visualize as visualize\n",
    "import mrcnn.shapes    as shapes\n",
    "from mrcnn.config      import Config\n",
    "from mrcnn.model       import log\n",
    "from mrcnn.dataset     import Dataset \n",
    "\n",
    "from mrcnn.utils       import stack_tensors, stack_tensors_3d\n",
    "from mrcnn.datagen     import data_generator, load_image_gt\n",
    "from mrcnn.callbacks   import get_layer_output_1,get_layer_output_2\n",
    "from mrcnn.visualize   import plot_gaussian\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "MODEL_PATH = 'E:\\Models'\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(MODEL_PATH, \"mrcnn_development_logs\")\n",
    "\n",
    "# Path to COCO trained weights\n",
    "COCO_MODEL_PATH   = os.path.join(MODEL_PATH, \"mask_rcnn_coco.h5\")\n",
    "RESNET_MODEL_PATH = os.path.join(MODEL_PATH, \"resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n",
    "\n",
    "print(\"Tensorflow Version: {}   Keras Version : {} \".format(tf.__version__,keras.__version__))\n",
    "\n",
    "\n",
    "# Build configuration object -----------------------------------------------\n",
    "config = shapes.ShapesConfig()\n",
    "config.BATCH_SIZE      = 5                  # Batch size is 2 (# GPUs * images/GPU).\n",
    "config.IMAGES_PER_GPU  = 5                  # Must match BATCH_SIZE\n",
    "config.STEPS_PER_EPOCH = 2\n",
    "config.FCN_INPUT_SHAPE = config.IMAGE_SHAPE[0:2]\n",
    "\n",
    "# config.LAST_EPOCH_RAN  = 5784\n",
    "config.display() \n",
    "\n",
    "# Build shape dataset        -----------------------------------------------\n",
    "# Training dataset\n",
    "# generate 500 shapes \n",
    "dataset_train = shapes.ShapesDataset()\n",
    "dataset_train.load_shapes(500, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = shapes.ShapesDataset()\n",
    "dataset_val.load_shapes(50, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_val.prepare()\n",
    "\n",
    "# Load and display random samples\n",
    "# image_ids = np.random.choice(dataset_train.image_ids, 3)\n",
    "# for image_id in [3]:\n",
    "#     image = dataset_train.load_image(image_id)\n",
    "#     mask, class_ids = dataset_train.load_mask(image_id)\n",
    "#     visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "print(' COCO Model Path       : ', COCO_MODEL_PATH)\n",
    "print(' Checkpoint folder Path: ', MODEL_DIR)\n",
    "print(' Model Parent Path     : ', MODEL_PATH)\n",
    "print(' Resent Model Path     : ', RESNET_MODEL_PATH)\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
    "np.set_printoptions(linewidth=100,precision=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T17:46:06.105259Z",
     "start_time": "2018-05-13T17:45:54.991981Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Initialize model WITHOUT MASKING LAYERS!!!!\n",
      "    set_log_dir: Checkpoint path set to : E:\\Models\\mrcnn_development_logs\\shapes20180513T1945\\mask_rcnn_shapes_{epoch:04d}.h5\n",
      "    set_log_dir: self.epoch set to 0 \n",
      "\n",
      ">>> Resnet Graph \n",
      "     Input_image shape : (?, 128, 128, 3)\n",
      "     After ZeroPadding2D  : (?, 134, 134, 3) (?, 134, 134, 3)\n",
      "     After Conv2D padding : (?, 64, 64, 64) (?, 64, 64, 64)\n",
      "     After BatchNorm      : (?, 64, 64, 64) (?, 64, 64, 64)\n",
      "     After MaxPooling2D   : (?, 32, 32, 64) (?, 32, 32, 64)\n",
      "\n",
      ">>> Feature Pyramid Network (FPN) Graph \n",
      "     FPN P2 shape : (None, 32, 32, 256)\n",
      "     FPN P3 shape : (None, 16, 16, 256)\n",
      "     FPN P4 shape : (None, 8, 8, 256)\n",
      "     FPN P5 shape : (None, 4, 4, 256)\n",
      "     FPN P6 shape : (None, 2, 2, 256)\n",
      "\n",
      ">>> RPN Layer \n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     depth                   : 256\n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     anchor_stride           : 1\n",
      "\n",
      ">>> RPN Outputs  <class 'list'>\n",
      "      rpn_class_logits/concat:0\n",
      "      rpn_class/concat:0\n",
      "      rpn_bbox/concat:0\n",
      "\n",
      ">>> Proposal Layer - generate  2000  proposals\n",
      "    Init complete. Size of anchors:  (4092, 4)\n",
      "     Scores :  (5, 4092)\n",
      "     Deltas :  (5, 4092, 4)\n",
      "     Anchors:  (5, 4092, 4)\n",
      "     Boxes shape / type after processing:  (5, 4092, 4) <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "     Output: Prposals shape :  (5, ?, ?) (5, None, None)\n",
      "\n",
      ">>> Detection Target Layer (Training Mode)\n",
      "    Detection Target Layer : call()  <class 'list'> 3\n",
      "     proposals.shape    : (5, ?, ?) (5, ?, ?) (None, 2000, 4)\n",
      "     gt_class_ids.shape : (?, ?) (?, ?) (None, None)\n",
      "     gt_bboxes.shape    : (?, ?, 4) (?, ?, 4) (None, None, 4)\n",
      "\n",
      "    Detection Target Layer : return  <class 'list'> 4\n",
      "     output 0  shape (5, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 1  shape (5, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 2  shape (5, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 3  shape (5, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "\n",
      ">>> FPN Classifier Graph \n",
      "     rois shape          : (5, ?, ?)\n",
      "     No of feature_maps  : 4\n",
      "        feature_maps shape  : (?, 32, 32, 256)\n",
      "        feature_maps shape  : (?, 16, 16, 256)\n",
      "        feature_maps shape  : (?, 8, 8, 256)\n",
      "        feature_maps shape  : (?, 4, 4, 256)\n",
      "     input_shape         : [128 128   3]\n",
      "     pool_size           : 7\n",
      "   > PyramidRoI Alignment Layer Call()  5\n",
      "     boxes.shape    : (None, 32, 4)\n",
      "     roi_align_classifier output shape is :  (1, ?, 7, 7, 256) (1, ?, 7, 7, 256)\n",
      "     mrcnn_class_conv1    output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_bn1      output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_relu1    output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_conv2 output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_bn2      output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_relu2    output shape is :  (?, 32, 1, 1, 1024)\n",
      "     pool_squeeze(Shared) output shape is :  (?, 32, 1024)\n",
      "     mrcnn_class_logits   output shape is :  (?, 32, 4)\n",
      "     mrcnn_class_probs    output shape is :  (?, 32, 4)\n",
      "   mrcnn_bbox_fc        output shape is :  (?, 32, 16)\n",
      "   mrcnn_bbox           output shape is :  (?, 32, 4, 4)\n",
      "\n",
      ">>> CHM Layer  \n",
      "   > CHMLayer Call()  7\n",
      "     mrcnn_class.shape    : (?, 32, 4) (None, 32, 4)\n",
      "     mrcnn_bbox.shape     : (?, 32, 4, 4) (None, 32, 4, 4)\n",
      "     output_rois.shape    : (5, ?, ?) (None, 32, 4)\n",
      "     gt_class_ids.shape   : (?, ?) (None, None)\n",
      "     gt_bboxes.shape      : (?, ?, 4) (None, None, 4)\n",
      "     tgt_class_ids.shape  : (5, ?) (None, 32)\n",
      "     tgt_deltas.shape     : (5, ?, ?) (None, 32, 4)\n",
      "\n",
      "  > BUILD_PREDICTIONS_TF()\n",
      "    num_rois          :  32\n",
      "    mrcnn_class shape :  Tensor(\"cntxt_layer/Shape:0\", shape=(3,), dtype=int32) (None, 32, 4)\n",
      "    mrcnn_bbox.shape  :  Tensor(\"cntxt_layer/Shape_1:0\", shape=(4,), dtype=int32) (None, 32, 4, 4) (?, 32, 4, 4)\n",
      "    output_rois.shape :  Tensor(\"cntxt_layer/Shape_2:0\", shape=(3,), dtype=int32) (5, None, 4)\n",
      "    pred_classes     :  (?, 32)\n",
      "    pred_classes_exp :  (?, 32, 1)\n",
      "    pred_scores      :  (?, 32, 1)\n",
      "    batch_grid       :  (5, 32)\n",
      "    roi_grid         :  (5, 32)\n",
      "\n",
      "\n",
      "  > BUILD_GROUND TRUTH_TF()\n",
      "    gt_class_ids shape :  (?, ?)\n",
      "    gt_bboxes.shape    :  (?, ?, 4)\n",
      "    gt_classes_exp shape  (?, ?, 1)\n",
      "    gt_scores_exp shape  (?, ?, 1)\n",
      "    gt_array shape : (5, 100, 7) (5, 100, 7)\n",
      "     gt_tensor final shape  :  (5, 4, 100, 6)\n",
      "\n",
      "\n",
      "  > BUILD_GROUND TRUTH_TF()\n",
      "    gt_class_ids shape :  (5, ?)\n",
      "    gt_bboxes.shape    :  (5, ?, ?)\n",
      "    gt_classes_exp shape  (5, ?, 1)\n",
      "    gt_scores_exp shape  (5, ?, 1)\n",
      "    gt_array shape : (5, 32, ?) (5, 32, ?)\n",
      "     gt_deltas final shape  :  (5, 4, 32, 6)\n",
      "    pred_cls_cnt shape :  (5, 4) Keras tensor  True\n",
      "    gt_cls_cnt shape :  (5, 4) Keras tensor  True\n",
      "\n",
      " \n",
      "  > build_heatmap() for  ['pred_heatmap']\n",
      "    orignal in_tensor shape :  (5, 4, 32, 6)\n",
      "    modified in_tensor shape :  (5, 4, 32, 6)\n",
      "    num of bboxes per class is :  Tensor(\"cntxt_layer/ToInt32_1/x:0\", shape=(), dtype=int32)\n",
      "    after transpose  (128, 128, 5, 32, 2)\n",
      "    pt2_sum shape  (5, 4, 32)\n",
      "    dense shape  (?, 6)\n",
      "    Build Stacked output from dynamically partitioned lists --------------\n",
      "    >> input to MVN.PROB: pos_grid (meshgrid) shape:  (128, 128, 5, 32, 2)\n",
      "    << output probabilities shape: (5, 32, 128, 128)\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    gaussian_grid      :  (5, 32, 128, 128)\n",
      "    class shape        :  (5, ?)\n",
      "    roi_grid shape     :  (5, 32)\n",
      "    batch_grid shape   :  (5, 32)\n",
      "    scatter_classes    :  (5, 32, 3)\n",
      "    gaussian scattered :  (5, 4, 32, 128, 128)\n",
      "\n",
      "    Reduce sum based on class ---------------------------------------------\n",
      "    gaussian sum type/name :  <class 'tensorflow.python.framework.ops.Tensor'> cntxt_layer/pred_heatmap_1:0 pred_heatmap\n",
      "    gaussian_sum shape     :  (5, 128, 128, 4) Keras tensor  False\n",
      "\n",
      "    L2 normalization ------------------------------------------------------\n",
      " pred_shape: KB.shape: Tensor(\"cntxt_layer/Shape_8:0\", shape=(4,), dtype=int32)  tf.get_shape():  (4,)  pred_maks.shape: (5, 128, 128, 4) tf.shape : Tensor(\"cntxt_layer/Shape_9:0\", shape=(4,), dtype=int32)\n",
      "WARNING:tensorflow:From D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3157: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "   gauss_flatten    :  (None, None, None) (?, ?, ?)  Keras tensor  False\n",
      "   gauss_norm1      :  (None, None, None) (?, ?, ?)  Keras tensor  False\n",
      "   gauss_norm final :  (5, 128, 128, 4) (5, 128, 128, 4)  Keras tensor  False\n",
      "\n",
      " \n",
      "  > build_heatmap() for  ['gt_heatmap']\n",
      "    orignal in_tensor shape :  (5, 4, 100, 6)\n",
      "    modified in_tensor shape :  (5, 4, 100, 6)\n",
      "    num of bboxes per class is :  Tensor(\"cntxt_layer/ToInt32_4/x:0\", shape=(), dtype=int32)\n",
      "    after transpose  (128, 128, 5, 100, 2)\n",
      "    pt2_sum shape  (5, 4, 100)\n",
      "    dense shape  (?, 6)\n",
      "    Build Stacked output from dynamically partitioned lists --------------\n",
      "    >> input to MVN.PROB: pos_grid (meshgrid) shape:  (128, 128, 5, 100, 2)\n",
      "    << output probabilities shape: (5, 100, 128, 128)\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    gaussian_grid      :  (5, 100, 128, 128)\n",
      "    class shape        :  (5, ?)\n",
      "    roi_grid shape     :  (5, 100)\n",
      "    batch_grid shape   :  (5, 100)\n",
      "    scatter_classes    :  (5, 100, 3)\n",
      "    gaussian scattered :  (5, 4, 100, 128, 128)\n",
      "\n",
      "    Reduce sum based on class ---------------------------------------------\n",
      "    gaussian sum type/name :  <class 'tensorflow.python.framework.ops.Tensor'> cntxt_layer/gt_heatmap:0 gt_heatmap\n",
      "    gaussian_sum shape     :  (5, 128, 128, 4) Keras tensor  False\n",
      "\n",
      "    L2 normalization ------------------------------------------------------\n",
      " pred_shape: KB.shape: Tensor(\"cntxt_layer/Shape_15:0\", shape=(4,), dtype=int32)  tf.get_shape():  (4,)  pred_maks.shape: (5, 128, 128, 4) tf.shape : Tensor(\"cntxt_layer/Shape_16:0\", shape=(4,), dtype=int32)\n",
      "   gauss_flatten    :  (None, None, None) (?, ?, ?)  Keras tensor  False\n",
      "   gauss_norm1      :  (None, None, None) (?, ?, ?)  Keras tensor  False\n",
      "   gauss_norm final :  (5, 128, 128, 4) (5, 128, 128, 4)  Keras tensor  False\n",
      "\n",
      "    Output build_heatmap \n",
      "     pred_heatmap     :  (5, 128, 128, 4) Keras tensor  False\n",
      "     gt_heatmap       :  (5, 128, 128, 4) Keras tensor  False\n",
      "     complete\n",
      "<<<  shape of pred_heatmap   :  (5, 128, 128, 4)  Keras tensor  True\n",
      "<<<  shape of gt_heatmap     :  (5, 128, 128, 4)  Keras tensor  True\n",
      "\n",
      ">>> FCN Layer \n",
      "     feature map shape is  (5, 128, 128, 4)\n",
      "     height : 128 width : 128 classes : 4\n",
      "     image_data_format:  channels_last\n",
      "     rois_per_class   :  channels_last\n",
      "   FCN Block 11 shape is :  (5, 128, 128, 64)\n",
      "   FCN Block 12 shape is :  (5, 128, 128, 64)\n",
      "   FCN Block 13 shape is :  (5, 64, 64, 64)\n",
      "   FCN Block 21 shape is :  (5, 64, 64, 128)\n",
      "   FCN Block 22 shape is :  (5, 64, 64, 128)\n",
      "   FCN Block 23 (Max pooling) shape is :  (5, 32, 32, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FCN Block 31 shape is :  (5, 32, 32, 256)\n",
      "   FCN Block 32 shape is :  (5, 32, 32, 256)\n",
      "   FCN Block 33 shape is :  (5, 32, 32, 256)\n",
      "   FCN Block 34 (Max pooling) shape is :  (5, 16, 16, 256)\n",
      "   FCN fully connected 1 (fcn_fc1) shape is :  (5, 16, 16, 1024)\n",
      "   FCN fully connected 2 (fcn_fc2) shape is :  (5, 16, 16, 1024)\n",
      "   FCN final conv2d (fcn_classify) shape is :  (None, 16, 16, 4)\n",
      "   h_factor :  8.0 w_factor :  8.0\n",
      "\n",
      ">>> BilinearUpSampling2D layer\n",
      "     data_format :  channels_last\n",
      "     size        :  (8.0, 8.0)\n",
      "     target_size :  None\n",
      "     input_spec  :  [InputSpec(ndim=4)]\n",
      "     call resize_images_bilinear with size:  (8.0, 8.0)\n",
      "     CHANNELS LAST: X:  (5, 16, 16, 4)  KB.int_shape() :  (None, 16, 16, 4)\n",
      "     target_height   :  None  target_width  :  None\n",
      "     new_shape (2):  (2,) (2,)\n",
      "     new_shape (3):  (2,) (2,)\n",
      "     X after image.resize_bilinear:  (5, ?, ?, 4)\n",
      "     Dimensions of X after set_shape() :  (5, 128, 128, 4)\n",
      "    BilinearUpSampling2D. compute_output_shape()\n",
      "   FCN heatmap (fcn_heatmap) shape is :  (5, 128, 128, 4) Keras tensor  True\n",
      "\n",
      "     fcn_class_conv1    output shape is :  (5, 116, 116, 128)\n",
      "     fcn_class_bn1      output shape is :  (5, 116, 116, 128)\n",
      "     fcn_class_relu1    output shape is :  (5, 116, 116, 128)\n",
      "     fcn_class_conv2    output shape is :  (5, 104, 104, 64)\n",
      "     fcn_class_bn2      output shape is :  (5, 104, 104, 64)\n",
      "     fcn_class_relu2    output shape is :  (5, 104, 104, 64)\n",
      "     fcn_class_conv3    output shape is :  (5, 92, 92, 32)\n",
      "     fcn_class_bn3      output shape is :  (5, 92, 92, 32)\n",
      "     fcn_class_relu3    output shape is :  (5, 92, 92, 32)\n",
      "     Input to Classifier / BBox heads :  (?, ?)\n",
      "     fcn_class_logits   output shape is :  (?, 128)\n",
      "     fcn_class_probs    output shape is :  (?, 128)\n",
      "     fcn_scores         output shape is :  (?, 4, 32)\n",
      "     Dense layer        output shape is :  (?, 512) (None, 512)\n",
      "     fcn_bbox_deltas    output shape is :  (?, 4, 32, 4)\n",
      "   fcn_heatmap  shape is :  (None, 128, 128, 4)  Keras tensor  True\n",
      "\n",
      "\n",
      "---------------------------------------------------\n",
      "    building Loss Functions \n",
      "---------------------------------------------------\n",
      " gt_deltas         : True (None, 4, 32, 6)\n",
      " fcn_bbox_deltas   : True (None, 4, 32, 4)\n",
      " target_class_ids  : True (None, 32)\n",
      "\n",
      ">>> rpn_bbox_loss_graph\n",
      "    rpn_match size : (?, ?)\n",
      "    rpn_bbox  size : (?, ?, 4)\n",
      "    tf default session:  None\n",
      "\n",
      ">>> rpn_bbox_loss_graph\n",
      "    rpn_match size : (?, ?)\n",
      "    rpn_bbox  size : (?, ?, 4)\n",
      "    tf default session:  None\n",
      "\n",
      ">>> mrcnn_class_loss_graph \n",
      "    target_class_ids  size : (5, ?)\n",
      "    pred_class_logits size : (?, 32, 4)\n",
      "    active_class_ids  size : (?, ?)\n",
      "\n",
      ">>> mrcnn_class_loss_graph \n",
      "    target_class_ids  size : (?, 32)\n",
      "    pred_class_logits size : (?, 32, 4)\n",
      "    active_class_ids  size : (?, ?)\n",
      "\n",
      ">>> mrcnn_bbox_loss_graph \n",
      "    target_class_ids  size : (5, ?)\n",
      "    pred_bbox size         : (?, 32, 4, 4)\n",
      "    target_bbox size       : (5, ?, ?)\n",
      "    reshpaed pred_bbox size         : (?, 4, 4)\n",
      "    reshaped target_bbox size       : (?, 4)\n",
      "    pred_bbox size         : (?, 4)\n",
      "    target_bbox size       : (?, 4)\n",
      "\n",
      ">>> mrcnn_bbox_loss_graph \n",
      "    target_class_ids  size : (?, 32)\n",
      "    pred_bbox size         : (?, 32, 4, 4)\n",
      "    target_bbox size       : (?, 32, 4)\n",
      "    reshpaed pred_bbox size         : (?, 4, 4)\n",
      "    reshaped target_bbox size       : (?, 4)\n",
      "    pred_bbox size         : (?, 4)\n",
      "    target_bbox size       : (?, 4)\n",
      "\n",
      ">>> fcn_bbox_loss_graph \n",
      "    target_class_ids  : (5, ?)\n",
      "    fcn_bbox_deltas   : (?, 4, 32, 4)\n",
      "    target_bbox_deltas    : (5, 4, 32, 6)\n",
      "    reshaped class_array            : (640, 1)\n",
      "    reshaped pred_bbox size         : (?, 4)\n",
      "    reshaped target_bbox size       : (640, 4)\n",
      "    y_true shape: (?, 4)\n",
      "    y_pred shape: (?, 4)\n",
      "\n",
      ">>> fcn_bbox_loss_graph \n",
      "    target_class_ids  : (?, 32)\n",
      "    fcn_bbox_deltas   : (?, 4, 32, 4)\n",
      "    target_bbox_deltas    : (?, 4, 32, 6)\n",
      "    reshaped class_array            : (?, 1)\n",
      "    reshaped pred_bbox size         : (?, 4)\n",
      "    reshaped target_bbox size       : (?, 4)\n",
      "    y_true shape: (?, 4)\n",
      "    y_pred shape: (?, 4)\n",
      " output_rois       : True\n",
      " pred_heatmap      : True\n",
      " gt_heatmap        : True\n",
      " fcn_heatmap       : True\n",
      " fcn_class_logits  : True\n",
      " fcn_scores        : True\n",
      " gt_deltas         : True\n",
      " fcn_bbox_deltas   : True\n",
      " target_class_ids  : True\n",
      "\n",
      ">>> MODIFIED MaskRCNN build complete -- WITHOUT MASKING LAYERS!!!!\n",
      ">>> MODIFIED MaskRCNN initialization complete -- WITHOUT MASKING LAYERS!!!!\n"
     ]
    }
   ],
   "source": [
    "try :\n",
    "    del model\n",
    "    gc.collect()\n",
    "except: \n",
    "    pass\n",
    "KB.clear_session()\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T17:46:09.656227Z",
     "start_time": "2018-05-13T17:46:09.414622Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " COCO Model Path       :  E:\\Models\\mask_rcnn_coco.h5\n",
      " Checkpoint folder Path:  E:\\Models\\mrcnn_development_logs\n",
      " Model Parent Path     :  E:\\Models\n",
      " Resent Model Path     :  E:\\Models\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      ">>> find_last checkpoint in :  E:\\Models\\mrcnn_development_logs\n",
      "(None, None)\n"
     ]
    }
   ],
   "source": [
    "print(' COCO Model Path       : ', COCO_MODEL_PATH)\n",
    "print(' Checkpoint folder Path: ', MODEL_DIR)\n",
    "print(' Model Parent Path     : ', MODEL_PATH)\n",
    "print(' Resent Model Path     : ', RESNET_MODEL_PATH)\n",
    "print(model.find_last())\n",
    "\n",
    "# model.compile_only(learning_rate=config.LEARNING_RATE, layers='all')\n",
    "# tst = model.keras_model.to_json()\n",
    "# save_model(MODEL_DIR, 'my_saved_model')\n",
    "# print(model.find_last())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T17:46:24.564664Z",
     "start_time": "2018-05-13T17:46:15.280338Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> load_weights()\n",
      "    load_weights: Loading weights from: E:\\Models\\mask_rcnn_coco.h5\n",
      "    load_weights: Log directory set to : E:\\Models\\mask_rcnn_coco.h5\n",
      "    set_log_dir: Checkpoint path set to : E:\\Models\\mrcnn_development_logs\\shapes20180513T1946\\mask_rcnn_shapes_{epoch:04d}.h5\n",
      "    set_log_dir: self.epoch set to 0 \n",
      "    Load weights complete :  E:\\Models\\mask_rcnn_coco.h5\n",
      "Load weights complete\n"
     ]
    }
   ],
   "source": [
    "#model.keras_model.summary(line_length = 120) \n",
    "# model.compile_only(learning_rate=config.LEARNING_RATE, layers='heads')\n",
    "# KB.set_learning_phase(1)\n",
    "'''\n",
    "methods to load weights\n",
    "1 - load a specific file\n",
    "2 - find a last checkpoint in a specific folder \n",
    "3 - use init_with keyword \n",
    "'''\n",
    "## 1- look for a specific weights file \n",
    "## Load trained weights (fill in path to trained weights here)\n",
    "# model_path  = 'E:\\\\Models\\\\mrcnn_logs\\\\shapes20180428T1819\\\\mask_rcnn_shapes_5784.h5'\n",
    "# print(' model_path : ', model_path )\n",
    "# assert model_path != \"\", \"Provide path to trained weights\"\n",
    "# print(\"Loading weights from \", model_path)\n",
    "# model.load_weights(model_path, by_name=True)    \n",
    "# print('Load weights complete')\n",
    "\n",
    "# ## 2- look for last checkpoint file in a specific folder (not working correctly)\n",
    "# model.config.LAST_EPOCH_RAN = 5784\n",
    "# model.model_dir = 'E:\\\\Models\\\\mrcnn_logs\\\\shapes20180428T1819'\n",
    "# last_model_found = model.find_last()\n",
    "# print(' last model in MODEL_DIR: ', last_model_found)\n",
    "# # loc= model.load_weights(model.find_last()[1], by_name=True)\n",
    "# # print('Load weights complete :', loc)\n",
    "\n",
    "\n",
    "## 3- Use init_with keyword\n",
    "## Which weights to start with?\n",
    "init_with = \"coco\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "#     loc=model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "    loc=model.load_weights(RESNET_MODEL_PATH, by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    \n",
    "    # See README for instructions to download the COCO weights\n",
    "    loc=model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    loc= model.load_weights(model.find_last()[1], by_name=True)\n",
    "print('Load weights complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false
   },
   "source": [
    "###  Print some model information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T17:46:29.174422Z",
     "start_time": "2018-05-13T17:46:28.918743Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Inputs: \n",
      "0      Tensor(\"input_image:0\", shape=(?, 128, 128, 3), dtype=float32)\n",
      "1      Tensor(\"input_image_meta:0\", shape=(?, ?), dtype=float32)\n",
      "2      Tensor(\"input_rpn_match:0\", shape=(?, ?, 1), dtype=int32)\n",
      "3      Tensor(\"input_rpn_bbox:0\", shape=(?, ?, 4), dtype=float32)\n",
      "4      Tensor(\"input_gt_class_ids:0\", shape=(?, ?), dtype=int32)\n",
      "5      Tensor(\"input_gt_boxes:0\", shape=(?, ?, 4), dtype=float32)\n",
      "6      Tensor(\"input_gt_masks:0\", shape=(?, 56, 56, ?), dtype=bool)\n",
      "\n",
      " Outputs: \n",
      "0      Tensor(\"rpn_class_logits/concat:0\", shape=(?, ?, 2), dtype=float32)\n",
      "1      Tensor(\"rpn_class/concat:0\", shape=(?, ?, 2), dtype=float32)\n",
      "2      Tensor(\"rpn_bbox/concat:0\", shape=(?, ?, 4), dtype=float32)\n",
      "3      Tensor(\"rpn_proposal_rois/packed_2:0\", shape=(5, ?, ?), dtype=float32)\n",
      "4      Tensor(\"proposal_targets/output_rois:0\", shape=(5, ?, ?), dtype=float32)\n",
      "5      Tensor(\"proposal_targets/target_class_ids:0\", shape=(5, ?), dtype=int32)\n",
      "6      Tensor(\"proposal_targets/target_bbox_deltas:0\", shape=(5, ?, ?), dtype=float32)\n",
      "7      Tensor(\"proposal_targets/roi_gt_boxes:0\", shape=(5, ?, ?), dtype=float32)\n",
      "8      Tensor(\"mrcnn_class_logits/Reshape_1:0\", shape=(?, 32, 4), dtype=float32)\n",
      "9      Tensor(\"mrcnn_class/Reshape_1:0\", shape=(?, 32, 4), dtype=float32)\n",
      "10      Tensor(\"mrcnn_bbox/Reshape:0\", shape=(?, 32, 4, 4), dtype=float32)\n",
      "11      Tensor(\"rpn_class_loss/Reshape_2:0\", shape=(1, 1), dtype=float32)\n",
      "12      Tensor(\"rpn_bbox_loss/Reshape:0\", shape=(1, 1), dtype=float32)\n",
      "13      Tensor(\"mrcnn_class_loss/Reshape:0\", shape=(1, 1), dtype=float32)\n",
      "14      Tensor(\"mrcnn_bbox_loss/Reshape_3:0\", shape=(1, 1), dtype=float32)\n",
      "15      Tensor(\"fcn_bbox_loss/Reshape_3:0\", shape=(1, 1), dtype=float32)\n",
      "16      Tensor(\"cntxt_layer/pred_heatmap_1:0\", shape=(5, 128, 128, 4), dtype=float32)\n",
      "17      Tensor(\"cntxt_layer/gt_heatmap:0\", shape=(5, 128, 128, 4), dtype=float32)\n",
      "18      Tensor(\"cntxt_layer/pred_heatmap_norm:0\", shape=(5, 128, 128, 4), dtype=float32)\n",
      "19      Tensor(\"cntxt_layer/gt_heatmap_norm:0\", shape=(5, 128, 128, 4), dtype=float32)\n",
      "20      Tensor(\"cntxt_layer/pred_tensor:0\", shape=(5, 4, 32, 6), dtype=float32)\n",
      "21      Tensor(\"cntxt_layer/gt_tensor:0\", shape=(5, 4, 100, 6), dtype=float32)\n",
      "22      Tensor(\"cntxt_layer/gt_deltas:0\", shape=(5, 4, 32, 6), dtype=float32)\n",
      "23      Tensor(\"fcn_heatmap/ResizeBilinear:0\", shape=(5, 128, 128, 4), dtype=float32)\n",
      "24      Tensor(\"fcn_class_logits/BiasAdd:0\", shape=(?, 128), dtype=float32)\n",
      "25      Tensor(\"fcn_scores/Reshape:0\", shape=(?, 4, 32), dtype=float32)\n",
      "26      Tensor(\"fcn_bbox_deltas/Reshape:0\", shape=(?, 4, 32, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print('\\n Inputs: ') \n",
    "for i, out in enumerate(model.keras_model.inputs):\n",
    "    print(i , '    ', out)\n",
    "\n",
    "print('\\n Outputs: ') \n",
    "for i, out in enumerate(model.keras_model.outputs):\n",
    "    print(i , '    ', out)\n",
    "\n",
    "# print('\\n Losses (model.metrics_names): ') \n",
    "# pp.pprint(model.get_deduped_metrics_names())\n",
    "# model.keras_model.summary(line_length = 150) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Training\n",
    "\n",
    "Train in two stages:\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
    "\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Training head using  Keras.model.fit_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T15:45:17.278598Z",
     "start_time": "2018-05-11T15:45:17.036444Z"
    }
   },
   "outputs": [],
   "source": [
    "print(config.BATCH_SIZE)\n",
    "print(model.config.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-05-13T17:48:19.148Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mrcnn', 'fpn', 'rpn']\n",
      "['(mrcnn\\\\_.*)', '(fpn\\\\_.*)', '(rpn\\\\_.*)']\n",
      "layers regex : (mrcnn\\_.*)|(fpn\\_.*)|(rpn\\_.*)\n",
      "\n",
      "Selecting layers to train\n",
      "-------------------------\n",
      "Layer    Layer Name               Layer Type\n",
      "   0  input_image            (InputLayer          )   ............................no weights to train ]\n",
      "   1  zero_padding2d_1       (ZeroPadding2D       )   ............................no weights to train ]\n",
      "   2  conv1                  (Conv2D              )   ............................not a layer we want to train ]\n",
      "   3  bn_conv1               (BatchNorm           )   ............................not a layer we want to train ]\n",
      "   4  activation_1           (Activation          )   ............................no weights to train ]\n",
      "   5  max_pooling2d_1        (MaxPooling2D        )   ............................no weights to train ]\n",
      "   6  res2a_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "   7  bn2a_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "   8  activation_2           (Activation          )   ............................no weights to train ]\n",
      "   9  res2a_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  10  bn2a_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  11  activation_3           (Activation          )   ............................no weights to train ]\n",
      "  12  res2a_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  13  res2a_branch1          (Conv2D              )   ............................not a layer we want to train ]\n",
      "  14  bn2a_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  15  bn2a_branch1           (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  16  add_1                  (Add                 )   ............................no weights to train ]\n",
      "  17  res2a_out              (Activation          )   ............................no weights to train ]\n",
      "  18  res2b_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  19  bn2b_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  20  activation_4           (Activation          )   ............................no weights to train ]\n",
      "  21  res2b_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  22  bn2b_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  23  activation_5           (Activation          )   ............................no weights to train ]\n",
      "  24  res2b_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  25  bn2b_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  26  add_2                  (Add                 )   ............................no weights to train ]\n",
      "  27  res2b_out              (Activation          )   ............................no weights to train ]\n",
      "  28  res2c_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  29  bn2c_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  30  activation_6           (Activation          )   ............................no weights to train ]\n",
      "  31  res2c_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  32  bn2c_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  33  activation_7           (Activation          )   ............................no weights to train ]\n",
      "  34  res2c_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  35  bn2c_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  36  add_3                  (Add                 )   ............................no weights to train ]\n",
      "  37  res2c_out              (Activation          )   ............................no weights to train ]\n",
      "  38  res3a_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  39  bn3a_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  40  activation_8           (Activation          )   ............................no weights to train ]\n",
      "  41  res3a_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  42  bn3a_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  43  activation_9           (Activation          )   ............................no weights to train ]\n",
      "  44  res3a_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  45  res3a_branch1          (Conv2D              )   ............................not a layer we want to train ]\n",
      "  46  bn3a_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  47  bn3a_branch1           (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  48  add_4                  (Add                 )   ............................no weights to train ]\n",
      "  49  res3a_out              (Activation          )   ............................no weights to train ]\n",
      "  50  res3b_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  51  bn3b_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  52  activation_10          (Activation          )   ............................no weights to train ]\n",
      "  53  res3b_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  54  bn3b_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  55  activation_11          (Activation          )   ............................no weights to train ]\n",
      "  56  res3b_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  57  bn3b_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  58  add_5                  (Add                 )   ............................no weights to train ]\n",
      "  59  res3b_out              (Activation          )   ............................no weights to train ]\n",
      "  60  res3c_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  61  bn3c_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  62  activation_12          (Activation          )   ............................no weights to train ]\n",
      "  63  res3c_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  64  bn3c_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  65  activation_13          (Activation          )   ............................no weights to train ]\n",
      "  66  res3c_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  67  bn3c_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  68  add_6                  (Add                 )   ............................no weights to train ]\n",
      "  69  res3c_out              (Activation          )   ............................no weights to train ]\n",
      "  70  res3d_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  71  bn3d_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  72  activation_14          (Activation          )   ............................no weights to train ]\n",
      "  73  res3d_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  74  bn3d_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  75  activation_15          (Activation          )   ............................no weights to train ]\n",
      "  76  res3d_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  77  bn3d_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  78  add_7                  (Add                 )   ............................no weights to train ]\n",
      "  79  res3d_out              (Activation          )   ............................no weights to train ]\n",
      "  80  res4a_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  81  bn4a_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  82  activation_16          (Activation          )   ............................no weights to train ]\n",
      "  83  res4a_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  84  bn4a_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  85  activation_17          (Activation          )   ............................no weights to train ]\n",
      "  86  res4a_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  87  res4a_branch1          (Conv2D              )   ............................not a layer we want to train ]\n",
      "  88  bn4a_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  89  bn4a_branch1           (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  90  add_8                  (Add                 )   ............................no weights to train ]\n",
      "  91  res4a_out              (Activation          )   ............................no weights to train ]\n",
      "  92  res4b_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  93  bn4b_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  94  activation_18          (Activation          )   ............................no weights to train ]\n",
      "  95  res4b_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  96  bn4b_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      "  97  activation_19          (Activation          )   ............................no weights to train ]\n",
      "  98  res4b_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      "  99  bn4b_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 100  add_9                  (Add                 )   ............................no weights to train ]\n",
      " 101  res4b_out              (Activation          )   ............................no weights to train ]\n",
      " 102  res4c_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 103  bn4c_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 104  activation_20          (Activation          )   ............................no weights to train ]\n",
      " 105  res4c_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 106  bn4c_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 107  activation_21          (Activation          )   ............................no weights to train ]\n",
      " 108  res4c_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 109  bn4c_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 110  add_10                 (Add                 )   ............................no weights to train ]\n",
      " 111  res4c_out              (Activation          )   ............................no weights to train ]\n",
      " 112  res4d_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 113  bn4d_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 114  activation_22          (Activation          )   ............................no weights to train ]\n",
      " 115  res4d_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 116  bn4d_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 117  activation_23          (Activation          )   ............................no weights to train ]\n",
      " 118  res4d_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 119  bn4d_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 120  add_11                 (Add                 )   ............................no weights to train ]\n",
      " 121  res4d_out              (Activation          )   ............................no weights to train ]\n",
      " 122  res4e_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 123  bn4e_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 124  activation_24          (Activation          )   ............................no weights to train ]\n",
      " 125  res4e_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 126  bn4e_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 127  activation_25          (Activation          )   ............................no weights to train ]\n",
      " 128  res4e_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 129  bn4e_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 130  add_12                 (Add                 )   ............................no weights to train ]\n",
      " 131  res4e_out              (Activation          )   ............................no weights to train ]\n",
      " 132  res4f_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 133  bn4f_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 134  activation_26          (Activation          )   ............................no weights to train ]\n",
      " 135  res4f_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 136  bn4f_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 137  activation_27          (Activation          )   ............................no weights to train ]\n",
      " 138  res4f_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 139  bn4f_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 140  add_13                 (Add                 )   ............................no weights to train ]\n",
      " 141  res4f_out              (Activation          )   ............................no weights to train ]\n",
      " 142  res5a_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 143  bn5a_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 144  activation_28          (Activation          )   ............................no weights to train ]\n",
      " 145  res5a_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 146  bn5a_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 147  activation_29          (Activation          )   ............................no weights to train ]\n",
      " 148  res5a_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 149  res5a_branch1          (Conv2D              )   ............................not a layer we want to train ]\n",
      " 150  bn5a_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 151  bn5a_branch1           (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 152  add_14                 (Add                 )   ............................no weights to train ]\n",
      " 153  res5a_out              (Activation          )   ............................no weights to train ]\n",
      " 154  res5b_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 155  bn5b_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 156  activation_30          (Activation          )   ............................no weights to train ]\n",
      " 157  res5b_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 158  bn5b_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 159  activation_31          (Activation          )   ............................no weights to train ]\n",
      " 160  res5b_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 161  bn5b_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 162  add_15                 (Add                 )   ............................no weights to train ]\n",
      " 163  res5b_out              (Activation          )   ............................no weights to train ]\n",
      " 164  res5c_branch2a         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 165  bn5c_branch2a          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 166  activation_32          (Activation          )   ............................no weights to train ]\n",
      " 167  res5c_branch2b         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 168  bn5c_branch2b          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 169  activation_33          (Activation          )   ............................no weights to train ]\n",
      " 170  res5c_branch2c         (Conv2D              )   ............................not a layer we want to train ]\n",
      " 171  bn5c_branch2c          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 172  add_16                 (Add                 )   ............................no weights to train ]\n",
      " 173  res5c_out              (Activation          )   ............................no weights to train ]\n",
      " 174  fpn_c5p5               (Conv2D              )   TRAIN \n",
      " 175  fpn_p5upsampled        (UpSampling2D        )   ............................no weights to train ]\n",
      " 176  fpn_c4p4               (Conv2D              )   TRAIN \n",
      " 177  fpn_p4add              (Add                 )   ............................no weights to train ]\n",
      " 178  fpn_p4upsampled        (UpSampling2D        )   ............................no weights to train ]\n",
      " 179  fpn_c3p3               (Conv2D              )   TRAIN \n",
      " 180  fpn_p3add              (Add                 )   ............................no weights to train ]\n",
      " 181  fpn_p3upsampled        (UpSampling2D        )   ............................no weights to train ]\n",
      " 182  fpn_c2p2               (Conv2D              )   TRAIN \n",
      " 183  fpn_p2add              (Add                 )   ............................no weights to train ]\n",
      " 184  fpn_p5                 (Conv2D              )   TRAIN \n",
      " 185  fpn_p2                 (Conv2D              )   TRAIN \n",
      " 186  fpn_p3                 (Conv2D              )   TRAIN \n",
      " 187  fpn_p4                 (Conv2D              )   TRAIN \n",
      " 188  fpn_p6                 (MaxPooling2D        )   ............................no weights to train ]\n",
      "Entering model layer:  rpn_model ------------------------------\n",
      "       0  input_rpn_feature_map   (InputLayer          )   ............................no weights to train ]\n",
      "       1  rpn_conv_shared        (Conv2D              )   TRAIN \n",
      "       2  rpn_class_raw          (Conv2D              )   TRAIN \n",
      "       3  lambda_2               (Lambda              )   ............................no weights to train ]\n",
      "       4  rpn_bbox_pred          (Conv2D              )   TRAIN \n",
      "       5  rpn_class_xxx          (Activation          )   ............................no weights to train ]\n",
      "       6  lambda_3               (Lambda              )   ............................no weights to train ]\n",
      "Exiting model layer  rpn_model --------------------------------\n",
      " 190  rpn_class              (Concatenate         )   ............................no weights to train ]\n",
      " 191  rpn_bbox               (Concatenate         )   ............................no weights to train ]\n",
      " 192  input_gt_boxes         (InputLayer          )   ............................no weights to train ]\n",
      " 193  rpn_proposal_rois      (ProposalLayer       )   ............................no weights to train ]\n",
      " 194  input_gt_class_ids     (InputLayer          )   ............................no weights to train ]\n",
      " 195  lambda_1               (Lambda              )   ............................no weights to train ]\n",
      " 196  proposal_targets       (DetectionTargetLayer_mod)   ............................no weights to train ]\n",
      " 197  roi_align_classifier   (PyramidROIAlign     )   ............................no weights to train ]\n",
      " 198  mrcnn_class_conv1      (TimeDistributed     )   TRAIN \n",
      " 199  mrcnn_class_bn1        (TimeDistributed     )   TRAIN \n",
      " 200  activation_34          (Activation          )   ............................no weights to train ]\n",
      " 201  mrcnn_class_conv2      (TimeDistributed     )   TRAIN \n",
      " 202  mrcnn_class_bn2        (TimeDistributed     )   TRAIN \n",
      " 203  activation_35          (Activation          )   ............................no weights to train ]\n",
      " 204  pool_squeeze           (Lambda              )   ............................no weights to train ]\n",
      " 205  mrcnn_class_logits     (TimeDistributed     )   TRAIN \n",
      " 206  mrcnn_bbox_fc          (TimeDistributed     )   TRAIN \n",
      " 207  mrcnn_class            (TimeDistributed     )   ............................no weights to train ]\n",
      " 208  mrcnn_bbox             (Reshape             )   ............................no weights to train ]\n",
      " 209  cntxt_layer            (CHMLayer            )   ............................no weights to train ]\n",
      " 210  fcn_block1_conv1       (Conv2D              )   ............................not a layer we want to train ]\n",
      " 211  fcn_block1_conv2       (Conv2D              )   ............................not a layer we want to train ]\n",
      " 212  fcn_block1_pool        (MaxPooling2D        )   ............................no weights to train ]\n",
      " 213  fcn_block2_conv1       (Conv2D              )   ............................not a layer we want to train ]\n",
      " 214  fcn_block2_conv2       (Conv2D              )   ............................not a layer we want to train ]\n",
      " 215  fcn_block2_pool        (MaxPooling2D        )   ............................no weights to train ]\n",
      " 216  fcn_block3_conv1       (Conv2D              )   ............................not a layer we want to train ]\n",
      " 217  fcn_block3_conv2       (Conv2D              )   ............................not a layer we want to train ]\n",
      " 218  fcn_block3_conv3       (Conv2D              )   ............................not a layer we want to train ]\n",
      " 219  fcn_block3_pool        (MaxPooling2D        )   ............................no weights to train ]\n",
      " 220  fcn_fc1                (Conv2D              )   ............................not a layer we want to train ]\n",
      " 221  dropout_1              (Dropout             )   ............................no weights to train ]\n",
      " 222  fcn_fc2                (Conv2D              )   ............................not a layer we want to train ]\n",
      " 223  dropout_2              (Dropout             )   ............................no weights to train ]\n",
      " 224  fcn_classify           (Conv2D              )   ............................not a layer we want to train ]\n",
      " 225  fcn_heatmap            (BilinearUpSampling2D)   ............................no weights to train ]\n",
      " 226  fcn_class_conv1        (Conv2D              )   ............................not a layer we want to train ]\n",
      " 227  fcn_class_bn1          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 228  activation_37          (Activation          )   ............................no weights to train ]\n",
      " 229  dropout_3              (Dropout             )   ............................no weights to train ]\n",
      " 230  fcn_class_conv2        (Conv2D              )   ............................not a layer we want to train ]\n",
      " 231  fcn_class_bn2          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 232  dropout_4              (Dropout             )   ............................no weights to train ]\n",
      " 233  fcn_class_conv3        (Conv2D              )   ............................not a layer we want to train ]\n",
      " 234  fcn_class_bn3          (BatchNorm           )   ............................not a layer we want to train ]\n",
      " 235  activation_39          (Activation          )   ............................no weights to train ]\n",
      " 236  flatten_1              (Flatten             )   ............................no weights to train ]\n",
      " 237  input_image_meta       (InputLayer          )   ............................no weights to train ]\n",
      " 238  fcn_bbox_fc            (Dense               )   ............................not a layer we want to train ]\n",
      " 239  fcn_class_logits       (Dense               )   ............................not a layer we want to train ]\n",
      " 240  rpn_class_logits       (Concatenate         )   ............................no weights to train ]\n",
      " 241  input_rpn_match        (InputLayer          )   ............................no weights to train ]\n",
      " 242  input_rpn_bbox         (InputLayer          )   ............................no weights to train ]\n",
      " 243  lambda_4               (Lambda              )   ............................no weights to train ]\n",
      " 244  fcn_bbox_deltas        (Reshape             )   ............................no weights to train ]\n",
      " 245  fcn_probs              (Activation          )   ............................no weights to train ]\n",
      " 246  rpn_class_loss         (Lambda              )   ............................no weights to train ]\n",
      " 247  rpn_bbox_loss          (Lambda              )   ............................no weights to train ]\n",
      " 248  mrcnn_class_loss       (Lambda              )   ............................no weights to train ]\n",
      " 249  mrcnn_bbox_loss        (Lambda              )   ............................no weights to train ]\n",
      " 250  fcn_bbox_loss          (Lambda              )   ............................no weights to train ]\n",
      " 251  fcn_scores             (Reshape             )   ............................no weights to train ]\n",
      "   keras model add loss for  Tensor(\"rpn_class_loss/Reshape_2:0\", shape=(1, 1), dtype=float32)\n",
      "   keras model add loss for  Tensor(\"rpn_bbox_loss/Reshape:0\", shape=(1, 1), dtype=float32)\n",
      "   keras model add loss for  Tensor(\"mrcnn_class_loss/Reshape:0\", shape=(1, 1), dtype=float32)\n",
      "   keras model add loss for  Tensor(\"mrcnn_bbox_loss/Reshape_3:0\", shape=(1, 1), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting at epoch 0 of 25 epochs. LR=0.001\n",
      "\n",
      "Steps per epochs 2 \n",
      "Batch size       5 \n",
      "Checkpoint Path: E:\\Models\\mrcnn_development_logs\\shapes20180513T1946\\mask_rcnn_shapes_{epoch:04d}.h5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:98: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "2/2 [==============================] - 10s 5s/step - loss: 4.7420 - rpn_class_loss: 0.0268 - rpn_bbox_loss: 1.2504 - mrcnn_class_loss: 2.0219 - mrcnn_bbox_loss: 1.4430 - val_loss: 3.3343 - val_rpn_class_loss: 0.0338 - val_rpn_bbox_loss: 0.9163 - val_mrcnn_class_loss: 1.1383 - val_mrcnn_bbox_loss: 1.2459\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.33425665, saving model to E:\\Models\\mrcnn_development_logs\\shapes20180513T1946\\mask_rcnn_shapes_0001.h5\n",
      "Epoch 2/25\n",
      "2/2 [==============================] - 2s 949ms/step - loss: 3.6199 - rpn_class_loss: 0.0353 - rpn_bbox_loss: 1.1016 - mrcnn_class_loss: 1.1087 - mrcnn_bbox_loss: 1.3743 - val_loss: 2.4863 - val_rpn_class_loss: 0.0328 - val_rpn_bbox_loss: 0.8649 - val_mrcnn_class_loss: 0.5532 - val_mrcnn_bbox_loss: 1.0354\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.33425665 to 2.48634696, saving model to E:\\Models\\mrcnn_development_logs\\shapes20180513T1946\\mask_rcnn_shapes_0002.h5\n"
     ]
    }
   ],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "\n",
    "# model.train(dataset_train, dataset_val, \n",
    "#             learning_rate=config.LEARNING_RATE, \n",
    "# #             epochs = 69,\n",
    "#             epochs_to_run =2, \n",
    "#             layers='heads')\n",
    "\n",
    "train_layers = ['mrcnn', 'fpn','rpn']\n",
    "loss_names   = [  \"rpn_class_loss\", \"rpn_bbox_loss\" , \"mrcnn_class_loss\", \"mrcnn_bbox_loss\"]\n",
    "\n",
    "\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs = 25,\n",
    "#             epochs_to_run =0, \n",
    "#             batch_size = 0\n",
    "#             steps_per_epoch = 0 \n",
    "            layers = train_layers,\n",
    "            losses= loss_names\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Define Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T13:21:37.008439Z",
     "start_time": "2018-05-13T13:21:36.759257Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_generator = data_generator(dataset_train, model.config, shuffle=True,\n",
    "                                 batch_size=model.config.BATCH_SIZE,\n",
    "                                 augment = False)\n",
    "val_generator = data_generator(dataset_val, model.config, shuffle=True, \n",
    "                                batch_size=model.config.BATCH_SIZE,\n",
    "                                augment=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Get next shapes from generator and display loaded shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T13:21:38.648279Z",
     "start_time": "2018-05-13T13:21:38.383075Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_batch_x, train_batch_y = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T13:21:41.601482Z",
     "start_time": "2018-05-13T13:21:39.496536Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train_batch_x, train_batch_y = next(train_generator)\n",
    "imgmeta_idx = model.keras_model.input_names.index('input_image_meta')\n",
    "img_meta    = train_batch_x[imgmeta_idx]\n",
    "\n",
    "for img_idx in range(config.BATCH_SIZE):\n",
    "    image_id = img_meta[img_idx,0]\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    print('Image id: ',image_id)\n",
    "    print('Image meta', img_meta[img_idx])\n",
    "    print('Classes (1: circle, 2: square, 3: triangle ): ',class_ids)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Push Data thru model using get_layer_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T13:21:52.971580Z",
     "start_time": "2018-05-13T13:21:43.214787Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "model_output = get_layer_output_2(model.keras_model, train_batch_x, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0      Tensor(\"input_image:0\", shape=(?, 128, 128, 3), dtype=float32)\n",
    "# 1      Tensor(\"input_image_meta:0\", shape=(?, ?), dtype=float32)\n",
    "# 2      Tensor(\"input_rpn_match:0\", shape=(?, ?, 1), dtype=int32)\n",
    "# 3      Tensor(\"input_rpn_bbox:0\", shape=(?, ?, 4), dtype=float32)\n",
    "# 4      Tensor(\"input_gt_class_ids:0\", shape=(?, ?), dtype=int32)\n",
    "# 5      Tensor(\"input_gt_boxes:0\", shape=(?, ?, 4), dtype=float32)\n",
    "# 6      Tensor(\"input_gt_masks:0\", shape=(?, 56, 56, ?), dtype=bool)\n",
    "\n",
    "input_image_meta =  train_batch_x[1]\n",
    "input_rpn_match  =  train_batch_x[2]\n",
    "input_rpn_bbox   =  train_batch_x[3]\n",
    "input_gt_class_ids = train_batch_x[4]\n",
    "input_gt_bboxes = train_batch_x[5]\n",
    "# gt_masks   =  train_batch_x[6]\n",
    "print(' input_rpn_match    ', input_rpn_match.shape)\n",
    "print(' input_rpn_bbox     ', input_rpn_bbox.shape)\n",
    "print(' input_gt_class_ids ', input_gt_class_ids.shape)\n",
    "print(' input_gt_bboxes    ', input_gt_bboxes.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T13:22:48.349621Z",
     "start_time": "2018-05-13T13:22:48.086415Z"
    }
   },
   "outputs": [],
   "source": [
    "# KB.set_session(sess)\n",
    "print(len(model_output))\n",
    "# rpn_class_logits   = model_output[0]\n",
    "# rpn_class          = model_output[1]\n",
    "# rpn_bbox           = model_output[2]\n",
    "# rpn_proposal_rois  = model_output[3]\n",
    "output_rois        = model_output[4]\n",
    "target_class_ids   = model_output[5]\n",
    "target_bbox_deltas = model_output[6]\n",
    "roi_gt_boxes       = model_output[7]\n",
    "mrcnn_class_logits = model_output[8]\n",
    "mrcnn_class        = model_output[9]\n",
    "mrcnn_bbox         = model_output[10]\n",
    "# rpn_class_loss   = model_output[11]\n",
    "# rpn_bbox_loss    = model_output[12]\n",
    "# mrcnn_class_loss = model_output[13]\n",
    "# mrcnn_bbox_loss  = model_output[14]\n",
    "fcn_bbox_loss      = model_output[15]\n",
    "pred_hm            = model_output[16]\n",
    "gt_hm              = model_output[17]\n",
    "pred_hm_norm       = model_output[18]\n",
    "gt_hm_norm         = model_output[19]\n",
    "pred_tensor        = model_output[20]\n",
    "gt_tensor          = model_output[21]\n",
    "gt_deltas          = model_output[22]\n",
    "fcn_heatmap        = model_output[23]\n",
    "fcn_class_logits   = model_output[24]\n",
    "fcn_scores         = model_output[25]\n",
    "fcn_bbox_deltas    = model_output[26]\n",
    "# print(type(model_output[4]))\n",
    "# print(type(output_rois))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T13:25:09.473058Z",
     "start_time": "2018-05-13T13:25:09.230439Z"
    }
   },
   "outputs": [],
   "source": [
    "print(gt_deltas.shape, fcn_bbox_deltas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T13:26:41.382012Z",
     "start_time": "2018-05-13T13:26:41.135397Z"
    }
   },
   "outputs": [],
   "source": [
    "img = 0\n",
    "cls = 3\n",
    "print(gt_deltas[img,cls])\n",
    "print(fcn_bbox_deltas[img,cls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T16:04:16.108798Z",
     "start_time": "2018-05-11T16:04:15.859069Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.keras_model.summary(line_length=132, positions=[0.30,0.75, .83, 1. ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T15:57:13.903381Z",
     "start_time": "2018-05-11T15:57:13.676279Z"
    }
   },
   "outputs": [],
   "source": [
    "print(model.keras_model.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## - Training heads using train_in_batches ()\n",
    "\n",
    "We need to use this method for the time being as the fit generator does not have provide EASY access to the output in Keras call backs. By training in batches, we pass a batch through the network, pick up the generated RoI detections and bounding boxes and generate our semantic / gaussian tensors ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-28T15:03:53.709099Z",
     "start_time": "2018-04-28T15:02:36.185321Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.train_in_batches(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE/6, \n",
    "            epochs_to_run = 3,\n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Simulate one training iteration - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T17:13:55.474597Z",
     "start_time": "2018-04-24T17:13:54.602267Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mrcnn.datagen import data_generator, load_image_gt\n",
    "np.set_printoptions(linewidth=100)\n",
    "\n",
    "learning_rate   = model.config.LEARNING_RATE\n",
    "epochs_to_run   = 2\n",
    "layers          = 'heads'\n",
    "batch_size      = 0\n",
    "steps_per_epoch = 0\n",
    "\n",
    "# assert self.mode == \"training\", \"Create model in training mode.\"\n",
    "# Pre-defined layer regular expressions\n",
    "layer_regex = {\n",
    "    # all layers but the backbone\n",
    "    \"heads\": r\"(mrcnn\\_.*)|(rpn\\_.*)|(fpn\\_.*)|(fcn\\_.*)\",\n",
    "    # From a specific Resnet stage and up\n",
    "    \"3+\": r\"(res3.*)|(bn3.*)|(res4.*)|(bn4.*)|(res5.*)|(bn5.*)|(mrcnn\\_.*)|(rpn\\_.*)|(fpn\\_.*)\",\n",
    "    \"4+\": r\"(res4.*)|(bn4.*)|(res5.*)|(bn5.*)|(mrcnn\\_.*)|(rpn\\_.*)|(fpn\\_.*)\",\n",
    "    \"5+\": r\"(res5.*)|(bn5.*)|(mrcnn\\_.*)|(rpn\\_.*)|(fpn\\_.*)\",\n",
    "    # All layers\n",
    "    \"all\": \".*\",\n",
    "}\n",
    "\n",
    "if layers in layer_regex.keys():\n",
    "    layers = layer_regex[layers]\n",
    "if batch_size == 0 :\n",
    "    batch_size = model.config.BATCH_SIZE            \n",
    "if steps_per_epoch == 0:\n",
    "    steps_per_epoch = model.config.STEPS_PER_EPOCH\n",
    "\n",
    "# Data generators\n",
    "train_generator = data_generator(dataset_train, model.config, shuffle=True,\n",
    "                                 batch_size=batch_size)\n",
    "val_generator   = data_generator(dataset_val, model.config, shuffle=True,\n",
    "                                 batch_size=batch_size,\n",
    "                                 augment=False)\n",
    "\n",
    "# Train\n",
    "log(\"Last epoch completed : {} \".format(model.epoch))\n",
    "log(\"Starting from epoch {} for {} epochs. LR={}\".format(model.epoch, epochs_to_run, learning_rate))\n",
    "log(\"Steps per epoch:    {} \".format(steps_per_epoch))\n",
    "log(\"Batchsize      :    {} \".format(batch_size))\n",
    "log(\"Checkpoint Folder:  {} \".format(model.checkpoint_path))\n",
    "epochs = model.epoch + epochs_to_run\n",
    "\n",
    "from tensorflow.python.platform import gfile\n",
    "if not gfile.IsDirectory(model.log_dir):\n",
    "    log('Creating checkpoint folder')\n",
    "    gfile.MakeDirs(model.log_dir)\n",
    "else:\n",
    "    log('Checkpoint folder already exists')\n",
    "\n",
    "model.set_trainable(layers)            \n",
    "model.compile(learning_rate, model.config.LEARNING_MOMENTUM)        \n",
    "\n",
    "out_labels = model.keras_model._get_deduped_metrics_names()\n",
    "callback_metrics = out_labels + ['val_' + n for n in out_labels]\n",
    "\n",
    "progbar = keras.callbacks.ProgbarLogger(count_mode='steps')\n",
    "progbar.set_model(model.keras_model)\n",
    "progbar.set_params({\n",
    "    'epochs': epochs,\n",
    "    'steps': steps_per_epoch,\n",
    "    'verbose': 1,\n",
    "    'do_validation': False,\n",
    "    'metrics': callback_metrics,\n",
    "})\n",
    "\n",
    "progbar.set_model(model.keras_model) \n",
    "\n",
    "chkpoint = keras.callbacks.ModelCheckpoint(model.checkpoint_path, \n",
    "                                           monitor='loss', verbose=1, save_best_only = True, save_weights_only=True)\n",
    "chkpoint.set_model(model.keras_model)\n",
    "\n",
    "progbar.on_train_begin()\n",
    "epoch_idx = model.epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Simulate one training iteration - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T17:14:05.845189Z",
     "start_time": "2018-04-24T17:14:05.616563Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if epoch_idx >= epochs:\n",
    "    print('Final epoch {} has already completed - Training will not proceed'.format(epochs))\n",
    "\n",
    "# while epoch_idx < epochs :\n",
    "progbar.on_epoch_begin(epoch_idx)\n",
    "steps_index = 0\n",
    "# for steps_index in range(steps_per_epoch):\n",
    "\n",
    "batch_logs = {}\n",
    "print(' self.epoch {}   epochs {}  step {} '.format(model.epoch, epochs, steps_index))\n",
    "batch_logs['batch'] = steps_index\n",
    "batch_logs['size']  = batch_size\n",
    "progbar.on_batch_begin(steps_index, batch_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T17:14:08.788990Z",
     "start_time": "2018-04-24T17:14:08.545340Z"
    }
   },
   "outputs": [],
   "source": [
    "train_batch_x, train_batch_y = next(train_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Simulate one training iteration - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T17:14:32.661153Z",
     "start_time": "2018-04-24T17:14:12.145950Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "imgmeta_idx= model.keras_model.input_names.index('input_image_meta')\n",
    "img_meta  =  train_batch_x[imgmeta_idx]\n",
    "\n",
    "image_id = img_meta[0,0]\n",
    "print('Image id: ',image_id)\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "image_id = img_meta[1,0]\n",
    "print('Image id: ',image_id)\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "outs = model.keras_model.train_on_batch(train_batch_x, train_batch_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate one training iteration - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T17:14:40.086910Z",
     "start_time": "2018-04-24T17:14:36.273765Z"
    }
   },
   "outputs": [],
   "source": [
    "if not isinstance(outs, list):\n",
    "    outs = [outs]\n",
    "for l, o in zip(out_labels, outs):\n",
    "    batch_logs[l] = o\n",
    "\n",
    "progbar.on_batch_end(steps_index, batch_logs)\n",
    "\n",
    "        # print(outs)\n",
    "progbar.on_epoch_end(epoch_idx, {})\n",
    "    # if (epoch_idx % 10) == 0:\n",
    "chkpoint.on_epoch_end(epoch_idx  , batch_logs)\n",
    "epoch_idx += 1\n",
    "\n",
    "# if epoch_idx != self.epoch:\n",
    "# chkpoint.on_epoch_end(epoch_idx -1, batch_logs)\n",
    "model.epoch = max(epoch_idx - 1, epochs)\n",
    "\n",
    "print('Final : self.epoch {}   epochs {}'.format(model.epoch, epochs))\n",
    "# end if (else)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Fine Tuning\n",
    "Fine tune all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also \n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=211,\n",
    "            layers=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "# Uncomment to save manually\n",
    "model_path = os.path.join(MODEL_DIR, \"mask_rcnn_shapes.h5\")\n",
    "model.keras_model.save_weights(model_path)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python [conda env:TF_gpu]",
   "language": "python",
   "name": "conda-env-TF_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
