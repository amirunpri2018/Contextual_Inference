{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Development note book for `build_heatmap()` / `build_gaussian_tf()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-12T12:33:57.194592Z",
     "start_time": "2018-05-12T12:33:56.961972Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T10:59:17.834942Z",
     "start_time": "2018-05-14T10:58:43.516710Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 1.6.0   Keras Version : 2.1.4 \n",
      " Initialize config object - super\n",
      "(56, 56)\n",
      " COCO Model Path       :  E:\\Models\\mask_rcnn_coco.h5\n",
      " Checkpoint folder Path:  E:\\Models\\mrcnn_logs\n",
      "E:\\Models\n",
      "E:\\Models\\mask_rcnn_coco.h5\n",
      "E:\\Models\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "E:\\Models\\mrcnn_logs\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import  gc\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import keras.backend as KB\n",
    "sys.path.append('../')\n",
    "\n",
    "import mrcnn.model_mod     as modellib\n",
    "import mrcnn.visualize as visualize\n",
    "import mrcnn.shapes    as shapes\n",
    "from mrcnn.config      import Config\n",
    "from mrcnn.model       import log\n",
    "from mrcnn.dataset     import Dataset \n",
    "\n",
    "from mrcnn.utils       import stack_tensors, stack_tensors_3d\n",
    "from mrcnn.datagen     import data_generator, load_image_gt\n",
    "from mrcnn.callbacks   import get_layer_output_1,get_layer_output_2\n",
    "from mrcnn.visualize   import plot_gaussian\n",
    "# from mrcnn.pc_layer    import PCTensor\n",
    "# from mrcnn.pc_layer   import PCNLayer\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "MODEL_PATH = 'E:\\Models'\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(MODEL_PATH, \"mrcnn_logs\")\n",
    "# Path to COCO trained weights\n",
    "COCO_MODEL_PATH   = os.path.join(MODEL_PATH, \"mask_rcnn_coco.h5\")\n",
    "RESNET_MODEL_PATH = os.path.join(MODEL_PATH, \"resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n",
    "\n",
    "print(\"Tensorflow Version: {}   Keras Version : {} \".format(tf.__version__,keras.__version__))\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
    "np.set_printoptions(linewidth=100,precision=4)\n",
    "\n",
    "\n",
    "# Build configuration object -----------------------------------------------\n",
    "config = shapes.ShapesConfig()\n",
    "config.BATCH_SIZE      = 3                  # Batch size is 2 (# GPUs * images/GPU).\n",
    "config.IMAGES_PER_GPU  = 3                  # Must match BATCH_SIZE\n",
    "config.STEPS_PER_EPOCH = 2\n",
    "config.FCN_INPUT_SHAPE = config.IMAGE_SHAPE[0:2]\n",
    "# config.display() \n",
    "\n",
    "# Build shape dataset        -----------------------------------------------\n",
    "# Training dataset\n",
    "# generate 500 shapes \n",
    "dataset_train = shapes.ShapesDataset()\n",
    "dataset_train.load_shapes(150, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_train.prepare()\n",
    " \n",
    "\n",
    "# Load and display random samples\n",
    "# image_ids = np.random.choice(dataset_train.image_ids, 3)\n",
    "# for image_id in [3]:\n",
    "#     image = dataset_train.load_image(image_id)\n",
    "#     mask, class_ids = dataset_train.load_mask(image_id)\n",
    "#     visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "print(' COCO Model Path       : ', COCO_MODEL_PATH)\n",
    "print(' Checkpoint folder Path: ', MODEL_DIR)\n",
    "print(MODEL_PATH)\n",
    "print(COCO_MODEL_PATH)\n",
    "print(RESNET_MODEL_PATH)\n",
    "print(MODEL_DIR)\n",
    "\n",
    "\n",
    "np.set_printoptions(linewidth=100, precision=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-12T12:34:32.762154Z",
     "start_time": "2018-05-12T12:34:24.836112Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    set_log_dir: Checkpoint path set to : E:\\Models\\mrcnn_logs\\shapes20180512T1434\\mask_rcnn_shapes_{epoch:04d}.h5\n",
      "    set_log_dir: self.epoch set to 0 \n",
      "\n",
      ">>> Resnet Graph \n",
      "     Input_image shape : (?, 128, 128, 3)\n",
      "     After ZeroPadding2D  : (?, 134, 134, 3) (?, 134, 134, 3)\n",
      "     After Conv2D padding : (?, 64, 64, 64) (?, 64, 64, 64)\n",
      "     After BatchNorm      : (?, 64, 64, 64) (?, 64, 64, 64)\n",
      "     After MaxPooling2D   : (?, 32, 32, 64) (?, 32, 32, 64)\n",
      "\n",
      ">>> Feature Pyramid Network (FPN) Graph \n",
      "     FPN P2 shape : (None, 32, 32, 256)\n",
      "     FPN P3 shape : (None, 16, 16, 256)\n",
      "     FPN P4 shape : (None, 8, 8, 256)\n",
      "     FPN P5 shape : (None, 4, 4, 256)\n",
      "     FPN P6 shape : (None, 2, 2, 256)\n",
      "\n",
      ">>> RPN Layer \n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     depth                   : 256\n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     anchor_stride           : 1\n",
      "\n",
      ">>> RPN Outputs  <class 'list'>\n",
      "      rpn_class_logits/concat:0\n",
      "      rpn_class/concat:0\n",
      "      rpn_bbox/concat:0\n",
      "\n",
      ">>> Proposal Layer - generate  2000  proposals\n",
      "    Init complete. Size of anchors:  (4092, 4)\n",
      "     Scores :  (3, 4092)\n",
      "     Deltas :  (3, 4092, 4)\n",
      "     Anchors:  (3, 4092, 4)\n",
      "     Boxes shape / type after processing:  (3, 4092, 4) <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "     Output: Prposals shape :  (3, ?, ?) (3, None, None)\n",
      "\n",
      ">>> Detection Target Layer (Training Mode)\n",
      "    Detection Target Layer : call()  <class 'list'> 3\n",
      "     proposals.shape    : (3, ?, ?) (3, ?, ?) (None, 2000, 4)\n",
      "     gt_class_ids.shape : (?, ?) (?, ?) (None, None)\n",
      "     gt_bboxes.shape    : (?, ?, 4) (?, ?, 4) (None, None, 4)\n",
      "\n",
      "    Detection Target Layer : return  <class 'list'> 4\n",
      "     output 0  shape (3, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 1  shape (3, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 2  shape (3, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 3  shape (3, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "\n",
      ">>> FPN Classifier Graph \n",
      "     rois shape          : (3, ?, ?)\n",
      "     No of feature_maps  : 4\n",
      "        feature_maps shape  : (?, 32, 32, 256)\n",
      "        feature_maps shape  : (?, 16, 16, 256)\n",
      "        feature_maps shape  : (?, 8, 8, 256)\n",
      "        feature_maps shape  : (?, 4, 4, 256)\n",
      "     input_shape         : [128 128   3]\n",
      "     pool_size           : 7\n",
      "   > PyramidRoI Alignment Layer Call()  5\n",
      "     boxes.shape    : (None, 32, 4)\n",
      "     roi_align_classifier output shape is :  (1, ?, 7, 7, 256) (1, ?, 7, 7, 256)\n",
      "     mrcnn_class_conv1    output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_bn1      output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_relu1    output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_conv2 output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_bn2      output shape is :  (?, 32, 1, 1, 1024)\n",
      "     mrcnn_class_relu2    output shape is :  (?, 32, 1, 1, 1024)\n",
      "     pool_squeeze(Shared) output shape is :  (?, 32, 1024)\n",
      "     mrcnn_class_logits   output shape is :  (?, 32, 4)\n",
      "     mrcnn_class_probs    output shape is :  (?, 32, 4)\n",
      "   mrcnn_bbox_fc        output shape is :  (?, 32, 16)\n",
      "   mrcnn_bbox           output shape is :  (?, 32, 4, 4)\n",
      "\n",
      ">>> CHM Layer  \n",
      "   > CHMLayer Call()  5\n",
      "     mrcnn_class.shape    : (?, 32, 4) (None, 32, 4)\n",
      "     mrcnn_bbox.shape     : (?, 32, 4, 4) (None, 32, 4, 4)\n",
      "     output_rois.shape    : (3, ?, ?) (None, 32, 4)\n",
      "     gt_class_ids.shape   : (?, ?) (None, None)\n",
      "     gt_bboxes.shape      : (?, ?, 4) (None, None, 4)\n",
      "\n",
      "  > BUILD_PREDICTIONS_TF()\n",
      "    num_rois          :  32\n",
      "    mrcnn_class shape :  Tensor(\"cntxt_layer/Shape:0\", shape=(3,), dtype=int32) (None, 32, 4)\n",
      "    mrcnn_bbox.shape  :  Tensor(\"cntxt_layer/Shape_1:0\", shape=(4,), dtype=int32) (None, 32, 4, 4) (?, 32, 4, 4)\n",
      "    output_rois.shape :  Tensor(\"cntxt_layer/Shape_2:0\", shape=(3,), dtype=int32) (3, None, 4)\n",
      "    pred_classes     :  (?, 32)\n",
      "    pred_classes_exp :  (?, 32, 1)\n",
      "    pred_scores      :  (?, 32, 1)\n",
      "    batch_grid       :  (3, 32)\n",
      "    roi_grid         :  (3, 32)\n",
      "    bbox_idx         :  (3, 32, 1)\n",
      "\n",
      "\n",
      "  > BUILD_GROUND TRUTH_TF()\n",
      "    gt_class_ids shape :  (?, ?)     notm_gt_bbox.shape  :  (?, ?, 4)\n",
      "    final gt_tensor shape  :  (3, 4, 100, 6)\n",
      "    final gt_cls_cnt shape :  (3, 4)\n",
      "    complete\n",
      "\n",
      " \n",
      "  > build_heatmap() for  ['pred_heatmap']\n",
      "    orignal in_tensor shape :  (3, 4, 32, 6)\n",
      "    modified in_tensor shape :  (3, 4, 32, 6)\n",
      "    num of bboxes per class is :  Tensor(\"cntxt_layer/ToInt32_1/x:0\", shape=(), dtype=int32)\n",
      "    after transpose  (128, 128, 3, 32, 2)\n",
      "    pt2_sum shape  (3, 4, 32)\n",
      "    dense shape  (?, 6)\n",
      "    Build Stacked output from dynamically partitioned lists --------------\n",
      "    >> input to MVN.PROB: pos_grid (meshgrid) shape:  (128, 128, 3, 32, 2)\n",
      "    << output probabilities shape: (3, 32, 128, 128)\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    gaussian_grid      :  (3, 32, 128, 128)\n",
      "    class shape        :  (3, ?)\n",
      "    roi_grid shape     :  (3, 32)\n",
      "    batch_grid shape   :  (3, 32)\n",
      "    scatter_classes    :  (3, 32, 3)\n",
      "    gaussian scattered :  (3, 4, 32, 128, 128)\n",
      "\n",
      "    Reduce sum based on class ---------------------------------------------\n",
      "    gaussian sum type/name :  <class 'tensorflow.python.framework.ops.Tensor'> cntxt_layer/pred_heatmap_1:0 pred_heatmap\n",
      "    gaussian_sum shape     :  (3, 128, 128, 4) Keras tensor  False\n",
      "\n",
      "    L2 normalization ------------------------------------------------------\n",
      " pred_shape: KB.shape: Tensor(\"cntxt_layer/Shape_6:0\", shape=(4,), dtype=int32)  tf.get_shape():  (4,)  pred_maks.shape: (3, 128, 128, 4) tf.shape : Tensor(\"cntxt_layer/Shape_7:0\", shape=(4,), dtype=int32)\n",
      "WARNING:tensorflow:From D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3157: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "   gauss_flatten    :  (None, None, None) (?, ?, ?)  Keras tensor  False\n",
      "   gauss_norm1      :  (None, None, None) (?, ?, ?)  Keras tensor  False\n",
      "   gauss_norm final :  (3, 128, 128, 4) (3, 128, 128, 4)  Keras tensor  False\n",
      "\n",
      " \n",
      "  > build_heatmap() for  ['gt_heatmap']\n",
      "    orignal in_tensor shape :  (3, 4, 100, 6)\n",
      "    modified in_tensor shape :  (3, 4, 100, 6)\n",
      "    num of bboxes per class is :  Tensor(\"cntxt_layer/ToInt32_4/x:0\", shape=(), dtype=int32)\n",
      "    after transpose  (128, 128, 3, 100, 2)\n",
      "    pt2_sum shape  (3, 4, 100)\n",
      "    dense shape  (?, 6)\n",
      "    Build Stacked output from dynamically partitioned lists --------------\n",
      "    >> input to MVN.PROB: pos_grid (meshgrid) shape:  (128, 128, 3, 100, 2)\n",
      "    << output probabilities shape: (3, 100, 128, 128)\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    gaussian_grid      :  (3, 100, 128, 128)\n",
      "    class shape        :  (3, ?)\n",
      "    roi_grid shape     :  (3, 100)\n",
      "    batch_grid shape   :  (3, 100)\n",
      "    scatter_classes    :  (3, 100, 3)\n",
      "    gaussian scattered :  (3, 4, 100, 128, 128)\n",
      "\n",
      "    Reduce sum based on class ---------------------------------------------\n",
      "    gaussian sum type/name :  <class 'tensorflow.python.framework.ops.Tensor'> cntxt_layer/gt_heatmap:0 gt_heatmap\n",
      "    gaussian_sum shape     :  (3, 128, 128, 4) Keras tensor  False\n",
      "\n",
      "    L2 normalization ------------------------------------------------------\n",
      " pred_shape: KB.shape: Tensor(\"cntxt_layer/Shape_11:0\", shape=(4,), dtype=int32)  tf.get_shape():  (4,)  pred_maks.shape: (3, 128, 128, 4) tf.shape : Tensor(\"cntxt_layer/Shape_12:0\", shape=(4,), dtype=int32)\n",
      "   gauss_flatten    :  (None, None, None) (?, ?, ?)  Keras tensor  False\n",
      "   gauss_norm1      :  (None, None, None) (?, ?, ?)  Keras tensor  False\n",
      "   gauss_norm final :  (3, 128, 128, 4) (3, 128, 128, 4)  Keras tensor  False\n",
      "\n",
      "    Output build_heatmap \n",
      "     pred_heatmap :  (3, 128, 128, 4) Keras tensor  False\n",
      "     gt_heatmap   :  (3, 128, 128, 4) Keras tensor  False\n",
      "<<<  shape of pred_heatmap   :  (3, 128, 128, 4)  Keras tensor  True\n",
      "<<<  shape of gt_heatmap     :  (3, 128, 128, 4)  Keras tensor  True\n",
      "\n",
      ">>> FCN Layer \n",
      "     feature map shape is  (3, 128, 128, 4)\n",
      "     height : 128 width : 128 classes : 4\n",
      "     image_data_format     channels_last\n",
      "   FCN Block 11 shape is :  (3, 128, 128, 64)\n",
      "   FCN Block 12 shape is :  (3, 128, 128, 64)\n",
      "   FCN Block 13 shape is :  (3, 64, 64, 64)\n",
      "   FCN Block 21 shape is :  (3, 64, 64, 128)\n",
      "   FCN Block 22 shape is :  (3, 64, 64, 128)\n",
      "   FCN Block 23 (Max pooling) shape is :  (3, 32, 32, 128)\n",
      "   FCN Block 31 shape is :  (3, 32, 32, 256)\n",
      "   FCN Block 32 shape is :  (3, 32, 32, 256)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FCN Block 33 shape is :  (3, 32, 32, 256)\n",
      "   FCN Block 34 (Max pooling) shape is :  (3, 16, 16, 256)\n",
      "   FCN fully connected 1 (fcn_fc1) shape is :  (3, 16, 16, 2048)\n",
      "   FCN fully connected 2 (fcn_fc2) shape is :  (3, 16, 16, 2048)\n",
      "   FCN final conv2d (fcn_classify) shape is :  (None, 16, 16, 4)\n",
      "   h_factor :  8.0 w_factor :  8.0\n",
      "\n",
      ">>> BilinearUpSampling2D layer\n",
      "     data_format :  channels_last\n",
      "     size        :  (8.0, 8.0)\n",
      "     target_size :  None\n",
      "     input_spec  :  [InputSpec(ndim=4)]\n",
      "     call resize_images_bilinear with size:  (8.0, 8.0)\n",
      "     CHANNELS LAST: X:  (3, 16, 16, 4)  KB.int_shape() :  (None, 16, 16, 4)\n",
      "     target_height   :  None  target_width  :  None\n",
      "     new_shape (2):  (2,) (2,)\n",
      "     new_shape (3):  (2,) (2,)\n",
      "     X after image.resize_bilinear:  (3, ?, ?, 4)\n",
      "     Dimensions of X after set_shape() :  (3, 128, 128, 4)\n",
      "    BilinearUpSampling2D. compute_output_shape()\n",
      "   FCN output (fcn_bilinear) shape is :  (3, 128, 128, 4) Keras tensor  True\n",
      "   fcn_heatmap  shape is :  (None, 128, 128, 4)  Keras tensor  True\n",
      "\n",
      "\n",
      "---------------------------------------------------\n",
      "    building Loss Functions \n",
      "---------------------------------------------------\n",
      "\n",
      ">>> rpn_bbox_loss_graph\n",
      "    rpn_match size : (?, ?)\n",
      "    rpn_bbox  size : (?, ?, 4)\n",
      "    tf default session:  None\n",
      "\n",
      ">>> rpn_bbox_loss_graph\n",
      "    rpn_match size : (?, ?)\n",
      "    rpn_bbox  size : (?, ?, 4)\n",
      "    tf default session:  None\n",
      "\n",
      ">>> mrcnn_class_loss_graph \n",
      "    target_class_ids  size : (3, ?)\n",
      "    pred_class_logits size : (?, 32, 4)\n",
      "    active_class_ids  size : (?, ?)\n",
      "\n",
      ">>> mrcnn_class_loss_graph \n",
      "    target_class_ids  size : (?, 1)\n",
      "    pred_class_logits size : (?, 32, 4)\n",
      "    active_class_ids  size : (?, ?)\n",
      "\n",
      ">>> mrcnn_bbox_loss_graph \n",
      "    target_class_ids  size : (3, ?)\n",
      "    pred_bbox size         : (?, 32, 4, 4)\n",
      "    target_bbox size       : (3, ?, ?)\n",
      "\n",
      ">>> mrcnn_bbox_loss_graph \n",
      "    target_class_ids  size : (?, 1)\n",
      "    pred_bbox size         : (?, 32, 4, 4)\n",
      "    target_bbox size       : (?, 32, 4)\n",
      "\n",
      ">>> MODIFIED MaskRCNN build complete\n",
      ">>> MODIFIED MaskRCNN initialization complete\n"
     ]
    }
   ],
   "source": [
    "try :\n",
    "    del model\n",
    "    print('delete model is successful')\n",
    "    gc.collect()\n",
    "except: \n",
    "    pass\n",
    "KB.clear_session()\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' COCO Model Path       : ', COCO_MODEL_PATH)\n",
    "print(' Checkpoint folder Path: ', MODEL_DIR)\n",
    "print(' Model Parent Path     : ', MODEL_PATH)\n",
    "print(' Resent Model Path     : ', RESNET_MODEL_PATH)\n",
    "print(model.find_last())\n",
    "\n",
    "# model.compile_only(learning_rate=config.LEARNING_RATE, layers='all')\n",
    "# sys.setrecursionlimit(5000)\n",
    "# tst = model.keras_model.to_json()\n",
    "# save_model(MODEL_DIR, 'my_saved_model')\n",
    "# print(model.find_last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-12T12:40:37.028646Z",
     "start_time": "2018-05-12T12:40:25.833829Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> find_last checkpoint in :  E:\\Models\\mrcnn_logs\n",
      "('E:\\\\Models\\\\mrcnn_logs\\\\shapes20180511T1742', 'E:\\\\Models\\\\mrcnn_logs\\\\shapes20180511T1742\\\\mask_rcnn_shapes_0023.h5')\n",
      ">>> load_weights()\n",
      "    load_weights: Loading weights from: E:\\Models\\mask_rcnn_coco.h5\n",
      "    load_weights: Log directory set to : E:\\Models\\mask_rcnn_coco.h5\n",
      "    set_log_dir: Checkpoint path set to : E:\\Models\\mrcnn_logs\\shapes20180512T1440\\mask_rcnn_shapes_{epoch:04d}.h5\n",
      "    set_log_dir: self.epoch set to 0 \n",
      "    Load weights complete :  E:\\Models\\mask_rcnn_coco.h5\n"
     ]
    }
   ],
   "source": [
    "#model.keras_model.summary(line_length = 120) \n",
    "# model.compile_only(learning_rate=config.LEARNING_RATE, layers='heads')\n",
    "# KB.set_learning_phase(1)\n",
    "'''\n",
    "methods to load weights\n",
    "1 - load a specific file\n",
    "2 - find a last checkpoint in a specific folder \n",
    "3 - use init_with keyword \n",
    "'''\n",
    "## 1- look for a specific weights file \n",
    "## Load trained weights (fill in path to trained weights here)\n",
    "# model_path  = 'E:\\\\Models\\\\mrcnn_logs\\\\shapes20180428T1819\\\\mask_rcnn_shapes_5784.h5'\n",
    "# print(' model_path : ', model_path )\n",
    "# assert model_path != \"\", \"Provide path to trained weights\"\n",
    "# print(\"Loading weights from \", model_path)\n",
    "# model.load_weights(model_path, by_name=True)    \n",
    "# print('Load weights complete')\n",
    "\n",
    "# ## 2- look for last checkpoint file in a specific folder (not working correctly)\n",
    "# model.config.LAST_EPOCH_RAN = 5784\n",
    "# model.model_dir = 'E:\\\\Models\\\\mrcnn_logs\\\\shapes20180428T1819'\n",
    "# last_model_found = model.find_last()\n",
    "# print(' last model in MODEL_DIR: ', last_model_found)\n",
    "# # loc= model.load_weights(model.find_last()[1], by_name=True)\n",
    "# # print('Load weights complete :', loc)\n",
    "\n",
    "\n",
    "## 3- Use init_with keyword\n",
    "## Which weights to start with?\n",
    "init_with = \"coco\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "#     loc=model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "    loc=model.load_weights(RESNET_MODEL_PATH, by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    \n",
    "    # See README for instructions to download the COCO weights\n",
    "    loc=model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    loc= model.load_weights(model.find_last()[1], by_name=True)\n",
    "print('Load weights complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-12T12:40:37.277331Z",
     "start_time": "2018-05-12T12:40:37.030649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Outputs: \n",
      "0      Tensor(\"rpn_class_logits/concat:0\", shape=(?, ?, 2), dtype=float32)\n",
      "1      Tensor(\"rpn_class/concat:0\", shape=(?, ?, 2), dtype=float32)\n",
      "2      Tensor(\"rpn_bbox/concat:0\", shape=(?, ?, 4), dtype=float32)\n",
      "3      Tensor(\"rpn_proposal_rois/packed_2:0\", shape=(3, ?, ?), dtype=float32)\n",
      "4      Tensor(\"proposal_targets/output_rois:0\", shape=(3, ?, ?), dtype=float32)\n",
      "5      Tensor(\"proposal_targets/target_class_ids:0\", shape=(3, ?), dtype=int32)\n",
      "6      Tensor(\"proposal_targets/target_bbox_deltas:0\", shape=(3, ?, ?), dtype=float32)\n",
      "7      Tensor(\"proposal_targets/roi_gt_boxes:0\", shape=(3, ?, ?), dtype=float32)\n",
      "8      Tensor(\"mrcnn_class_logits/Reshape_1:0\", shape=(?, 32, 4), dtype=float32)\n",
      "9      Tensor(\"mrcnn_class/Reshape_1:0\", shape=(?, 32, 4), dtype=float32)\n",
      "10      Tensor(\"mrcnn_bbox/Reshape:0\", shape=(?, 32, 4, 4), dtype=float32)\n",
      "11      Tensor(\"rpn_class_loss/Reshape_2:0\", shape=(1, 1), dtype=float32)\n",
      "12      Tensor(\"rpn_bbox_loss/Reshape:0\", shape=(1, 1), dtype=float32)\n",
      "13      Tensor(\"mrcnn_class_loss/Reshape:0\", shape=(1, 1), dtype=float32)\n",
      "14      Tensor(\"mrcnn_bbox_loss/Reshape_3:0\", shape=(1, 1), dtype=float32)\n",
      "15      Tensor(\"cntxt_layer/pred_heatmap_1:0\", shape=(3, 128, 128, 4), dtype=float32)\n",
      "16      Tensor(\"cntxt_layer/gt_heatmap:0\", shape=(3, 128, 128, 4), dtype=float32)\n",
      "17      Tensor(\"cntxt_layer/pred_heatmap_norm:0\", shape=(3, 128, 128, 4), dtype=float32)\n",
      "18      Tensor(\"cntxt_layer/gt_heatmap_norm:0\", shape=(3, 128, 128, 4), dtype=float32)\n",
      "19      Tensor(\"cntxt_layer/pred_tensor:0\", shape=(3, 4, 32, 6), dtype=float32)\n",
      "20      Tensor(\"cntxt_layer/gt_tensor:0\", shape=(3, 4, 100, 6), dtype=float32)\n",
      "21      Tensor(\"fcn_heatmap/ResizeBilinear:0\", shape=(3, 128, 128, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print('\\n Inputs: ') \n",
    "for i, out in enumerate(model.keras_model.inputs):\n",
    "    print(i , '    ', out)\n",
    "\n",
    "print('\\n Outputs: ') \n",
    "for i, out in enumerate(model.keras_model.outputs):\n",
    "    print(i , '    ', out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-12T12:42:03.546437Z",
     "start_time": "2018-05-12T12:42:03.312801Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_generator = data_generator(dataset_train, model.config, shuffle=True,\n",
    "                                 batch_size=model.config.BATCH_SIZE,\n",
    "                                 augment = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-12T12:42:05.528669Z",
     "start_time": "2018-05-12T12:42:05.281012Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "train_batch_x, train_batch_y = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-12T12:42:07.470865Z",
     "start_time": "2018-05-12T12:42:06.451121Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image id:  72\n",
      "Image meta [ 72 128 128   3   0   0 128 128   1   1   1   1]\n",
      "Classes (1: circle, 2: square, 3: triangle ):  [3 3]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x249ad127d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image id:  8\n",
      "Image meta [  8 128 128   3   0   0 128 128   1   1   1   1]\n",
      "Classes (1: circle, 2: square, 3: triangle ):  [2 3 2 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x249ac5da5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image id:  99\n",
      "Image meta [ 99 128 128   3   0   0 128 128   1   1   1   1]\n",
      "Classes (1: circle, 2: square, 3: triangle ):  [3 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x249ac8464a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train_batch_x, train_batch_y = next(train_generator)\n",
    "imgmeta_idx = model.keras_model.input_names.index('input_image_meta')\n",
    "img_meta    = train_batch_x[imgmeta_idx]\n",
    "\n",
    "for img_idx in range(config.BATCH_SIZE):\n",
    "    image_id = img_meta[img_idx,0]\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    print('Image id: ',image_id)\n",
    "    print('Image meta', img_meta[img_idx])\n",
    "    print('Classes (1: circle, 2: square, 3: triangle ): ',class_ids)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-12T12:42:18.158367Z",
     "start_time": "2018-05-12T12:42:11.624878Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/* Inputs */\n",
      "Input  0:  (input_image:0                           ) \t  Input shape: (3, 128, 128, 3)\n",
      "Input  1:  (input_image_meta:0                      ) \t  Input shape: (3, 12)\n",
      "Input  2:  (input_rpn_match:0                       ) \t  Input shape: (3, 4092, 1)\n",
      "Input  3:  (input_rpn_bbox:0                        ) \t  Input shape: (3, 256, 4)\n",
      "Input  4:  (input_gt_class_ids:0                    ) \t  Input shape: (3, 100)\n",
      "Input  5:  (input_gt_boxes:0                        ) \t  Input shape: (3, 100, 4)\n",
      "Input  6:  (input_gt_masks:0                        ) \t  Input shape: (3, 56, 56, 100)\n",
      "<class 'list'>\n",
      "\n",
      "/* Outputs */\n",
      "Output  0: (rpn_class_logits/concat:0               ) \t  Output shape: (3, 4092, 2)\n",
      "Output  1: (rpn_class/concat:0                      ) \t  Output shape: (3, 4092, 2)\n",
      "Output  2: (rpn_bbox/concat:0                       ) \t  Output shape: (3, 4092, 4)\n",
      "Output  3: (rpn_proposal_rois/packed_2:0            ) \t  Output shape: (3, 2000, 4)\n",
      "Output  4: (proposal_targets/output_rois:0          ) \t  Output shape: (3, 32, 4)\n",
      "Output  5: (proposal_targets/target_class_ids:0     ) \t  Output shape: (3, 32)\n",
      "Output  6: (proposal_targets/target_bbox_deltas:0   ) \t  Output shape: (3, 32, 4)\n",
      "Output  7: (proposal_targets/roi_gt_boxes:0         ) \t  Output shape: (3, 32, 4)\n",
      "Output  8: (mrcnn_class_logits/Reshape_1:0          ) \t  Output shape: (3, 32, 4)\n",
      "Output  9: (mrcnn_class/Reshape_1:0                 ) \t  Output shape: (3, 32, 4)\n",
      "Output 10: (mrcnn_bbox/Reshape:0                    ) \t  Output shape: (3, 32, 4, 4)\n",
      "Output 11: (rpn_class_loss/Reshape_2:0              ) \t  Output shape: (1, 1)\n",
      "Output 12: (rpn_bbox_loss/Reshape:0                 ) \t  Output shape: (1, 1)\n",
      "Output 13: (mrcnn_class_loss/Reshape:0              ) \t  Output shape: (1, 1)\n",
      "Output 14: (mrcnn_bbox_loss/Reshape_3:0             ) \t  Output shape: (1, 1)\n",
      "Output 15: (cntxt_layer/pred_heatmap_1:0            ) \t  Output shape: (3, 128, 128, 4)\n",
      "Output 16: (cntxt_layer/gt_heatmap:0                ) \t  Output shape: (3, 128, 128, 4)\n",
      "Output 17: (cntxt_layer/pred_heatmap_norm:0         ) \t  Output shape: (3, 128, 128, 4)\n",
      "Output 18: (cntxt_layer/gt_heatmap_norm:0           ) \t  Output shape: (3, 128, 128, 4)\n",
      "Output 19: (cntxt_layer/pred_tensor:0               ) \t  Output shape: (3, 4, 32, 6)\n",
      "Output 20: (cntxt_layer/gt_tensor:0                 ) \t  Output shape: (3, 4, 100, 6)\n",
      "Output 21: (fcn_heatmap/ResizeBilinear:0            ) \t  Output shape: (3, 128, 128, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_output = get_layer_output_2(model.keras_model, train_batch_x, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:24:50.253598Z",
     "start_time": "2018-05-11T13:24:50.012462Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_image_meta =  train_batch_x[1]\n",
    "input_rpn_match  =  train_batch_x[2]\n",
    "input_rpn_bbox   =  train_batch_x[3]\n",
    "input_gt_class_ids = train_batch_x[4]\n",
    "input_gt_bboxes = train_batch_x[5]\n",
    "# gt_masks   =  train_batch_x[6]\n",
    "print(' input_rpn_match    ', input_rpn_match.shape)\n",
    "print(' input_rpn_bbox     ', input_rpn_bbox.shape)\n",
    "print(' input_gt_class_ids ', input_gt_class_ids.shape)\n",
    "print(' input_gt_bboxes    ', input_gt_bboxes.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(model_output))\n",
    "# rpn_class_logits   = model_output[0]\n",
    "# rpn_class          = model_output[1]\n",
    "# rpn_bbox           = model_output[2]\n",
    "# rpn_proposal_rois  = model_output[3]\n",
    "# output_rois        = model_output[4]\n",
    "# target_class_ids   = model_output[5]\n",
    "# target_bbox_deltas = model_output[6]\n",
    "# roi_gt_boxes       = model_output[7]\n",
    "# mrcnn_class_logits = model_output[8]\n",
    "# mrcnn_class        = model_output[9]\n",
    "# mrcnn_bbox         = model_output[10]\n",
    "# rpn_class_loss   = model_output[11]\n",
    "# rpn_bbox_loss    = model_output[12]\n",
    "# mrcnn_class_loss = model_output[13]\n",
    "# mrcnn_bbox_loss  = model_output[14]\n",
    "# fcn_bbox_loss      = model_output[15]\n",
    "# pred_hm            = model_output[16]\n",
    "# gt_hm              = model_output[17]\n",
    "# pred_hm_norm       = model_output[18]\n",
    "gt_hm_norm         = model_output[19]\n",
    "# pred_tensor        = model_output[20]\n",
    "# gt_tensor          = model_output[21]\n",
    "# gt_deltas          = model_output[22]\n",
    "fcn_heatmap        = model_output[23]\n",
    "# fcn_class_logits   = model_output[24]\n",
    "# fcn_scores         = model_output[25]\n",
    "# fcn_bbox_deltas    = model_output[26]\n",
    "# print(type(model_output[4]))\n",
    "# print(type(output_rois))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:12:47.630505Z",
     "start_time": "2018-05-11T13:12:47.372814Z"
    },
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "print(pred_tensor[0,2])\n",
    "print(output_rois[0,:])\n",
    "width  = pred_tensor[:,:,:,3] - pred_tensor[:,:,:,1]      # x2 - x1\n",
    "height = pred_tensor[:,:,:,2] - pred_tensor[:,:,:,0]\n",
    "cx     = pred_tensor[:,:,:,1] + ( width  / 2.0)\n",
    "cy     = pred_tensor[:,:,:,0] + ( height / 2.0)\n",
    "means  = np.floor(np.stack((cy,cx),axis = -1))\n",
    "\n",
    "print(means.shape)\n",
    "print(means[0,2,:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:20:27.357106Z",
     "start_time": "2018-05-11T13:20:27.100938Z"
    }
   },
   "outputs": [],
   "source": [
    "print(gt_tensor[0,2])\n",
    "print(output_rois[0,:])\n",
    "width  = gt_tensor[:,:,:,3] - gt_tensor[:,:,:,1]      # x2 - x1\n",
    "height = gt_tensor[:,:,:,2] - gt_tensor[:,:,:,0]\n",
    "cx     = gt_tensor[:,:,:,1] + ( width  / 2.0)\n",
    "cy     = gt_tensor[:,:,:,0] + ( height / 2.0)\n",
    "gt_means  = np.floor(np.stack((cy,cx),axis = -1))\n",
    "\n",
    "print(gt_means.shape)\n",
    "print(gt_means[0,2,:12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Find maximum of gaussian distributions for the pred_heatmap\n",
    "Potentially use this as our heatmap scores \n",
    "Found out that using MAX values from the class heatmap (currently generated from the pred_tensor that itself is generated form output_rois and mrcnn_class) is not a viable option, because mutlple max values tend to congreagate around the peak of the gaussian distribution. \n",
    "This is also the case for gt_heatmaps.\n",
    "This will probably also be the case for the FCN output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pred_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:23:37.739059Z",
     "start_time": "2018-05-11T13:23:37.484900Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, threshold=10000)\n",
    "\n",
    "print(pred_hm.shape)\n",
    "cls_hm = pred_hm[0,:,:,2]\n",
    "print(cls_hm.shape)\n",
    "print(np.unravel_index(np.argmax(cls_hm) , cls_hm.shape) )\n",
    "print(np.max(cls_hm))\n",
    "\n",
    "print(pred_hm_norm.shape)\n",
    "cls_hm_norm = pred_hm_norm[0,:,:,2]\n",
    "print(cls_hm_norm.shape)\n",
    "print(np.unravel_index(np.argmax(cls_hm_norm) , cls_hm_norm.shape) )\n",
    "print(np.max(cls_hm_norm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:09:06.929477Z",
     "start_time": "2018-05-11T13:09:06.655253Z"
    },
    "hideCode": true,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "hm_ls =np.ravel(cls_hm)\n",
    "hm_ls_norm = np.ravel(cls_hm_norm)\n",
    "srtlst = np.argsort(hm_ls)\n",
    "srtlst_norm = np.argsort(hm_ls_norm)\n",
    "print(' Sortlist')\n",
    "print(srtlst[::-1])\n",
    "print(srtlst.shape)\n",
    "print('---- norm ------')\n",
    "print(srtlst_norm[::-1])\n",
    "print(srtlst_norm.shape)\n",
    "\n",
    "print(' Top scores')\n",
    "top_scores = srtlst[:-21:-1]\n",
    "print('---- norm ------')\n",
    "top_scores_norm = srtlst_norm[:-21:-1]\n",
    "print(len(top_scores),top_scores)\n",
    "print(' Top items ')\n",
    "for i in top_scores :\n",
    "    print( i , '  ', np.unravel_index(i, cls_hm.shape))\n",
    "print('---- norm ------')    \n",
    "for i in top_scores_norm :\n",
    "    print( i , '  ', np.unravel_index(i, cls_hm_norm.shape))\n",
    "print(' Top scores ')\n",
    "print(hm_ls[top_scores])\n",
    "print('---- norm ------')    \n",
    "print(hm_ls_norm[top_scores_norm])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gt_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:24:12.185707Z",
     "start_time": "2018-05-11T13:24:11.932533Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, threshold=10000)\n",
    "print(pred_hm.shape)\n",
    "cls_hm = gt_hm[0,:,:,2]\n",
    "print(cls_hm.shape)\n",
    "print(np.unravel_index(np.argmax(cls_hm) , cls_hm.shape) )\n",
    "print(np.max(cls_hm))\n",
    "\n",
    "print('---- norm -----')\n",
    "print(gt_hm_norm.shape)\n",
    "cls_hm_norm = gt_hm_norm[0,:,:,2]\n",
    "print(cls_hm_norm.shape)\n",
    "print(np.unravel_index(np.argmax(cls_hm_norm) , cls_hm_norm.shape) )\n",
    "print(np.max(cls_hm_norm))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:24:14.243495Z",
     "start_time": "2018-05-11T13:24:13.965220Z"
    },
    "hideCode": true,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "hm_ls =np.ravel(cls_hm)\n",
    "hm_ls_norm = np.ravel(cls_hm_norm)\n",
    "srtlst = np.argsort(hm_ls)\n",
    "srtlst_norm = np.argsort(hm_ls_norm)\n",
    "print(' Sortlist')\n",
    "print(srtlst[::-1])\n",
    "print(srtlst.shape)\n",
    "print('---- norm ------')\n",
    "print(srtlst_norm[::-1])\n",
    "print(srtlst_norm.shape)\n",
    "\n",
    "print(' Top scores')\n",
    "top_scores = srtlst[:-21:-1]\n",
    "print('---- norm ------')\n",
    "top_scores_norm = srtlst_norm[:-21:-1]\n",
    "print(len(top_scores),top_scores)\n",
    "print(' Top items ')\n",
    "for i in top_scores :\n",
    "    print( i , '  ', np.unravel_index(i, cls_hm.shape))\n",
    "print('---- norm ------')    \n",
    "for i in top_scores_norm :\n",
    "    print( i , '  ', np.unravel_index(i, cls_hm_norm.shape))\n",
    "print(' Top scores ')\n",
    "print(hm_ls[top_scores])\n",
    "print('---- norm ------')    \n",
    "print(hm_ls_norm[top_scores_norm])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T11:48:39.739236Z",
     "start_time": "2018-05-11T11:48:39.479040Z"
    }
   },
   "outputs": [],
   "source": [
    "max_a = np.max(cls_pred_heatmap)\n",
    "print(max_a.shape)\n",
    "\n",
    "print(np.unravel_index(np.argmax(prob_a) , prob_a.shape) )\n",
    "\n",
    "print()\n",
    "\n",
    "print(' covar ', covar_sqrd)\n",
    "print(prob_b[35:50, 45:54])\n",
    "max_b = np.max(prob_b)\n",
    "print(np.unravel_index(np.argmax(prob_b) , prob_b.shape) )\n",
    "\n",
    "print('max a , max_b ', max_a, max_b, max_a/max_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "##  `development build_gaussian_tf ()` \n",
    "\n",
    "### Generate Multivariate Normal Distribution from Pred_Tensor\n",
    "\n",
    "`pred_tensor[:,:,:,1:7]`  == `[116.9736  21.8213  36.2715  45.6026   0.    0.9139   ]`\n",
    "\n",
    "\n",
    "Detections returned by `detect()` routine:\n",
    "\n",
    "`[[ 25.          18.          80.          72.           2.           0.99936014]\n",
    "  [ 51.           3.         106.          71.           3.           0.99924326]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare values to pass to build_gaussian_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:24:50.253598Z",
     "start_time": "2018-05-11T13:24:50.012462Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# mrcnn_bbox  = model_output[11]\n",
    "# mrcnn_class = model_output[10]\n",
    "# pred_tensor = model_output[20]\n",
    "# output_rois = model_output[4]\n",
    "pred_heatmap= model_output[18]\n",
    "gt_heatmap  = model_output[19]\n",
    "print(type(model_output[4]))\n",
    "print(type(output_rois))\n",
    "\n",
    "# sess = KB.get_session()\n",
    "# KB.set_session(sess)\n",
    "print(len(model_output))\n",
    "# KB.set_session(sess)\n",
    "print(type(model_output[4]))\n",
    "print(type(output_rois))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T14:59:46.125773Z",
     "start_time": "2018-05-10T14:59:45.878270Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = 1\n",
    "max_score = np.max(mrcnn_class, axis = -1)\n",
    "max_class = np.argmax(mrcnn_class, axis = -1)\n",
    "print(' output_rois[',img,'] \\n', output_rois[1]*[128,128,128,128])\n",
    "print('max class shape:',max_class.shape, 'max score shape: ',max_score.shape)\n",
    "print('max class[',img,']\\n',max_class[img])\n",
    "print('max score[',img,']\\n',max_score[img])\n",
    "print(' mrcnn class.shape ',mrcnn_class.shape)\n",
    "print('marcnn_classe[',img,',:]\\n',mrcnn_class[1,:])\n",
    "# print(output_rois[1])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "\n",
    "###  Display for visual check - `pred_tensor` is the final result which is passed on to  `build_gaussian_tf()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:49:20.117333Z",
     "start_time": "2018-05-11T13:49:19.805503Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# with sess.as_default():\n",
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "# print('scatter shape is ', pred_scatt.get_shape())\n",
    "print('pred_tensor shape is ', pred_tensor.shape)\n",
    "img = 0\n",
    "print('Image ', img , '/ Class 0 ------------')\n",
    "print(pred_tensor[img,0])\n",
    "print('Image ', img , '/ Class 1 ------------')\n",
    "print(pred_tensor[img,1])\n",
    "print('Image ', img , '/ Class 2 ------------')\n",
    "print(pred_tensor[img,2])\n",
    "print('Image ', img , '/ Class 3 ------------')\n",
    "print(pred_tensor[img,3])\n",
    "\n",
    "# cls = 3\n",
    "# print('Image 0 / Class ', cls ,' ------------')\n",
    "# print(pred_tensor[0, cls].eval())\n",
    "# print('Image 1 / Class ', cls ,' ------------')\n",
    "# print(pred_tensor[1, cls].eval())\n",
    "# print('Image 2 / Class ', cls ,' ------------')\n",
    "# print(pred_tensor[2, cls].eval())\n",
    "\n",
    "\n",
    "\n",
    "# print(pred_tensor_out.shape)\n",
    "# print(pred_tensor_out[2,2, :].eval())\n",
    "# print(pred_tensor.shape)\n",
    "# pred_tensor_tst = pred_tensor *[128, 128, 128,128,1,1]\n",
    "# print(pred_tensor_tst[2,2,:].eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "\n",
    "####  Display for visual check - `gt_tensor` is the final result which is passed on to  `build_gaussian_tf()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:51:18.251895Z",
     "start_time": "2018-05-11T13:51:17.973154Z"
    }
   },
   "outputs": [],
   "source": [
    "# with sess.as_default():\n",
    "np.set_printoptions(linewidth=150, precision=6)\n",
    "# print('scatter shape is ', pred_scatt.get_shape())\n",
    "print('pred_tensor shape is ', gt_tensor.shape)\n",
    "img = 1\n",
    "print('Image ', img , '/ Class 0 ------------')\n",
    "print(gt_tensor[img,0])\n",
    "print('Image ', img , '/ Class 1 ------------')\n",
    "print(gt_tensor[img,1])\n",
    "print('Image ', img , '/ Class 2 ------------')\n",
    "print(gt_tensor[img,2])\n",
    "print('Image ', img , '/ Class 3 ------------')\n",
    "print(gt_tensor[img,3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Copy of `build_gaussian_tf()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T13:19:16.255914Z",
     "start_time": "2018-05-10T13:19:15.065988Z"
    },
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "def build_gaussian_tf(in_tensor, config, names = None):\n",
    "\n",
    "    num_detections  = config.DETECTION_MAX_INSTANCES\n",
    "    img_h, img_w    = config.IMAGE_SHAPE[:2]\n",
    "    batch_size      = config.BATCH_SIZE\n",
    "    num_classes     = config.NUM_CLASSES  \n",
    "    print('\\n ')\n",
    "    print('  > BUILD_GAUSSIAN_TF() for ', names )\n",
    "    \n",
    "    # rois per image is determined by size of input tensor \n",
    "    #   detection mode:   config.TRAIN_ROIS_PER_IMAGE \n",
    "    #   ground_truth  :   config.DETECTION_MAX_INSTANCES\n",
    "    \n",
    "    print('    orignal in_tensor shape : ', in_tensor.shape)   \n",
    "    # in_tensor = in_tensor[:,:,:,2:7]\n",
    "    print('    modified in_tensor shape : ', in_tensor.get_shape())\n",
    "    \n",
    "    rois_per_image  = tf.to_int32(in_tensor.shape[2])\n",
    "    # strt_cls        = 0 if rois_per_image == 32 else 1\n",
    "    print('    num of bboxes per class is : ', rois_per_image)\n",
    "\n",
    "    #-----------------------------------------------------------------------------\n",
    "    ## Build mesh-grid to hold pixel coordinates  \n",
    "    #-----------------------------------------------------------------------------\n",
    "    X = tf.range(img_w, dtype=tf.int32)\n",
    "    Y = tf.range(img_h, dtype=tf.int32)\n",
    "    X, Y = tf.meshgrid(X, Y)\n",
    "    # print('    X/Y shapes :',  X.get_shape(), Y.get_shape())\n",
    "    # print('    X : \\n',X.eval())\n",
    "    # print('    Y : \\n',Y.eval())\n",
    "\n",
    "    # repeat X and Y  batch_size x rois_per_image times\n",
    "    ones = tf.ones([batch_size, rois_per_image,1, 1], dtype = tf.int32)\n",
    "    rep_X = ones * X\n",
    "    rep_Y = ones * Y \n",
    "    # print('    Ones: ',ones.shape)                \n",
    "    # print(' ones_exp * X', ones.shape, '*', X.shape, '= ',rep_X.shape)\n",
    "    # print(' ones_exp * Y', ones.shape, '*', Y.shape, '= ',rep_Y.shape)\n",
    "\n",
    "    # # stack the X and Y grids \n",
    "    bef_pos = tf.to_float(tf.stack([rep_X,rep_Y], axis = -1))\n",
    "    # print(' before transpse ', bef_pos.get_shape())\n",
    "    pos_grid = tf.transpose(bef_pos,[2,3,0,1,4])\n",
    "    print('    after transpose ', pos_grid.get_shape())    \n",
    "\n",
    "    # pt2_reshape = tf.reshape( in_tensor , [batch_size, num_classes * rois_per_image ,8])\n",
    "    # print('    pt2_reshape shape is : ', pt2_reshape.get_shape())\n",
    "    # print(pt2_reshape[0].eval())\n",
    "    # print(pt2_reshape[1].eval())\n",
    "    # print(pt2_reshape[2].eval())\n",
    "\n",
    "    #-----------------------------------------------------------------------------    \n",
    "    ## Stack non_zero bboxes from in_tensor into pt2_dense \n",
    "    #-----------------------------------------------------------------------------\n",
    "    pt2_sum = tf.reduce_sum(tf.abs(in_tensor[:,:,:,:-2]), axis=-1)\n",
    "    print('    pt2_sum shape ',pt2_sum.shape)\n",
    "    # print(pt2_sum[0].eval())\n",
    "\n",
    "    pt2_mask = tf.greater(pt2_sum , 0)\n",
    "    # print(' pt2_mask shape ', pt2_mask.get_shape())\n",
    "    # print(pt2_mask.eval())\n",
    "\n",
    "    # pt2_ind shape is [?, 3]. \n",
    "    #   pt2_ind[0] corresponds to image_index \n",
    "    #   pt2_ind[1] corresponds to class_index \n",
    "    #   pt2_ind[2] corresponds to roi row_index \n",
    "    pt2_ind  = tf.where(pt2_mask)\n",
    "    # print('    pt2_ind shape ', pt2_ind.get_shape())\n",
    "    # print(pt2_ind.eval())\n",
    "    # pt2_ind_float  =  tf.to_float(pt2_ind[:,0:1])\n",
    "\n",
    "    # pt2_dense shape is [?, 6]\n",
    "    #    pt2_dense[0] is image index\n",
    "    #    pt2_dense[1:4]  roi cooridnaytes \n",
    "    #    pt2_dense[5]    is class id \n",
    "    pt2_dense = tf.gather_nd( in_tensor, pt2_ind)\n",
    "\n",
    "    # append image index to front of rows - REMOVED 1-5-2018\n",
    "    #  pt2_dense = tf.concat([tf.to_float(pt2_ind[:,0:1]), pt2_dense],axis=1)\n",
    "    print('    dense shape ',pt2_dense.get_shape())\n",
    "    # print(dense.eval())\n",
    "\n",
    "    ## split pt2_dense by pt2_ind[:,0], which identifies the image \n",
    "    stacked_list = tf.dynamic_partition(pt2_dense, tf.to_int32(pt2_ind[:,0]), num_partitions = batch_size )\n",
    "\n",
    "    \n",
    "    #-----------------------------------------------------------------------------\n",
    "    ##  Build Stacked output from dynamically partitioned lists \n",
    "    #-----------------------------------------------------------------------------\n",
    "    print('    Build Stacked output from dynamically partitioned lists --------------')  \n",
    "\n",
    "    stacked_output=[]\n",
    "    for img, item  in enumerate(stacked_list) : \n",
    "        rois_in_image  = tf.shape(item)[0]\n",
    "        pad_item =  tf.pad(item,[[0, rois_per_image - rois_in_image ],[0,0]])\n",
    "        stacked_output.append(pad_item)\n",
    "    stacked_tensor = tf.stack(stacked_output)\n",
    "\n",
    "    # print()    \n",
    "    # print('   -- Stacked output contents --------------')    \n",
    "    # print('    stacked_output shape : ', len(stacked_output))\n",
    "    # for img, item  in enumerate(stacked_output) :\n",
    "        # print('   img ', img, ' stacked_list[img] ', tf.shape(item).eval() ) \n",
    "    # print('   stacked_tensor shape : ', tf.shape(stacked_tensor).eval())\n",
    "    \n",
    "    #-----------------------------------------------------------------------------\n",
    "    ##  Build mean and convariance tensors for Multivariate Normal Distribution \n",
    "    #-----------------------------------------------------------------------------\n",
    "    width  = stacked_tensor[:,:,3] - stacked_tensor[:,:,1]      # x2 - x1\n",
    "    height = stacked_tensor[:,:,2] - stacked_tensor[:,:,0]\n",
    "    cx     = stacked_tensor[:,:,1] + ( width  / 2.0)\n",
    "    cy     = stacked_tensor[:,:,0] + ( height / 2.0)\n",
    "    means  = tf.stack((cx,cy),axis = -1)\n",
    "    covar  = tf.stack((width * 0.5 , height * 0.5), axis = -1)\n",
    "    covar  = tf.sqrt(covar)\n",
    "\n",
    "    tfd = tf.contrib.distributions\n",
    "    mvn = tfd.MultivariateNormalDiag( loc  = means,  scale_diag = covar)\n",
    "    prob_grid = mvn.prob(pos_grid)\n",
    "    prob_grid = tf.transpose(prob_grid,[2,3,0,1])\n",
    "\n",
    "    # print('    means shape :', means.get_shape(),' covar shape ', covar.get_shape())\n",
    "    # print('    from MVN    : mns shape      : ', means.shape, means.get_shape())\n",
    "    # print('    from MVN    : cov shape      : ', covar.shape, covar.get_shape())\n",
    "    # print('    from MVN    : mean shape     : ', mvn.mean().get_shape(), '\\t stddev shape', mvn.stddev().get_shape())\n",
    "    # print('    from MVN    : mvn.batch_shape: ', mvn.batch_shape , '\\t mvn.event_shape ',  mvn.event_shape)\n",
    "    # print('    from Linear : op shape       : ', mvn.scale.shape, ' Linear Op batch shape ',mvn.scale.batch_shape)\n",
    "    # print('    from Linear : op Range Dim   : ', mvn.scale.range_dimension)\n",
    "    # print('    from Linear : op Domain Dim  : ', mvn.scale.domain_dimension) \n",
    "    print('    >> input to MVN.PROB: pos_grid (meshgrid) shape: ', pos_grid.get_shape())\n",
    "    print('    << output probabilities shape:' , prob_grid.get_shape())\n",
    "    # print(prob_grid.eval())\n",
    "    \n",
    "    #--------------------------------------------------------------------------------\n",
    "    # kill distributions of NaN boxes (resulting from bboxes with height/width of zero\n",
    "    # which cause singular sigma cov matrices\n",
    "    #--------------------------------------------------------------------------------\n",
    "    gauss_grid = tf.where(tf.is_nan(prob_grid),  tf.zeros_like(prob_grid), prob_grid)\n",
    "\n",
    "    \n",
    "    #--------------------------------------------------------------------------------\n",
    "    ## scatter out the probability distributions based on class\n",
    "    #--------------------------------------------------------------------------------\n",
    "    print('\\n    Scatter out the probability distributions based on class --------------')     \n",
    "    class_inds      = tf.to_int32(stacked_tensor[:,:,-2])   # - should be -2 since class moved to that postion\n",
    "    batch_grid, roi_grid = tf.meshgrid( tf.range(batch_size, dtype=tf.int32), tf.range(rois_per_image, dtype=tf.int32),\n",
    "                                        indexing = 'ij' )\n",
    "    scatter_classes = tf.stack([batch_grid, class_inds, roi_grid ],axis = -1)\n",
    "    gauss_scatt     = tf.scatter_nd(scatter_classes, gauss_grid, [batch_size, num_classes, rois_per_image, img_w, img_h])\n",
    "\n",
    "    print('    gaussian_grid      : ', gauss_grid.shape)    \n",
    "    print('    class shape        : ', class_inds.shape)\n",
    "    print('    roi_grid shape     : ', roi_grid.get_shape() )\n",
    "    print('    batch_grid shape   : ', batch_grid.get_shape())\n",
    "    print('    scatter_classes    : ', scatter_classes.get_shape())\n",
    "    print('    gaussian scattered : ', gauss_scatt.shape)   \n",
    "    \n",
    "    ## sum based on class -----------------------------------------------------------------\n",
    "    print('\\n    Reduce sum based on class ---------------------------------------------')         \n",
    "    gauss_sum = tf.reduce_sum(gauss_scatt, axis=2, name='pred_gaussian')\n",
    "    gauss_sum = tf.where(gauss_sum > 1e-6, gauss_sum,tf.zeros_like(gauss_sum))\n",
    "    gauss_sum = tf.transpose(gauss_sum,[0,2,3,1], name = names[0])\n",
    "    print('    gaussian sum type/name : ', type(gauss_sum), gauss_sum.name, names[0])\n",
    "    print('    gaussian_sum shape     : ', gauss_sum.get_shape(), 'Keras tensor ', KB.is_keras_tensor(gauss_sum) )    \n",
    "\n",
    "    # L2 normalization  -----------------------------------------------------------------\n",
    "    # print('\\n    L2 normalization ------------------------------------------------------')         \n",
    "    \n",
    "    # gauss_flatten = KB.reshape(gauss_sum, [tf.shape(gauss_sum)[0], -1, tf.shape(gauss_sum)[-1]] )\n",
    "    # gauss_norm    = KB.l2_normalize(gauss_flatten, axis = 1)\n",
    "    # gauss_norm    = KB.reshape(gauss_norm, KB.shape(gauss_sum))\n",
    "    # print('    Shape of guassian_flattened  : ', KB.int_shape(gauss_flatten), 'Keras tensor ', KB.is_keras_tensor(gauss_flatten) )\n",
    "    # print('    Shape of L2 normalized tensor: ', KB.int_shape(gauss_norm), 'Keras tensor ', KB.is_keras_tensor(gauss_norm) )\n",
    "    print('    complete')\n",
    "\n",
    "    return  gauss_sum    # [gauss_sum, gauss_scatt, means, covar]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T17:19:42.006304Z",
     "start_time": "2018-05-04T17:19:41.197152Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gauss_sum2 =  build_gaussian_tf(pred_tensor, model.config, names = 'Kevin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T14:45:20.671389Z",
     "start_time": "2018-05-10T14:45:20.406851Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_mask2(input):\n",
    "    ''' input is a row of the pred_tensor array (x1,y1, x2,y2)\n",
    "    '''\n",
    "    # row = input.eval()\n",
    "    print(row)\n",
    "    y_extent = tf.range(row[0], row[2])\n",
    "    x_extent = tf.range(row[1], row[3])\n",
    "    print('y_extent', y_extent.eval())\n",
    "    Y,X   = tf.meshgrid(y_extent, x_extent)\n",
    "    print(Y.shape, X.shape)\n",
    "    bbox_mask    = tf.stack([Y,X],axis=2)\n",
    "    print(' bbox_mask shapoe: ',bbox_mask.shape)\n",
    "\n",
    "    mask_indices = tf.reshape(bbox_mask,[-1,2])\n",
    "    print('  size of mask_indices: ', mask_indices.shape)\n",
    "\n",
    "    mask_size = mask_indices.get_shape()[0]\n",
    "    mask_updates = tf.ones([mask_size], dtype = tf.int32)\n",
    "    print('  size of bbox_mask: ', mask_size)\n",
    "    res = tf.scatter_nd_add(ref2, mask_indices, mask_updates)\n",
    "    print( ' ref shape: ', res.shape)\n",
    "    print( ' indices shape: ', mask_indices.shape)\n",
    "    print( ' updates shape: ', mask_updates.shape)\n",
    "    return res\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `development_build_gaussian_tf()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T15:09:56.964712Z",
     "start_time": "2018-05-10T15:09:55.686808Z"
    },
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "##def development_build_gaussian_tf(in_tensor, config, names = None):\n",
    "# in_tensor = KB.constant(pred_tensor)\n",
    "# graph1 = tf.Graph()\n",
    "# with graph1.as_default():\n",
    "in_tensor = tf.placeholder(tf.float32, shape=[3,4,32,6], name = 'in_tensor')\n",
    "config = model.config\n",
    "names = ['Dev']\n",
    "\n",
    "\n",
    "\n",
    "num_detections  = config.DETECTION_MAX_INSTANCES\n",
    "img_h, img_w    = config.IMAGE_SHAPE[:2]\n",
    "batch_size      = config.BATCH_SIZE\n",
    "num_classes     = config.NUM_CLASSES  \n",
    "print('\\n ')\n",
    "print('  > BUILD_GAUSSIAN_TF() for ', names )\n",
    "\n",
    "# rois per image is determined by size of input tensor \n",
    "#   detection mode:   config.TRAIN_ROIS_PER_IMAGE \n",
    "#   ground_truth  :   config.DETECTION_MAX_INSTANCES\n",
    "\n",
    "print('    orignal in_tensor shape : ', in_tensor.shape)   \n",
    "# in_tensor = in_tensor[:,:,:,2:7]\n",
    "print('    modified in_tensor shape : ', in_tensor.get_shape())\n",
    "\n",
    "rois_per_image  = tf.to_int32(in_tensor.shape[2])\n",
    "# strt_cls        = 0 if rois_per_image == 32 else 1\n",
    "print('    num of bboxes per class is : ', rois_per_image)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "## Build mesh-grid to hold pixel coordinates  \n",
    "#-----------------------------------------------------------------------------\n",
    "X = tf.range(img_w, dtype=tf.int32)\n",
    "Y = tf.range(img_h, dtype=tf.int32)\n",
    "X, Y = tf.meshgrid(X, Y)\n",
    "# print('    X/Y shapes :',  X.get_shape(), Y.get_shape())\n",
    "# print('    X : \\n',X.eval())\n",
    "# print('    Y : \\n',Y.eval())\n",
    "\n",
    "# repeat X and Y  batch_size x rois_per_image times\n",
    "ones = tf.ones([batch_size, rois_per_image,1, 1], dtype = tf.int32)\n",
    "rep_X = ones * X\n",
    "rep_Y = ones * Y \n",
    "# print('    Ones: ',ones.shape)                \n",
    "# print(' ones_exp * X', ones.shape, '*', X.shape, '= ',rep_X.shape)\n",
    "# print(' ones_exp * Y', ones.shape, '*', Y.shape, '= ',rep_Y.shape)\n",
    "\n",
    "# # stack the X and Y grids \n",
    "bef_pos = tf.to_float(tf.stack([rep_X,rep_Y], axis = -1))\n",
    "# print(' before transpse ', bef_pos.get_shape())\n",
    "pos_grid = tf.transpose(bef_pos,[2,3,0,1,4])\n",
    "print('    after transpose ', pos_grid.get_shape())    \n",
    "\n",
    "# pt2_reshape = tf.reshape( in_tensor , [batch_size, num_classes * rois_per_image ,8])\n",
    "# print('    pt2_reshape shape is : ', pt2_reshape.get_shape())\n",
    "# print(pt2_reshape[0].eval())\n",
    "# print(pt2_reshape[1].eval())\n",
    "# print(pt2_reshape[2].eval())\n",
    "\n",
    "#-----------------------------------------------------------------------------    \n",
    "## Stack non_zero bboxes from in_tensor into pt2_dense \n",
    "##  identify rows that have a non_zero bbox (pt2_sum > 0)\n",
    "##  get the indices  pt2_ind \n",
    "#-----------------------------------------------------------------------------\n",
    "pt2_sum = tf.reduce_sum(tf.abs(in_tensor[:,:,:,:-2]), axis=-1)\n",
    "print('    pt2_sum shape ',pt2_sum.shape)\n",
    "# print(pt2_sum[0].eval())\n",
    "\n",
    "pt2_mask = tf.greater(pt2_sum , 0)\n",
    "# print(' pt2_mask shape ', pt2_mask.get_shape())\n",
    "# print(pt2_mask.eval())\n",
    "\n",
    "# pt2_ind shape is [?, 3]. \n",
    "#   pt2_ind[0] corresponds to image_index \n",
    "#   pt2_ind[1] corresponds to class_index \n",
    "#   pt2_ind[2] corresponds to roi row_index \n",
    "pt2_ind  = tf.where(pt2_mask)\n",
    "print('    pt2_ind shape ', pt2_ind.get_shape())\n",
    "#     print(pt2_ind.eval())\n",
    "# pt2_ind_float  =  tf.to_float(pt2_ind[:,0:1])\n",
    "\n",
    "# pt2_dense shape is [?, 6]\n",
    "#    pt2_dense[0] is image index\n",
    "#    pt2_dense[1:4]  roi cooridnaytes \n",
    "#    pt2_dense[5]    is class id \n",
    "pt2_dense = tf.gather_nd( in_tensor, pt2_ind)\n",
    "\n",
    "# append image index to front of rows - REMOVED 1-5-2018\n",
    "#  pt2_dense = tf.concat([tf.to_float(pt2_ind[:,0:1]), pt2_dense],axis=1)\n",
    "print('    dense shape ',pt2_dense.get_shape())\n",
    "# print(pt2_dense.eval())\n",
    "\n",
    "## split pt2_dense by pt2_ind[:,0], which identifies the image \n",
    "stacked_list = tf.dynamic_partition(pt2_dense, tf.to_int32(pt2_ind[:,0]), num_partitions = batch_size )\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "##  Build Stacked output from dynamically partitioned lists \n",
    "#-----------------------------------------------------------------------------\n",
    "print('    Build Stacked output from dynamically partitioned lists --------------')  \n",
    "\n",
    "stacked_output=[]\n",
    "for img, item  in enumerate(stacked_list) : \n",
    "    rois_in_image  = tf.shape(item)[0]\n",
    "    pad_item =  tf.pad(item,[[0, rois_per_image - rois_in_image ],[0,0]])\n",
    "    stacked_output.append(pad_item)\n",
    "stacked_tensor = tf.stack(stacked_output)\n",
    "\n",
    "# print()    \n",
    "# print('   -- Stacked output contents --------------')    \n",
    "# print('    stacked_output shape : ', len(stacked_output))\n",
    "# for img, item  in enumerate(stacked_output) :\n",
    "    # print('   img ', img, ' stacked_list[img] ', tf.shape(item).eval() ) \n",
    "# print('   stacked_tensor shape : ', tf.shape(stacked_tensor).eval())\n",
    "rnd_tensor = tf.floor(stacked_tensor[:,:,:5])    \n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "##  Build mean and convariance tensors for Multivariate Normal Distribution \n",
    "#-----------------------------------------------------------------------------\n",
    "width  = stacked_tensor[:,:,3] - stacked_tensor[:,:,1]      # x2 - x1\n",
    "height = stacked_tensor[:,:,2] - stacked_tensor[:,:,0]\n",
    "cx     = stacked_tensor[:,:,1] + ( width  / 2.0)\n",
    "cy     = stacked_tensor[:,:,0] + ( height / 2.0)\n",
    "means  = tf.stack((cx,cy),axis = -1)\n",
    "covar  = tf.stack((width * 0.5 , height * 0.5), axis = -1)\n",
    "covar  = tf.sqrt(covar)\n",
    "\n",
    "tfd = tf.contrib.distributions\n",
    "mvn = tfd.MultivariateNormalDiag( loc  = means,  scale_diag = covar)\n",
    "prob_grid = mvn.prob(pos_grid)\n",
    "prob_grid = tf.transpose(prob_grid,[2,3,0,1])\n",
    "\n",
    "# print('    means shape :', means.get_shape(),' covar shape ', covar.get_shape())\n",
    "# print('    from MVN    : mns shape      : ', means.shape, means.get_shape())\n",
    "# print('    from MVN    : cov shape      : ', covar.shape, covar.get_shape())\n",
    "# print('    from MVN    : mean shape     : ', mvn.mean().get_shape(), '\\t stddev shape', mvn.stddev().get_shape())\n",
    "# print('    from MVN    : mvn.batch_shape: ', mvn.batch_shape , '\\t mvn.event_shape ',  mvn.event_shape)\n",
    "# print('    from Linear : op shape       : ', mvn.scale.shape, ' Linear Op batch shape ',mvn.scale.batch_shape)\n",
    "# print('    from Linear : op Range Dim   : ', mvn.scale.range_dimension)\n",
    "# print('    from Linear : op Domain Dim  : ', mvn.scale.domain_dimension) \n",
    "print('    >> input to MVN.PROB: pos_grid (meshgrid) shape: ', pos_grid.get_shape())\n",
    "print('    << output probabilities shape:' , prob_grid.get_shape())\n",
    "# print(prob_grid.eval())\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# kill distributions of NaN boxes (resulting from bboxes with height/width of zero\n",
    "# which cause singular sigma cov matrices\n",
    "#--------------------------------------------------------------------------------\n",
    "gauss_grid = tf.where(tf.is_nan(prob_grid),  tf.zeros_like(prob_grid), prob_grid)\n",
    "\n",
    "\n",
    "## scatter out the probability distributions based on class ----------------------------\n",
    "print('\\n    Scatter out the probability distributions based on class --------------')     \n",
    "class_inds      = tf.to_int32(stacked_tensor[:,:,-2])   # - should be -2 since class moved to that postion\n",
    "batch_grid, roi_grid = tf.meshgrid( tf.range(batch_size, dtype=tf.int32), tf.range(rois_per_image, dtype=tf.int32),\n",
    "                                    indexing = 'ij' )\n",
    "scatter_classes = tf.stack([batch_grid, class_inds, roi_grid ],axis = -1)\n",
    "gauss_scatt     = tf.scatter_nd(scatter_classes, gauss_grid, [batch_size, num_classes, rois_per_image, img_w, img_h])\n",
    "\n",
    "print('    gaussian_grid      : ', gauss_grid.shape)    \n",
    "print('    class shape        : ', class_inds.shape)\n",
    "print('    roi_grid shape     : ', roi_grid.get_shape() )\n",
    "print('    batch_grid shape   : ', batch_grid.get_shape())\n",
    "print('    scatter_classes    : ', scatter_classes.get_shape())\n",
    "print('    gaussian scattered : ', gauss_scatt.shape)   \n",
    "\n",
    "## sum based on class -----------------------------------------------------------------\n",
    "print('\\n    Reduce sum based on class ---------------------------------------------')         \n",
    "gauss_sum = tf.reduce_sum(gauss_scatt, axis=2, name='pred_gaussian')\n",
    "gauss_sum = tf.where(gauss_sum > 1e-6, gauss_sum,tf.zeros_like(gauss_sum))\n",
    "gauss_sum = tf.transpose(gauss_sum,[0,2,3,1], name = names[0])\n",
    "print('    gaussian sum type/name : ', type(gauss_sum), gauss_sum.name, names[0])\n",
    "print('    gaussian_sum shape     : ', gauss_sum.get_shape(), 'Keras tensor ', KB.is_keras_tensor(gauss_sum) )    \n",
    "\n",
    "\n",
    "print('\\n    L2 normalization ------------------------------------------------------')   \n",
    "heatmap_shape=KB.shape(gauss_sum)\n",
    "print(' pred_shape: KB.shape:' , heatmap_shape, ' tf.get_shape(): ', heatmap_shape.get_shape(), ' pred_maks.shape:', \n",
    "                                 gauss_sum.shape, 'tf.shape :', tf.shape(gauss_sum))\n",
    "\n",
    "output_flatten = KB.reshape(gauss_sum, (heatmap_shape[0], -1, heatmap_shape[-1]) )\n",
    "output_norm1   = KB.l2_normalize(output_flatten, axis = 1)    \n",
    "output_norm    = KB.identity(KB.reshape(output_norm1,  heatmap_shape ) , name = names[0]+'_norm')   \n",
    "\n",
    "print('   output_flatten    : ', KB.int_shape(output_flatten) , output_flatten.get_shape(),' Keras tensor ', KB.is_keras_tensor(output_flatten) )\n",
    "print('   output_norm1      : ', KB.int_shape(output_norm1)   ,   output_norm1.get_shape(),' Keras tensor ', KB.is_keras_tensor(output_norm1) )\n",
    "print('   output_norm final : ', KB.int_shape(output_norm)    ,    output_norm.get_shape(),' Keras tensor ', KB.is_keras_tensor(output_norm) )\n",
    "\n",
    "\n",
    "## return  gauss_sum    # [gauss_sum, gauss_scatt, means, covar]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Tensorflow execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T15:10:04.730267Z",
     "start_time": "2018-05-10T15:10:00.524802Z"
    }
   },
   "outputs": [],
   "source": [
    "feed_dict = {in_tensor: pred_tensor}\n",
    "fetches = [stacked_tensor, rnd_tensor, gauss_sum]\n",
    "sess = tf.Session()\n",
    "print(' tfsession() is ', sess)\n",
    "tt = sess.run(fetches, feed_dict = feed_dict )\n",
    "print(type(tt), len(tt))\n",
    "sess.close()\n",
    "\n",
    "img = 1\n",
    "print(' Stacked Tensor Shape: ', tt[0].shape)\n",
    "print(' Stacked Tensor :   \\n ', tt[0][img])\n",
    "\n",
    "print(' rnd_tensor shape ', tt[1].shape)\n",
    "print(' rnd_tensor :  \\n ', tt[1][img])\n",
    "\n",
    "print(' Gauss_Sum shape :\\n', tt[2].shape)\n",
    "# print(' FP gt boxes        :\\n', tt[3])\n",
    "# print(' FP gt class assign :\\n', tt[4])\n",
    "# print(' gt class ids assign :\\n', tt[5])\n",
    "# print()\n",
    "# print('fp_rois ', tt[6].shape, '\\n',tt[6])\n",
    "# print('rois ', tt[9].shape, '\\n',tt[9])\n",
    "# print()\n",
    "# print('fp_rois_gt_boxes ', tt[7].shape, '\\n',tt[7])\n",
    "# print('rois_gt_boxes ', tt[10].shape, '\\n',tt[10])\n",
    "# print()\n",
    "# print('fp_rois_gt_class_ids ', tt[8].shape, '\\n',tt[8])\n",
    "# print('rois_gt_class_ids ', tt[11].shape, '\\n',tt[11])\n",
    "# # return positive_ind_shuffled, positive_indices, positive_overlaps, roi_gt_box_assignment,roi_gt_boxes, roi_gt_class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T13:43:36.617141Z",
     "start_time": "2018-05-10T13:43:35.151625Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    gauss_sum = development_build_gaussian_tf(KB.constant(pred_tensor), model.config, names = ['Dev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    rnd_tensor = tf.floor(stacked_tensor)    \n",
    "    sum_tensor = tf.reduce_sum(tf.abs(rnd_tensor[:,:,:4]), axis=-1)\n",
    "    non_zero   = tf.cast(sum_tensor, tf.bool)\n",
    "    non_zero_exp = tf.expand_dims(non_zero, axis =-1)\n",
    "    \n",
    "    print(' rnd_tensor :', tf.shape(rnd_tensor).eval())\n",
    "    print(' sum_tensor :', tf.shape(sum_tensor).eval())\n",
    "    print(' non_zero   :', tf.shape(non_zero).eval())\n",
    "    print(' non_zero_exp:', tf.shape(non_zero_exp).eval())\n",
    "    non_zero_exp = KB.repeat_elements(non_zero_exp, 6, axis=-1)\n",
    "    print(' non_zero_exp:', tf.shape(non_zero_exp).eval())\n",
    "    nz_tensor  = tf.boolean_mask(rnd_tensor, non_zero_exp, axis = -1)\n",
    "    print(' nz_tensor  :', tf.shape(nz_tensor).eval())\n",
    "\n",
    "#     print(stacked_tensor[0].eval())\n",
    "    print(rnd_tensor[0].eval())\n",
    "    print()\n",
    "#     print(stacked_tensor[1].eval())\n",
    "    print(rnd_tensor[1].eval())\n",
    "    print()\n",
    "#     print(stacked_tensor[2].eval())\n",
    "    print(rnd_tensor[2].eval())\n",
    "    \n",
    "    print(sum_tensor[1].eval())    \n",
    "    print(non_zero[1].eval())    \n",
    "#     non_zeros = tf.cast(tf.reduce_sum(tf.abs(rnd_tensor), axis=1), tf.bool)\n",
    "    print(non_zero_exp[1].eval())    \n",
    "\n",
    "    print(nz_tensor[1].eval())\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "###  Test `means`, `covar`, `gauss_grid`, and `gauss_sum ` between development version and final version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:10:10.133108Z",
     "start_time": "2018-05-02T11:10:09.386212Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "print(means.get_shape(), means.get_shape())\n",
    "tst1 = means.eval()\n",
    "tst2 = means2.eval()\n",
    "print(tst1.shape, tst2.shape)\n",
    "\n",
    "print(tst1[0,:10])\n",
    "print()\n",
    "print(tst2[0,:10])\n",
    "print(np.all(tst1 == tst2))\n",
    "print()\n",
    "del tst1, tst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:10:14.482950Z",
     "start_time": "2018-05-02T11:10:14.205020Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tst1 = st.eval()\n",
    "tst2 = st2.eval()\n",
    "print(tst1.shape, tst2.shape)\n",
    "\n",
    "print(tst1[0,:10])\n",
    "print()\n",
    "print(tst2[0,:10])\n",
    "print(np.all(tst1 == tst2))\n",
    "print()\n",
    "del tst1, tst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:10:18.158709Z",
     "start_time": "2018-05-02T11:10:17.474806Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tst1 = gauss_grid.eval()\n",
    "tst2 = gauss_grid2.eval()\n",
    "print(tst1.shape, tst2.shape)\n",
    "\n",
    "print(tst1[0,0,:10])\n",
    "print()\n",
    "print(tst2[0,0,:10])\n",
    "print(np.all(tst1 == tst2))\n",
    "# print()\n",
    "del tst1, tst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:10:23.859635Z",
     "start_time": "2018-05-02T11:10:23.164182Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tst1 = gauss_sum.eval()\n",
    "tst2 = gauss_sum2.eval()\n",
    "print(tst1.shape, tst2.shape)\n",
    "\n",
    "# print(tst1[0,0,:10])\n",
    "# print()\n",
    "# print(tst2[0,0,:10])\n",
    "print(np.all(tst1 == tst2))\n",
    "# print()\n",
    "del tst1, tst2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "###  Compute mean and max of `gauss_grid()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T10:04:30.778443Z",
     "start_time": "2018-05-02T10:04:08.500Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(gauss_grid.shape)\n",
    "for img in [0,1,2]:\n",
    "    for bbx in range(32):\n",
    "        gauss_mean = KB.mean(gauss_grid[img, bbx,:,:]).eval()\n",
    "        gauss_min  = KB.min(gauss_grid[img, bbx,:,:]).eval()\n",
    "        gauss_max  = KB.max(gauss_grid[img, bbx,:,:]).eval()\n",
    "#         prob    = stacked_tensor[img,bbx,-1].eval() 'prob: ',prob ,\n",
    "        print('Img/bbx: {}/{}     Mean:  {:6e}  \\t Max: {:6e}  \\t Min : {:6e}'.format(img, bbx, gauss_mean, gauss_max, gauss_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "###  Compute mean and max of `gauss_grid2()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T10:04:30.776944Z",
     "start_time": "2018-05-02T10:03:27.542792Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(gauss_grid2.shape)\n",
    "for img in [0,1,2]:\n",
    "    for bbx in range(32):\n",
    "        gauss_mean = KB.mean(gauss_grid2[img, bbx,:,:]).eval()\n",
    "        gauss_min  = KB.min(gauss_grid2[img, bbx,:,:]).eval()\n",
    "        gauss_max  = KB.max(gauss_grid2[img, bbx,:,:]).eval()\n",
    "#         prob    = stacked_tensor[img,bbx,-1].eval() 'prob: ',prob ,\n",
    "        print('Img/bbx: {}/{}     Mean:  {:6e}  \\t Max: {:6e}  \\t Min : {:6e}'.format(img, bbx, gauss_mean, gauss_max, gauss_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "###  Compute `gauss_grid()` and   `gauss_grid2()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:10:39.307514Z",
     "start_time": "2018-05-02T11:10:38.603585Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(gauss_grid2.shape)\n",
    "gauss_max  = KB.max(gauss_grid, axis = [2,3]).eval()\n",
    "gauss_max2  = KB.max(gauss_grid2, axis = [2,3]).eval()\n",
    "\n",
    "for img in [0,1,2]:\n",
    "    for bbx in range(32):\n",
    "\n",
    "#         prob    = stacked_tensor[img,bbx,-1].eval() 'prob: ',prob ,\n",
    "        print('Img/bbx: {}/{}     MAX:  {:6e}  \\t MAX2: {:6e}  \\t Equal : {}'.format(img, bbx, gauss_max[img, bbx],gauss_max2[img,bbx],(gauss_max[img,bbx]== gauss_max2[img,bbx])))\n",
    "del gauss_max, gauss_max2    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Compute `gauss_sum()` and  `gauss_sum2()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:10:52.883112Z",
     "start_time": "2018-05-02T11:10:52.154331Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "print(gauss_sum.shape, gauss_sum2.shape)\n",
    "# print(gauss_grid2.shape)\n",
    "tst1 = tf.transpose(gauss_sum, [0,3,1,2])\n",
    "tst2 = tf.transpose(gauss_sum2, [0,3,1,2])\n",
    "print(tst1.shape, tst2.shape)\n",
    "\n",
    "gauss_max1 = KB.max(tst1, axis = [2,3]).eval()\n",
    "gauss_max2 = KB.max(tst2, axis = [2,3]).eval()\n",
    "print(gauss_max1.shape, gauss_max2.shape)\n",
    "\n",
    "# gauss_max2  = KB.max(gauss_grid2, axis = [2,3]).eval()\n",
    "\n",
    "for img in [0,1,2]:\n",
    "    for bbx in range(4):\n",
    "        print('Img/bbx: {}/{}     MAX:  {:6e}  \\t MAX2: {:6e}  \\t Equal : {}'.format(img, bbx, gauss_max1[img, bbx],gauss_max2[img,bbx],(gauss_max1[img,bbx]== gauss_max2[img,bbx])))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T10:58:45.332214Z",
     "start_time": "2018-05-02T10:58:44.117193Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "for img in [0,1,2]:\n",
    "    for bbx in range(4):\n",
    "        print('Img/bbx: {}/{}    Equal : {}'.format(img, bbx, (tst1[img,bbx]==  tst2[img,bbx])))\n",
    "del gauss_max1, gauss_max2    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "\n",
    "###  Compute mean and max OF `gauss_sum2()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T09:55:59.702691Z",
     "start_time": "2018-05-02T09:55:42.231847Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(gauss_sum2.shape)\n",
    "for img in [0,1,2]:\n",
    "    for cls in range(4):\n",
    "        gauss_mean = KB.mean(gauss_sum2[img,:,:,cls]).eval()\n",
    "        gauss_min  = KB.min(gauss_sum2[img, :,:,cls]).eval()\n",
    "        gauss_max  = KB.max(gauss_sum2[img, :,:,cls]).eval()\n",
    "        print('Img/bbx: ', img, '/',cls ,'   Mean: ', gauss_mean, '\\t Max: ' , gauss_max, '\\t Min :', gauss_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Compute min and max of `gauss_sum()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T09:57:11.807587Z",
     "start_time": "2018-05-02T09:56:55.286325Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "print(gauss_sum.shape)\n",
    "for img in [0,1,2]:\n",
    "    for cls in range(4):\n",
    "        gauss_mean = KB.mean(gauss_sum[img,:,:,cls]).eval()\n",
    "        gauss_min  =  KB.min(gauss_sum[img, :,:,cls]).eval()\n",
    "        gauss_max  =  KB.max(gauss_sum[img, :,:,cls]).eval()\n",
    "        print('Img/bbx: ', img, '/',cls ,'   Mean: ', gauss_mean, '\\t Max: ' , gauss_max, '\\t Min :', gauss_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T08:44:41.071788Z",
     "start_time": "2018-05-02T08:44:33.434419Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "pred_gauss = tf.constant(layers_out[19])\n",
    "print(pred_gauss.shape)\n",
    "for img in [0,1,2]:\n",
    "    for cls in range(4):\n",
    "        gauss_mean = KB.mean(pred_gauss[img,:,:,cls]).eval()\n",
    "        gauss_min  = KB.min(pred_gauss[img, :,:,cls]).eval()\n",
    "        gauss_max  = KB.max(pred_gauss[img, :,:,cls]).eval()\n",
    "        print('Img/bbx: ', img, '/',cls ,'   Mean: ', gauss_mean, '\\t Max: ' , gauss_max, '\\t Min :', gauss_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Plot Predicted  Heatmaps `pred_gaussian` \n",
    "\n",
    "`pred_gaussian2` and `gt_gaussian2` from Tensorflow PCN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:14:01.486755Z",
     "start_time": "2018-05-02T11:13:59.680438Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# gt_heatmap  = layers_out[27]     # gt_gaussiam \n",
    "# pred_heatmap= layers_out[24]  # pred_gaussian\n",
    "# gt_heatmap  = gauss_sum.eval()    # gt_gaussiam \n",
    "gt_heatmap  = layers_out[18]     # gt_gaussiam \n",
    "\n",
    "pred_heatmap= gauss_sum2.eval()  # pred_gaussian\n",
    "print('gt_gaussian heatmap shape : ', gt_heatmap.shape, ' pred_gaussian heatmap shape: ', pred_heatmap.shape)\n",
    "num_images = 1 # config.IMAGES_PER_GPU\n",
    "num_classes = config.NUM_CLASSES\n",
    "\n",
    "img = 0\n",
    "\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "print('Classes (1: circle, 2: square, 3: triangle ): ')\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "\n",
    "for cls in range(1,num_classes):\n",
    "    ttl = 'GROUND TRUTH HEATMAP - image :  {} class: {} '.format(img,cls)\n",
    "    print(' *** Zout  ', gt_heatmap[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian( gt_heatmap[img,:,:,cls], title = ttl)\n",
    "    \n",
    "    ttl = 'PREDICTED heatmap  - image :  {} class: {} '.format(img,cls)     \n",
    "    print(' *** pred_heatmap ', pred_heatmap[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian(pred_heatmap[img,:,:,cls], title = ttl)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Plot Predicted  Heatmaps `pred_gaussian` \n",
    "\n",
    "`pred_gaussian2` and `gt_gaussian2` from Tensorflow PCN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# gt_heatmap  = layers_out[27]     # gt_gaussiam \n",
    "# pred_heatmap= layers_out[24]  # pred_gaussian\n",
    "gt_heatmap  = layers_out[19]     # gt_gaussiam \n",
    "pred_heatmap= layers_out[18]  # pred_gaussian\n",
    "print('gt_gaussian heatmap shape : ', gt_heatmap.shape, ' pred_gaussian heatmap shape: ', pred_heatmap.shape)\n",
    "num_images = 1 # config.IMAGES_PER_GPU\n",
    "num_classes = config.NUM_CLASSES\n",
    "\n",
    "img = 0\n",
    "\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "print('Classes (1: circle, 2: square, 3: triangle ): ')\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "\n",
    "for cls in range(1,num_classes):\n",
    "    ttl = 'GROUND TRUTH HEATMAP - image :  {} class: {} '.format(img,cls)\n",
    "    print(' *** Zout  ', gt_heatmap[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian( gt_heatmap[img,:,:,cls], title = ttl)\n",
    "    \n",
    "    ttl = 'PREDICTED heatmap  - image :  {} class: {} '.format(img,cls)     \n",
    "    print(' *** pred_heatmap ', pred_heatmap[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian(pred_heatmap[img,:,:,cls], title = ttl)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "\n",
    "### Plot Predicted and Ground Truth Probability Heatmaps `pred_gaussian` and `gt_gaussian` (Tensorflow)\n",
    "\n",
    "`pred_gaussian2` and `gt_gaussian2` from Tensorflow PCN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# gt_heatmap  = layers_out[27]     # gt_gaussiam \n",
    "# pred_heatmap= layers_out[24]  # pred_gaussian\n",
    "gt_heatmap  = layers_out[19]     # gt_gaussiam \n",
    "pred_heatmap= layers_out[18]  # pred_gaussian\n",
    "print('gt_gaussian heatmap shape : ', gt_heatmap.shape, ' pred_gaussian heatmap shape: ', pred_heatmap.shape)\n",
    "num_images = 1 # config.IMAGES_PER_GPU\n",
    "num_classes = config.NUM_CLASSES\n",
    "\n",
    "img = 0\n",
    "\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "print('Classes (1: circle, 2: square, 3: triangle ): ')\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "\n",
    "for cls in range(1,num_classes):\n",
    "    ttl = 'GROUND TRUTH HEATMAP - image :  {} class: {} '.format(img,cls)\n",
    "    print(' *** Zout  ', gt_heatmap[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian( gt_heatmap[img,:,:,cls], title = ttl)\n",
    "    \n",
    "    ttl = 'PREDICTED heatmap  - image :  {} class: {} '.format(img,cls)     \n",
    "    print(' *** pred_heatmap ', pred_heatmap[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian(pred_heatmap[img,:,:,cls], title = ttl)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "###  Softmax Sparse Cross Entropy Ignoring Last Label -- Used in Keras FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T07:53:31.114036Z",
     "start_time": "2018-04-27T07:53:30.853311Z"
    },
    "hideCode": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K \n",
    "\n",
    "y_pred = tf.placeholder(dtype=tf.float32, shape=(16,320,320,20))\n",
    "y_true = tf.placeholder(dtype=tf.float32, shape=(16,320,320,1))\n",
    "print(K.int_shape(y_pred), K.int_shape(y_true))\n",
    "y_pred = K.reshape(y_pred, (-1, K.int_shape(y_pred)[-1]))\n",
    "print(K.int_shape(y_pred))\n",
    "log_softmax = tf.nn.log_softmax(y_pred)\n",
    "print(K.int_shape(log_softmax))\n",
    "\n",
    "y_true = K.flatten(y_true)\n",
    "print(K.int_shape(y_true))\n",
    "\n",
    "y_true = K.one_hot(tf.to_int32(y_true), K.int_shape(y_pred)[-1]+1)\n",
    "print(K.int_shape(y_true))\n",
    "\n",
    "unpacked = tf.unstack(y_true, axis=-1)\n",
    "print(len(unpacked), unpacked[0].shape)\n",
    "\n",
    "y_true = tf.stack(unpacked[:-1], axis=-1)\n",
    "print(K.int_shape(y_true))\n",
    "\n",
    "\n",
    "cross_entropy = -K.sum(y_true * log_softmax, axis=1)\n",
    "print(K.int_shape(cross_entropy))\n",
    "\n",
    "cross_entropy_mean = K.mean(cross_entropy)\n",
    "print(K.int_shape(cross_entropy_mean))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import keras.backend as K\n",
    "# print(K.int_shape(bef_pos)[-1])\n",
    "# unpacked  = K.flatten(test)\n",
    "# unpacked.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T23:19:54.102900Z",
     "start_time": "2018-04-16T23:19:53.889289Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Experimental code to Create mask for class bounding boxes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "###  `build_mask` routine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T15:10:59.695664Z",
     "start_time": "2018-05-10T15:10:59.445880Z"
    }
   },
   "outputs": [],
   "source": [
    "    print(tt[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T13:10:32.048123Z",
     "start_time": "2018-05-10T13:10:32.012979Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "def dev_build_mask2(input):\n",
    "    # row = input.eval()\n",
    "    print(row)\n",
    "    y_extent = tf.range(row[0], row[2])\n",
    "    x_extent = tf.range(row[1], row[3])\n",
    "    print('y_extent', y_extent.eval())\n",
    "    Y,X   = tf.meshgrid(y_extent, x_extent)\n",
    "    print(Y.shape, X.shape)\n",
    "    bbox_mask    = tf.stack([Y,X],axis=2)\n",
    "    print(' bbox_mask shapoe: ',bbox_mask.shape)\n",
    "\n",
    "    mask_indices = tf.reshape(bbox_mask,[-1,2])\n",
    "    print('  size of mask_indices: ', mask_indices.shape)\n",
    "\n",
    "    mask_size = mask_indices.get_shape()[0]\n",
    "    mask_updates = tf.ones([mask_size], dtype = tf.int32)\n",
    "    print('  size of bbox_mask: ', mask_size)\n",
    "    res = tf.scatter_nd_add(ref2, mask_indices, mask_updates)\n",
    "    print( ' ref shape: ', res.shape)\n",
    "    print( ' indices shape: ', mask_indices.shape)\n",
    "    print( ' updates shape: ', mask_updates.shape)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "###  Comparing Scipy / Tensorflow Multivar normal distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T10:10:11.958301Z",
     "start_time": "2018-04-16T10:10:10.121532Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "tfd        = tf.contrib.distributions\n",
    "grid       = pos_grid_1[:,:,0,0,:]\n",
    "covar      = np.array([27.7818, 26.6678],dtype = np.float32)\n",
    "covar_sqrt = np.sqrt(covar)\n",
    "covar_sqrd = covar ** 2\n",
    "full_covar = np.array([[27.7818, 0],[0, 26.6678]],dtype = np.float32)\n",
    "mean       = np.array([48.8926, 36.101 ],dtype = np.float32)\n",
    "\n",
    "print('   grid :', grid.dtype, grid.shape)\n",
    "print('   Covar sqrt :', covar_sqrt)\n",
    "print('   Covar sqrd :', covar_sqrd)\n",
    "\n",
    "mvn1  = tfd.MultivariateNormalDiag(loc=mean,scale_diag=covar_sqrt)\n",
    "prob1 = mvn1.prob(grid2)\n",
    "print()\n",
    "print('   mvn1 mean             ', mvn1.mean().eval())\n",
    "print('   mvn1 std deviation    ', mvn1.stddev().eval())\n",
    "print('   mvn1 covariance:      ', '\\n', mvn1.covariance().eval())\n",
    "print('   mvn1 location         ', mvn1.loc.eval())\n",
    "print('   Linear OP shape       ', mvn1.scale.shape)\n",
    "print('   Linear Op batch shape ', mvn1.scale.batch_shape)\n",
    "print('   Linear op Range Dim   ', mvn1.scale.range_dimension)\n",
    "print('   Linear op Domain Dim  ', mvn1.scale.domain_dimension) \n",
    "print('   Linear op Domain Dim  ', mvn1.scale.diag_part().eval()) \n",
    "\n",
    "mvn2  = tfd.MultivariateNormalDiag(loc=mean,scale_diag=covar)\n",
    "prob2 = mvn2.prob(grid2)\n",
    "print()\n",
    "print('   mvn2 mean             ', mvn2.mean().eval())\n",
    "print('   mvn2 std deviation    ', mvn2.stddev().eval())\n",
    "print('   mvn2 covariance:      ', '\\n', mvn2.covariance().eval())\n",
    "print('   mvn2 location         ', mvn2.loc.eval())\n",
    "print('   Linear OP shape       ', mvn2.scale.shape)\n",
    "print('   Linear Op batch shape ', mvn2.scale.batch_shape)\n",
    "print('   Linear op Range Dim   ', mvn2.scale.range_dimension)\n",
    "print('   Linear op Domain Dim  ', mvn2.scale.domain_dimension) \n",
    "print('   Linear op Domain Dim  ', mvn2.scale.diag_part().eval()) \n",
    "\n",
    "\n",
    "mvn3  = tfd.MultivariateNormalFullCovariance( loc = mean, covariance_matrix = full_covar)\n",
    "prob3 = mvn3.prob(grid2)\n",
    "print()\n",
    "print('   mvn3 mean             ', mvn3.mean().eval())\n",
    "print('   mvn3 std deviation    ', mvn3.stddev().eval())\n",
    "print('   mvn3 covariance:      ', '\\n', mvn3.covariance().eval())\n",
    "print('   mvn3 location         ', mvn3.loc.eval())\n",
    "print('   Linear OP shape       ', mvn3.scale.shape)\n",
    "print('   Linear Op batch shape ', mvn3.scale.batch_shape)\n",
    "print('   Linear op Range Dim   ', mvn3.scale.range_dimension)\n",
    "print('   Linear op Domain Dim  ', mvn3.scale.domain_dimension) \n",
    "print('   Linear op Domain Dim  ', mvn3.scale.diag_part().eval()) \n",
    "\n",
    "print('   << output probabilities shape:' )\n",
    "print(' prob1 ', prob1.get_shape())\n",
    "print(prob1.eval())\n",
    "print(' prob2 ', prob2.get_shape())\n",
    "print(prob2.eval())\n",
    "print(' prob3 ', prob3.get_shape())\n",
    "print(prob3.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T09:59:30.850107Z",
     "start_time": "2018-04-16T09:59:30.182014Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150, threshold=10000)\n",
    "from scipy.stats import  multivariate_normal\n",
    "# Build mesh-grid to hold pixel coordinates ----------------------------------\n",
    "XX = np.arange(0, img_w, 1)\n",
    "YY = np.arange(0, img_h, 1)\n",
    "XX, YY = np.meshgrid(XX, YY)\n",
    "pos  = np.empty(XX.shape + (2,))   # concatinate shape of x to make ( x.rows, x.cols, 2)\n",
    "pos[:,:,0] = XX;\n",
    "pos[:,:,1] = YY;\n",
    "# print(XX)\n",
    "# print(YY)\n",
    "# print(pos[0,:,:])\n",
    "# print(pos[0])\n",
    "# print(grid[0].eval())\n",
    "print(' pos type    ', type(pos), type(grid))\n",
    "print(' grid shape ', pos.shape, grid.shape)\n",
    "print(np.all(pos == grid.eval()))\n",
    "print(' mean  ', mean)\n",
    "print(' covar ', covar)\n",
    "mvna    = multivariate_normal(mean, covar)\n",
    "prob_a = mvna.pdf(pos)\n",
    "\n",
    "mvnb = multivariate_normal(mean, covar_sqrd)\n",
    "prob_b = mvnb.pdf(pos)\n",
    "\n",
    "print(prob_a[35:50, 45:54])\n",
    "max_a = np.max(prob_a)\n",
    "print(np.unravel_index(np.argmax(prob_a) , prob_a.shape) )\n",
    "\n",
    "print()\n",
    "\n",
    "print(' covar ', covar_sqrd)\n",
    "print(prob_b[35:50, 45:54])\n",
    "max_b = np.max(prob_b)\n",
    "print(np.unravel_index(np.argmax(prob_b) , prob_b.shape) )\n",
    "\n",
    "print('max a , max_b ', max_a, max_b, max_a/max_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "###  Build indicies to gather bounding boxes from bboxes_4d corrsponding to predicted class\n",
    "#### Only used if we want to use mrcnn_bboxes (batch_size, num_rois, num_classes, 4)\n",
    "\n",
    "batch_size x nuum_detections x 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "###  Build indicies to gather bounding boxes from bboxes_4d corrsponding to predicted class\n",
    "###  Only used if we want to use mrcnn_bboxes (batch_size, num_rois, num_classes, 4)\n",
    "\n",
    "# gather_boxes = tf.stack([batch_grid, roi_grid, pred_classes, ], axis = -1)\n",
    "\n",
    "# print('-- gather_boxes  ----')\n",
    "# print('gather_boxes inds', type(gather_boxes), 'shape',tf.shape(gather_boxes).eval())\n",
    "# print(gather_boxes.eval())\n",
    "\n",
    "# mrcnn_bboxes_selected = tf.gather_nd(mrcnn_bboxes, gather_boxes)\n",
    "# print(' padding required for output_rois : ', mrcnn_bboxes_selected.get_shape())\n",
    "# print(mrcnn_bboxes_selected[0].eval())\n",
    "\n",
    "# print(' output_rois shape ', output_rois.get_shape())\n",
    "# print(pred_classes[0].eval())\n",
    "# print(output_rois[0].eval())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Experimental Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "###  Experiment for sort ordering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indices = tf.constant([\n",
    "            [[0,2],[0,1],[0,0]],\n",
    "            [[1,2],[1,1],[1,0]],\n",
    "            [[2,0],[2,1],[2,1]],\n",
    "          ])\n",
    "params = tf.constant( [\n",
    "          [['0-00', '0-01', '0-02', '0-03'], \n",
    "           ['0-10', '0-11', '0-12', '0-13'],\n",
    "           ['0-20', '0-21', '0-22', '0-23'],\n",
    "           ['0-30', '0-31', '0-32', '0-33']],\n",
    "    \n",
    "          [['1-00', '1-01', '1-02', '1-03'], \n",
    "           ['1-10', '1-11', '1-12', '1-13'],\n",
    "           ['1-20', '1-21', '1-22', '1-23'],\n",
    "           ['1-30', '1-31', '1-32', '1-33']],\n",
    "    \n",
    "          [['2-00', '2-01', '2-02', '2-03'], \n",
    "           ['2-10', '2-11', '2-12', '2-13'],\n",
    "           ['2-20', '2-21', '2-22', '2-23'],\n",
    "           ['2-30', '2-31', '2-32', '2-33']]    \n",
    "         ])\n",
    "print(params.shape, '   ', indices.shape)\n",
    "res = tf.gather_nd(params, indices)\n",
    "res.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "###  Experiment with GATHER() for splitting into classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# indices = tf.constant([\n",
    "#             [0,2,2],[0,1,1],[0,0,0],\n",
    "#             [1,2,2],[1,1,1],[1,0,0],\n",
    "#             [2,0,0],[2,1,1],[2,1,1],\n",
    "#            ])\n",
    "# indices = tf.constant([ [0,2],[0,1],[0,0],[1,2],[1,1],[1,0],[1,2],[1,3], [2,3]] ) # 9 x 2\n",
    "indices = tf.constant([\n",
    "           [\n",
    "            [[0,2],[0,1],[0,0],[1,2],[2,3]],\n",
    "            [[1,1],[1,0],[1,2],[1,3],[1,1]]\n",
    "           ]\n",
    "           ])\n",
    "params = tf.constant( [\n",
    "          [['0-00', '0-01', '0-02', '0-03', '0-04', '0-05', '0-06'], \n",
    "           ['0-10', '0-11', '0-12', '0-13', '0-14', '0-15', '0-16'],\n",
    "           ['0-20', '0-21', '0-22', '0-23', '0-24', '0-25', '0-26'],\n",
    "           ['0-30', '0-31', '0-32', '0-33', '0-34', '0-35', '0-36'],\n",
    "           ['0-40', '0-41', '0-42', '0-43', '0-44', '0-45', '0-46']],\n",
    "                                                          \n",
    "          [['1-00', '1-01', '1-02', '1-03', '1-04', '1-05', '1-06'], \n",
    "           ['1-10', '1-11', '1-12', '1-13', '1-14', '1-15', '1-16'],\n",
    "           ['1-20', '1-21', '1-22', '1-23', '1-24', '1-25', '1-26'],\n",
    "           ['1-30', '1-31', '1-32', '1-33', '1-34', '1-35', '1-36'],\n",
    "           ['1-40', '1-41', '1-42', '1-43', '1-44', '1-45', '1-46']],\n",
    "                                                          \n",
    "          [['2-00', '2-01', '2-02', '2-03', '2-04', '2-05', '2-06'], \n",
    "           ['2-10', '2-11', '2-12', '2-13', '2-14', '2-15', '2-16'],\n",
    "           ['2-20', '2-21', '2-22', '2-23', '2-24', '2-25', '2-26'],\n",
    "           ['2-30', '2-31', '2-32', '2-33', '2-34', '2-35', '2-36'],\n",
    "           ['2-40', '2-41', '2-42', '2-43', '2-44', '2-45', '2-46']]    \n",
    "         ])\n",
    "print(' params sahape: ', params.shape, ' parms[:axis]', params.shape[:0], params.shape[:1], params.shape[:2], params.shape[:3])\n",
    "print(' params sahape: ', params.shape, ' parms[:axis]', params.shape[0:], params.shape[1:], params.shape[2:], params.shape[3:])\n",
    "print(' indices.shape  ', indices.shape)\n",
    "res = tf.gather_nd(params, indices)\n",
    "print('result shape   ', res.get_shape())\n",
    "res.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "num_detections = 8\n",
    "# batch_size is  3\n",
    "gt_class_ids = tf.constant([[1,2,3,0,0,0,0,0],[3,3,3,0,0,0,0,0],[1,2,2,0,0,2,0,0]])\n",
    "gt_bboxes    = tf.random_uniform([batch_size,3,4], maxval = 127, dtype=tf.int32)\n",
    "\n",
    "\n",
    "gt_classes_exp = tf.to_float(tf.expand_dims(gt_class_ids ,axis=-1))\n",
    "print('    gt_classes_exp: ' ,gt_classes_exp.get_shape())\n",
    "print(gt_classes_exp.eval())\n",
    "\n",
    "\n",
    "zeros        = tf.zeros([batch_size,5,4], dtype = tf.int32)\n",
    "gt_bboxes    = tf.concat([gt_bboxes, zeros], axis = 1)\n",
    "gt_bboxes    = tf.to_float(gt_bboxes)\n",
    "print('\\n    gt_bboxes: ' ,gt_bboxes.get_shape())\n",
    "print(gt_bboxes.eval())\n",
    "\n",
    "mask = tf.greater(gt_class_ids,0)\n",
    "print(mask.eval())\n",
    "\n",
    "gt_scores     = tf.where(mask, tf.ones_like(gt_class_ids), tf.zeros_like(gt_class_ids))\n",
    "gt_scores_exp = tf.to_float(tf.expand_dims(gt_scores, axis=-1))\n",
    "print('\\n    gt_scores ', gt_scores_exp.get_shape())\n",
    "print(gt_scores_exp.eval())\n",
    "\n",
    "batch_grid, bbox_grid = tf.meshgrid( tf.range(batch_size    , dtype=tf.int32), \n",
    "                                    tf.range(num_detections , dtype=tf.int32), indexing = 'ij' )\n",
    "\n",
    "print('\\n    bbox_grid   ', type(bbox_grid)  , 'shape', bbox_grid.get_shape())\n",
    "print(bbox_grid.eval())\n",
    "print('\\n    batch_grid ', type(batch_grid), 'shape', batch_grid.get_shape())\n",
    "print(batch_grid.eval())\n",
    " \n",
    "bbox_idx_zeros  = tf.zeros_like(bbox_grid)\n",
    "bbox_idx        = tf.where(mask, bbox_grid , bbox_idx_zeros)\n",
    "bbox_idx        = tf.to_float(tf.expand_dims(bbox_idx, axis = -1))    \n",
    "print('    bbox_idx', type(bbox_idx), 'shape', bbox_idx.get_shape())\n",
    "print(bbox_idx.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "gt_array        = tf.concat([bbox_idx, gt_scores_exp , gt_bboxes, gt_classes_exp], axis=2)\n",
    "print('    gt_array  ',  type(gt_array), gt_array.shape)\n",
    "print(gt_array.eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "scatter_classes = tf.stack([batch_grid , gt_class_ids, bbox_grid],axis = -1)\n",
    "print('\\n    -- stack results ----')\n",
    "print('\\n    scatter_classes', type(scatter_classes), 'shape',tf.shape(scatter_classes).eval())\n",
    "print(scatter_classes.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "gt_scatter = tf.scatter_nd(scatter_classes, gt_array, [batch_size, num_classes, num_detections,7])\n",
    "print('    gt_tensor shape is ', gt_scatter.get_shape(), gt_scatter)\n",
    "gt_scatter.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "sort_vals, sort_inds = tf.nn.top_k(gt_scatter[:,:,:,0], k=gt_scatter.shape[2])\n",
    "print('    sort vals shape : ', sort_vals.get_shape())\n",
    "print(sort_vals.eval())\n",
    "print('    sort inds shape : ', sort_inds.get_shape())\n",
    "print(sort_inds.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# build gathering indexes to use in sorting \n",
    "class_grid, batch_grid, bbox_grid = tf.meshgrid(tf.range(num_classes),tf.range(batch_size), tf.range(num_detections))\n",
    "\n",
    "print('    class_grid  ', type(class_grid) , 'shape', class_grid.get_shape())\n",
    "print(class_grid.eval())\n",
    "print('    batch_grid  ', type(batch_grid) , 'shape', batch_grid.get_shape())\n",
    "print(class_grid.eval())\n",
    "print('    bbox_grid    ', type(bbox_grid) , 'shape', bbox_grid.get_shape())\n",
    "print(bbox_grid.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "gather_inds = tf.stack([batch_grid , class_grid, sort_inds],axis = -1)\n",
    "print('    -- pred_tensor results (A-boxes sorted by score ----')\n",
    "print('    gatehr_inds ', gather_inds.get_shape())\n",
    "print(gather_inds.eval())\n",
    "\n",
    "gt_tensor = tf.gather_nd(gt_scatter, gather_inds)\n",
    "print('    -- pred_tensor results (A-boxes sorted by score ----')\n",
    "print('    pred_tensor ', gt_tensor.get_shape())\n",
    "print(gt_tensor.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T08:39:08.799869Z",
     "start_time": "2018-04-27T08:39:08.370702Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "boxes1 = tf.Variable(tf.random_uniform([32, 4], minval=0, maxval=128, dtype=tf.float32, seed=1234), name = 'var')\n",
    "boxes2 = tf.Variable(tf.random_uniform([100, 4], minval=0, maxval=128, dtype=tf.float32, seed=1234), name = 'var')\n",
    "\n",
    "init = tf.global_variables_initializer().run()\n",
    "\n",
    "# boxes1 = tf.placeholder(tf.float32,(32,4))\n",
    "# boxes2 = tf.placeholder(tf.float32,(100,4))\n",
    "\n",
    "print(boxes1.get_shape(), boxes2.get_shape())\n",
    "aa = tf.expand_dims(boxes1, 1)\n",
    "print(tf.shape(aa).eval())\n",
    "aa = tf.tile(tf.expand_dims(boxes1, 1), [1, 1, tf.shape(boxes2)[0]])\n",
    "print(tf.shape(aa).eval())                          \n",
    "\n",
    "b1 = tf.reshape(tf.tile(tf.expand_dims(boxes1, 1), [1, 1, tf.shape(boxes2)[0]]), [-1, 4])\n",
    "print('b1 : ', tf.shape(b1).eval())\n",
    "b2 = tf.tile(boxes2, [tf.shape(boxes1)[0], 1])\n",
    "print('b2 : ', tf.shape(b1).eval())\n",
    "print('     overlaps_graph: shape of boxes1 after reshape: ',b1.shape)  # (?,4)\n",
    "print('     overlaps_graph: shape of boxes2 after reshape: ',b2.shape)  # (?,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T17:15:11.333768Z",
     "start_time": "2018-05-04T17:15:09.950026Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "May 03\n",
    "'''\n",
    "\n",
    "\n",
    "def development_build_gaussian_tf(in_tensor, config, names = None):    \n",
    "    # def build_gaussian_tf(in_tensor) :   #, pred_cls_cnt, config):\n",
    "    ## rois per image is determined by size of input tensor \n",
    "    ##   detection mode:   config.TRAIN_ROIS_PER_IMAGE \n",
    "    ##   ground_truth  :   config.DETECTION_MAX_INSTANCES    \n",
    "    '''\n",
    "    in_tensor :     [N, num_rois, 8 { index, ]\n",
    "    '''\n",
    "    in_tensor = pred_tensor\n",
    "\n",
    "    # num_detections  = config.DETECTION_MAX_INSTANCES\n",
    "\n",
    "    num_detections  = 32          # config.DETECTION_MAX_INSTANCES\n",
    "    num_cols        = 6\n",
    "    img_h, img_w    = [128, 128]  # config.IMAGE_SHAPE[:2]\n",
    "    batch_size      = config.BATCH_SIZE\n",
    "    num_classes     = config.NUM_CLASSES  \n",
    "\n",
    "    print('\\n ')\n",
    "    print('  > BUILD_GAUSSIAN_TF() for ' )\n",
    "\n",
    "    # rois per image is determined by size of input tensor \n",
    "    #   detection mode:   config.TRAIN_ROIS_PER_IMAGE \n",
    "    #   ground_truth  :   config.DETECTION_MAX_INSTANCES\n",
    "\n",
    "    print('    orignal in_tensor shape : ', in_tensor.shape)   \n",
    "    # in_tensor = in_tensor[:,:,:,2:7]\n",
    "    # in_tensor = in_tensor[:,:,:,]\n",
    "    print('    modified in_tensor shape : ', in_tensor.get_shape())\n",
    "\n",
    "    rois_per_image  = tf.to_int32(in_tensor.shape[2])\n",
    "    strt_cls        = 0 if rois_per_image == 32 else 1\n",
    "    print('    num of bboxes per class is : ', rois_per_image.eval())\n",
    "    # print(in_tensor[0].eval())\n",
    "\n",
    "    '''\n",
    "    ### Build Position meshgird\n",
    "    '''\n",
    "\n",
    "    ##-----------------------------------------------------------------------------\n",
    "    ## Build mesh-grid to hold pixel coordinates \n",
    "    ##-----------------------------------------------------------------------------\n",
    "    X = tf.range(img_w, dtype=tf.int32)\n",
    "    Y = tf.range(img_h, dtype=tf.int32)\n",
    "    X, Y = tf.meshgrid(X, Y)\n",
    "    # grid1 = tf.stack([X,Y], axis=-1)\n",
    "    # print('grid1 shape ', grid1.shape)\n",
    "    # print(grid1[0,:,:].eval())\n",
    "\n",
    "    print('   -- build meshgrid -----')\n",
    "    print('   X and Y meshgrid shapes ', X.get_shape(), Y.get_shape())\n",
    "    # print( ' X : \\n',X.eval())\n",
    "    # print( ' Y : \\n',Y.eval())\n",
    "\n",
    "    # ## hear we repeat X and Y  batch_size x rois_per_image times\n",
    "    ones = tf.ones([batch_size, rois_per_image,1, 1], dtype = tf.int32)\n",
    "    print('   ones: ',ones.shape)                \n",
    "    # # ones = tf.expand_dims(ones,-1)\n",
    "    # print(' ones with exp dims ',ones.shape)\n",
    "\n",
    "    rep_X = ones * X\n",
    "    rep_Y = ones * Y \n",
    "    # print(' ones_exp * X', ones.shape, '*', X.shape, '= ',rep_X.shape)\n",
    "    # print(' ones_exp * Y', ones.shape, '*', Y.shape, '= ',rep_Y.shape)\n",
    "\n",
    "    # # stack the X and Y grids \n",
    "    bef_pos = tf.to_float(tf.stack([rep_X,rep_Y], axis = -1))\n",
    "    print('   before transpse ', bef_pos.get_shape())\n",
    "    pos_grid = tf.transpose(bef_pos,[2,3,0,1,4])\n",
    "    print('   after transpose ', pos_grid.get_shape())    \n",
    "\n",
    "    # print(pos_grid_1[:,:,0,0,:].eval())\n",
    "\n",
    "    '''\n",
    "    ### Build stacked_list\n",
    "    For each image reduce the roi per class arrays into one array\n",
    "    List of stacked tensors (one per image) - each stacked tensor shape is `[? , 6]`\n",
    "    '''\n",
    "    ##-----------------------------------------------------------------------------\n",
    "    ## Stack non_zero bboxes from in_tensor into pt2_dense \n",
    "    ##-----------------------------------------------------------------------------\n",
    "    pt2_sum = tf.reduce_sum(tf.abs(in_tensor[:,:,:,:-2]) ,axis =-1)\n",
    "    print('   pt2_sum shape ',pt2_sum.shape)\n",
    "    print(pt2_sum[0].eval())\n",
    "\n",
    "    pt2_mask = tf.greater(pt2_sum , 0)\n",
    "    print('   pt2_mask shape ', pt2_mask.get_shape())\n",
    "    # print(pt2_mask.eval())\n",
    "\n",
    "    pt2_ind  = tf.where(pt2_mask)\n",
    "    print('   pt2_ind shape  ', pt2_ind.get_shape())\n",
    "    print(pt2_ind[1].eval())\n",
    "    # pt2_ind_float  =  tf.to_float(pt2_ind[:,0:1])\n",
    "\n",
    "    pt2_dense = tf.gather_nd( in_tensor, pt2_ind)\n",
    "\n",
    "    # concatinate image id to front of ROI rows \n",
    "    dense1 = tf.concat([tf.to_float(pt2_ind[:,0:1]), pt2_dense ],axis=1)\n",
    "    print('   dense1 shape ', pt2_dense .get_shape())\n",
    "    #     print(pt2_dense .eval())\n",
    "\n",
    "    stacked_list = tf.dynamic_partition(pt2_dense , tf.to_int32(pt2_ind[:,0]),num_partitions = batch_size )\n",
    "\n",
    "    ''' \n",
    "    ### Build stacked tensor\n",
    "    Convert stacked_list into a tensor by adding necessary padding to each item and stacking them all together.\n",
    "\n",
    "    '''\n",
    "    print('   -- Build Stacked output from dynamically partitioned lists --------------')  \n",
    "\n",
    "    stacked_output=[]\n",
    "    for img, item  in enumerate(stacked_list) :\n",
    "        # rois_in_image, cols  = tf.shape(stacked_list[img]).eval()\n",
    "        rois_in_image  = tf.shape(item).eval()[0]\n",
    "\n",
    "        print('\\n   ===> list item #', img)       \n",
    "        print('   img ', img, ' stacked_list[img] ', tf.shape(item).eval(), ' rois_in_image : ', rois_in_image)\n",
    "        #     print(stacked_list[img].eval())            \n",
    "        pad_item =  tf.pad(item,[[0, rois_per_image - rois_in_image ],[0,0]])\n",
    "        stacked_output.append(pad_item)\n",
    "        print('   tensor_list item pos padding :', tf.shape(pad_item).eval())\n",
    "        #     print(stacked_list[img].eval())\n",
    "    stacked_tensor = tf.stack(stacked_output)\n",
    "    print()    \n",
    "    print('   -- Stacked output contents --------------')    \n",
    "    print('    stacked_output shape : ', len(stacked_output))\n",
    "    for img, item  in enumerate(stacked_output) :\n",
    "        print('   img ', img, ' stacked_list[img] ', tf.shape(item).eval() ) \n",
    "    print('   stacked tensor : ', tf.shape(stacked_tensor).eval(), stacked_tensor.shape, stacked_tensor.get_shape())\n",
    "    # print(stacked_tensor[0].eval())\n",
    "    # print()\n",
    "    # print(stacked_tensor[1].eval())\n",
    "    print()\n",
    "    print(stacked_tensor[2].eval())\n",
    "\n",
    "    '''\n",
    "    ###  Build mean and covar components for Multivariate normal and execute\n",
    "    '''\n",
    "\n",
    "    ##-----------------------------------------------------------------------------\n",
    "    ##  Build mean and convariance tensors for Multivariate Normal Distribution\n",
    "    ##-----------------------------------------------------------------------------\n",
    "    width  = stacked_tensor[:,:,3] - stacked_tensor[:,:,1]\n",
    "    height = stacked_tensor[:,:,2] - stacked_tensor[:,:,0]\n",
    "    cx     = stacked_tensor[:,:,1] + ( width  / 2.0)\n",
    "    cy     = stacked_tensor[:,:,0] + ( height / 2.0)\n",
    "    means  = tf.stack((cx,cy),axis = -1)\n",
    "    covar_orig  = tf.stack((width * 0.5 , height * 0.5), axis = -1)\n",
    "    covar  = tf.sqrt(covar_orig)\n",
    "    \n",
    "    # print(means.eval())\n",
    "    # print(covar.eval())\n",
    "\n",
    "    # print('width shape ',width.get_shape()) \n",
    "    # print(mns.eval())\n",
    "    tfd = tf.contrib.distributions\n",
    "    mvn = tfd.MultivariateNormalDiag(\n",
    "        loc  = means,\n",
    "        scale_diag = covar)\n",
    "\n",
    "    print('   means shape ',means.get_shape(), '  ', means.get_shape())\n",
    "    print('   covar shape ',covar.get_shape(), '  ', covar.get_shape())\n",
    "    print('   from MVN :  \\t mean shape     :', mvn.mean().shape, '\\t stddev shape', mvn.stddev().shape )\n",
    "    print('   from MVN :  \\t mean shape     :', mvn.mean().get_shape(), '\\t stddev shape', mvn.stddev().get_shape())\n",
    "    print('   from MVN :  \\t mvn.batch_shape:', mvn.batch_shape , '\\t mvn.event_shape ',  mvn.event_shape)\n",
    "    print('   Linear OP shape      ', mvn.scale.shape, ' Linear Op batch shape ',mvn.scale.batch_shape)\n",
    "    print('   Linear op Range Dim  ', mvn.scale.range_dimension)\n",
    "    print('   Linear op Domain Dim ', mvn.scale.domain_dimension) \n",
    "\n",
    "    prob_grid = mvn.prob(pos_grid)\n",
    "    # print(prob.eval())\n",
    "    #     eq = tf.equal(grid, pos)\n",
    "    #     print( ' pos and grid probabalitiy matricies equal  -->', tf.reduce_all(eq).eval())\n",
    "    prob_grid = tf.transpose(prob_grid,[2,3,0,1])\n",
    "\n",
    "    print('    >> input to MVN.PROB: pos_grid (meshgrid) shape: ', pos_grid.get_shape())\n",
    "    print('    << output probabilities shape:' , prob_grid.get_shape())\n",
    "\n",
    "    #--------------------------------------------------------------------------------\n",
    "    # kill distributions of NaN boxes (resulting from bboxes with height/width of zero\n",
    "    # which cause singular sigma cov matrices\n",
    "    #--------------------------------------------------------------------------------\n",
    "    gauss_grid = tf.where(tf.is_nan(prob_grid),  tf.zeros_like(prob_grid), prob_grid)\n",
    "\n",
    "    #--------------------------------------------------------------------------------\n",
    "    ## scatter out the probability distributions based on class\n",
    "    #--------------------------------------------------------------------------------\n",
    "    print('    Scatter out the probability distributions based on class --------------')     \n",
    "    '''\n",
    "    class_inds      = tf.to_int32(stacked_tensor[:,:,-1])\n",
    "    '''\n",
    "    class_inds      = tf.to_int32(stacked_tensor[:,:,-2])\n",
    "    batch_grid, roi_grid = tf.meshgrid( tf.range(batch_size, dtype=tf.int32), tf.range(rois_per_image, dtype=tf.int32),\n",
    "                                        indexing = 'ij' )\n",
    "    scatter_classes = tf.stack([batch_grid, class_inds, roi_grid ],axis = -1)\n",
    "    gauss_scatt     = tf.scatter_nd(scatter_classes, gauss_grid, [batch_size, num_classes, rois_per_image, img_w, img_h])\n",
    "\n",
    "    print('    gaussian_grid      : ', gauss_grid.shape)    \n",
    "    print('    class shape        : ', class_inds.shape)\n",
    "    # print(class_inds.eval())\n",
    "    print('    roi_grid shape     : ', roi_grid.get_shape() )\n",
    "    print('    batch_grid shape   : ', batch_grid.get_shape())\n",
    "    print('    scatter_classes    : ', scatter_classes.get_shape())\n",
    "    print('    gaussian scattered : ', gauss_scatt.shape)   \n",
    "\n",
    "    print('   means shape ',means.get_shape())\n",
    "    # print(means.eval())\n",
    "    print('   covar orig shape ',covar_orig.get_shape())\n",
    "    # print(covar_orig.eval())\n",
    "\n",
    "\n",
    "    #--------------------------------------------------------------------------------\n",
    "    ## sum based on class\n",
    "    #--------------------------------------------------------------------------------\n",
    "    print('    Reduce sum based on class ---------------------------------------------')         \n",
    "    gauss_sum = tf.reduce_sum(gauss_scatt, axis=2, name='pred_gaussian')\n",
    "    print('    gaussian_sum shape : ', gauss_sum.get_shape())    \n",
    "\n",
    "    gauss_sum = tf.where(gauss_sum > 1e-6, gauss_sum,tf.zeros_like(gauss_sum))\n",
    "    gauss_sum = tf.transpose(gauss_sum,[0,2,3,1])\n",
    "    print('    gaussian_sum shape : ', gauss_sum.get_shape())    \n",
    "    print('    complete')    \n",
    "    \n",
    "    \n",
    "    return stacked_tensor,covar, means, gauss_grid, gauss_sum"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python [conda env:TF_gpu]",
   "language": "python",
   "name": "conda-env-TF_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
