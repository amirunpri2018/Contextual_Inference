{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Development Notebook for  `build_groundtruth_tf` function \n",
    "- Setup model, load weights and data generators \n",
    "- get items from data generator\n",
    "- pass through network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T13:10:10.501045Z",
     "start_time": "2018-05-13T13:10:06.143593Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import  gc\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import keras.backend as KB\n",
    "sys.path.append('../')\n",
    "\n",
    "import mrcnn.model_mod     as modellib\n",
    "import mrcnn.visualize as visualize\n",
    "import mrcnn.shapes    as shapes\n",
    "from mrcnn.config      import Config\n",
    "from mrcnn.model       import log\n",
    "from mrcnn.dataset     import Dataset \n",
    "\n",
    "from mrcnn.utils       import stack_tensors, stack_tensors_3d\n",
    "from mrcnn.datagen     import data_generator, load_image_gt\n",
    "from mrcnn.callbacks   import get_layer_output_1,get_layer_output_2\n",
    "from mrcnn.visualize   import plot_gaussian\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "MODEL_PATH = 'E:\\Models'\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(MODEL_PATH, \"mrcnn_development_logs\")\n",
    "# Path to COCO trained weights\n",
    "COCO_MODEL_PATH   = os.path.join(MODEL_PATH, \"mask_rcnn_coco.h5\")\n",
    "RESNET_MODEL_PATH = os.path.join(MODEL_PATH, \"resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n",
    "\n",
    "print(\"Tensorflow Version: {}   Keras Version : {} \".format(tf.__version__,keras.__version__))\n",
    "\n",
    "\n",
    "\n",
    "# Build configuration object -----------------------------------------------\n",
    "config = shapes.ShapesConfig()\n",
    "config.BATCH_SIZE      = 3                  # Batch size is 2 (# GPUs * images/GPU).\n",
    "config.IMAGES_PER_GPU  = 3                  # Must match BATCH_SIZE\n",
    "config.STEPS_PER_EPOCH = 2\n",
    "config.FCN_INPUT_SHAPE = config.IMAGE_SHAPE[0:2]\n",
    "# config.display() \n",
    "\n",
    "# Build shape dataset        -----------------------------------------------\n",
    "# Training dataset\n",
    "# generate 500 shapes \n",
    "dataset_train = shapes.ShapesDataset()\n",
    "dataset_train.load_shapes(150, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_train.prepare()\n",
    " \n",
    "config.display()\n",
    "\n",
    "try :\n",
    "    del model, train_generator, val_generator, mm\n",
    "    gc.collect()\n",
    "except: \n",
    "    pass\n",
    "# Load and display random samples\n",
    "# image_ids = np.random.choice(dataset_train.image_ids, 3)\n",
    "# for image_id in [3]:\n",
    "#     image = dataset_train.load_image(image_id)\n",
    "#     mask, class_ids = dataset_train.load_mask(image_id)\n",
    "#     visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "print(' COCO Model Path       : ', COCO_MODEL_PATH)\n",
    "print(' Checkpoint folder Path: ', MODEL_DIR)\n",
    "print(' Model Parent Path     : ', MODEL_PATH)\n",
    "print(' Resent Model Path     : ', RESNET_MODEL_PATH)\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
    "np.set_printoptions(linewidth=100,precision=4)\n",
    "\n",
    "# batch_size = 3\n",
    "# num_rois = 32\n",
    "# num_classes = 4\n",
    "# num_detections = 100\n",
    "# num_rois_per_image = 32\n",
    "# rois_per_image = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T13:10:20.196627Z",
     "start_time": "2018-05-13T13:10:10.503552Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try :\n",
    "    del model\n",
    "    print('delete model is successful')\n",
    "    gc.collect()\n",
    "except: \n",
    "    pass\n",
    "KB.clear_session()\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T13:19:57.415255Z",
     "start_time": "2018-05-13T13:19:57.150989Z"
    }
   },
   "outputs": [],
   "source": [
    "print(' COCO Model Path       : ', COCO_MODEL_PATH)\n",
    "print(' Checkpoint folder Path: ', MODEL_DIR)\n",
    "print(' Model Parent Path     : ', MODEL_PATH)\n",
    "print(' Resent Model Path     : ', RESNET_MODEL_PATH)\n",
    "print(model.find_last())\n",
    "\n",
    "# model.compile_only(learning_rate=config.LEARNING_RATE, layers='all')\n",
    "# sys.setrecursionlimit(5000)\n",
    "# tst = model.keras_model.to_json()\n",
    "# save_model(MODEL_DIR, 'my_saved_model')\n",
    "# print(model.find_last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T13:02:11.818750Z",
     "start_time": "2018-05-13T13:02:02.791420Z"
    }
   },
   "outputs": [],
   "source": [
    "#model.keras_model.summary(line_length = 120) \n",
    "# model.compile_only(learning_rate=config.LEARNING_RATE, layers='heads')\n",
    "# KB.set_learning_phase(1)\n",
    "'''\n",
    "methods to load weights\n",
    "1 - load a specific file\n",
    "2 - find a last checkpoint in a specific folder \n",
    "3 - use init_with keyword \n",
    "'''\n",
    "## 1- look for a specific weights file \n",
    "## Load trained weights (fill in path to trained weights here)\n",
    "# model_path  = 'E:\\\\Models\\\\mrcnn_logs\\\\shapes20180428T1819\\\\mask_rcnn_shapes_5784.h5'\n",
    "# print(' model_path : ', model_path )\n",
    "# assert model_path != \"\", \"Provide path to trained weights\"\n",
    "# print(\"Loading weights from \", model_path)\n",
    "# model.load_weights(model_path, by_name=True)    \n",
    "# print('Load weights complete')\n",
    "\n",
    "# ## 2- look for last checkpoint file in a specific folder (not working correctly)\n",
    "# model.config.LAST_EPOCH_RAN = 5784\n",
    "# model.model_dir = 'E:\\\\Models\\\\mrcnn_logs\\\\shapes20180428T1819'\n",
    "# last_model_found = model.find_last()\n",
    "# print(' last model in MODEL_DIR: ', last_model_found)\n",
    "# # loc= model.load_weights(model.find_last()[1], by_name=True)\n",
    "# # print('Load weights complete :', loc)\n",
    "\n",
    "\n",
    "## 3- Use init_with keyword\n",
    "## Which weights to start with?\n",
    "init_with = \"coco\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "#     loc=model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "    loc=model.load_weights(RESNET_MODEL_PATH, by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    \n",
    "    # See README for instructions to download the COCO weights\n",
    "    loc=model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    loc= model.load_weights(model.find_last()[1], by_name=True)\n",
    "print('Load weights complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T13:11:52.525801Z",
     "start_time": "2018-05-13T13:11:52.281604Z"
    }
   },
   "outputs": [],
   "source": [
    "print('\\n Inputs: ') \n",
    "for i, out in enumerate(model.keras_model.inputs):\n",
    "    print(i , '    ', out)\n",
    "\n",
    "print('\\n Outputs: ') \n",
    "for i, out in enumerate(model.keras_model.outputs):\n",
    "    print(i , '    ', out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T09:52:39.587891Z",
     "start_time": "2018-05-13T09:52:39.365259Z"
    }
   },
   "outputs": [],
   "source": [
    "train_generator = data_generator(dataset_train, model.config, shuffle=True,\n",
    "                                 batch_size=model.config.BATCH_SIZE,\n",
    "                                 augment = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T09:52:39.817459Z",
     "start_time": "2018-05-13T09:52:39.588852Z"
    }
   },
   "outputs": [],
   "source": [
    "train_batch_x, train_batch_y = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T09:52:40.834178Z",
     "start_time": "2018-05-13T09:52:39.819466Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_batch_x, train_batch_y = next(train_generator)\n",
    "imgmeta_idx = model.keras_model.input_names.index('input_image_meta')\n",
    "img_meta    = train_batch_x[imgmeta_idx]\n",
    "\n",
    "for img_idx in range(config.BATCH_SIZE):\n",
    "    image_id = img_meta[img_idx,0]\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    print('Image id: ',image_id)\n",
    "    print('Image meta', img_meta[img_idx])\n",
    "    print('Classes (1: circle, 2: square, 3: triangle ): ',class_ids)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T09:52:41.387636Z",
     "start_time": "2018-05-13T09:52:41.165046Z"
    }
   },
   "outputs": [],
   "source": [
    "# 0      Tensor(\"input_image:0\", shape=(?, 128, 128, 3), dtype=float32)\n",
    "# 1      Tensor(\"input_image_meta:0\", shape=(?, ?), dtype=float32)\n",
    "# 2      Tensor(\"input_rpn_match:0\", shape=(?, ?, 1), dtype=int32)\n",
    "# 3      Tensor(\"input_rpn_bbox:0\", shape=(?, ?, 4), dtype=float32)\n",
    "# 4      Tensor(\"input_gt_class_ids:0\", shape=(?, ?), dtype=int32)\n",
    "# 5      Tensor(\"input_gt_boxes:0\", shape=(?, ?, 4), dtype=float32)\n",
    "# 6      Tensor(\"input_gt_masks:0\", shape=(?, 56, 56, ?), dtype=bool)\n",
    "\n",
    "input_image_meta =  train_batch_x[1]\n",
    "input_rpn_match  =  train_batch_x[2]\n",
    "input_rpn_bbox   =  train_batch_x[3]\n",
    "input_gt_class_ids = train_batch_x[4]\n",
    "input_gt_bboxes = train_batch_x[5]\n",
    "# gt_masks   =  train_batch_x[6]\n",
    "print(' input_rpn_match    ', input_rpn_match.shape)\n",
    "print(' input_rpn_bbox     ', input_rpn_bbox.shape)\n",
    "print(' input_gt_class_ids ', input_gt_class_ids.shape)\n",
    "print(' input_gt_bboxes    ', input_gt_bboxes.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T09:52:49.837100Z",
     "start_time": "2018-05-13T09:52:43.404999Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "model_output = get_layer_output_2(model.keras_model, train_batch_x, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T09:54:28.776949Z",
     "start_time": "2018-05-13T09:54:28.541324Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(model_output))\n",
    "# rpn_class_logits   = model_output[0]\n",
    "# rpn_class          = model_output[1]\n",
    "# rpn_bbox           = model_output[2]\n",
    "# rpn_proposal_rois  = model_output[3]\n",
    "output_rois        = model_output[4]\n",
    "target_class_ids   = model_output[5]\n",
    "target_bbox_deltas = model_output[6]\n",
    "roi_gt_boxes       = model_output[7]\n",
    "mrcnn_class_logits = model_output[8]\n",
    "mrcnn_class        = model_output[9]\n",
    "mrcnn_bbox         = model_output[10]\n",
    "# rpn_class_loss   = model_output[11]\n",
    "# rpn_bbox_loss    = model_output[12]\n",
    "# mrcnn_class_loss = model_output[13]\n",
    "# mrcnn_bbox_loss  = model_output[14]\n",
    "fcn_bbox_loss      = model_output[15]\n",
    "pred_hm            = model_output[16]\n",
    "gt_hm              = model_output[17]\n",
    "pred_hm_norm       = model_output[18]\n",
    "gt_hm_norm         = model_output[19]\n",
    "pred_tensor        = model_output[20]\n",
    "gt_tensor          = model_output[21]\n",
    "gt_deltas          = model_output[22]\n",
    "fcn_heatmap        = model_output[23]\n",
    "fcn_class_logits   = model_output[24]\n",
    "fcn_scores         = model_output[25]\n",
    "fcn_bbox_deltas    = model_output[26]\n",
    "# print(type(model_output[4]))\n",
    "# print(type(output_rois))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T10:03:28.480953Z",
     "start_time": "2018-05-13T10:03:28.249359Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(target_bbox_deltas.shape)\n",
    "# print(output_rois[0])\n",
    "# print(roi_gt_boxes[0])\n",
    "# print(target_class_ids[0])\n",
    "# print(gt_deltas[0])\n",
    "# print(target_bbox_deltas[0])\n",
    "# print(pred_tensor[0,1])\n",
    "# print(output_rois[0])\n",
    "# print(mrcnn_class.shape)\n",
    "# print(mrcnn_class[0])\n",
    "# print(np.argmax(mrcnn_class[0], axis = -1))\n",
    "print(target_class_ids[0])\n",
    "print(target_bbox_deltas[0])\n",
    "print(gt_deltas[0,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  `development build_grround_truth_tf ()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-12T19:01:02.002396Z",
     "start_time": "2018-05-12T19:01:01.744237Z"
    }
   },
   "outputs": [],
   "source": [
    "sess = KB.get_session()\n",
    "gt_bboxes    = tf.identity(target_bbox_deltas)\n",
    "gt_class_ids = tf.identity(target_class_ids)\n",
    "num_bboxes   = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-12T19:01:03.253808Z",
     "start_time": "2018-05-12T19:01:02.999132Z"
    }
   },
   "outputs": [],
   "source": [
    "# // pass model to TensorBuilder\n",
    "batch_size      = config.BATCH_SIZE\n",
    "num_classes     = config.NUM_CLASSES\n",
    "h, w            = config.IMAGE_SHAPE[:2]\n",
    "num_cols        = 6\n",
    "\n",
    "# num of bounding boxes is determined by bbox_list.shape[1] instead of config.DETECTION_MAX_INSTANCES\n",
    "# use of this routine for both input_gt_boxes, and target_gt_deltas\n",
    "if num_bboxes == config.DETECTION_MAX_INSTANCES:\n",
    "    tensor_name = \"gt_tensor\"\n",
    "else:\n",
    "    tensor_name = \"gt_deltas\"\n",
    "\n",
    "print('\\n')\n",
    "print('  > BUILD_GROUND TRUTH_TF()' )\n",
    "print('    gt_class_ids shape : ', KB.int_shape(gt_class_ids), '    gt_bboxes.shape  : ', gt_bboxes.get_shape() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-12T19:01:05.976619Z",
     "start_time": "2018-05-12T19:01:04.961417Z"
    }
   },
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------\n",
    "# use the argmaxof each row to determine the dominating (predicted) class\n",
    "#---------------------------------------------------------------------------\n",
    "# gt_classes     = gt_class_ids    # batch_size x max gt detections\n",
    "gt_classes_exp = tf.to_float(tf.expand_dims(gt_class_ids ,axis=-1))\n",
    "print('    gt_classes_exp shape ', gt_classes_exp.get_shape() )\n",
    "\n",
    "ones = tf.ones_like(gt_class_ids)\n",
    "zeros= tf.zeros_like(gt_class_ids)\n",
    "mask = tf.greater(gt_class_ids , 0)\n",
    "print(mask.shape)\n",
    "print(mask.eval(session=sess))\n",
    "gt_scores  =  tf.where(mask, ones, zeros)\n",
    "# pred_scores      = tf.reduce_max(mrcnn_class ,axis=-1, keep_dims=True)   # (32,)\n",
    "gt_scores_exp = tf.to_float(tf.expand_dims(gt_scores, axis=-1))\n",
    "print('    gt_scores shape ', gt_scores.get_shape())\n",
    "print(gt_scores.eval(session=sess))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-12T19:01:37.152315Z",
     "start_time": "2018-05-12T19:01:36.055900Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------\n",
    "# create meshgrid to do something \n",
    "#---------------------------------------------------------------------------\n",
    "batch_grid, bbox_grid = tf.meshgrid( tf.range(batch_size    , dtype=tf.int32), \n",
    "                                    tf.range(num_bboxes, dtype=tf.int32), indexing = 'ij' )\n",
    "\n",
    "# sequence id is used to preserve the order of rois as passed to this routine\n",
    "sequence = gt_scores * (bbox_grid[...,::-1] + 1) \n",
    "sequence = tf.to_float(tf.expand_dims(sequence, axis = -1))   \n",
    "\n",
    "print('    batch_grid shape  ', batch_grid.get_shape())\n",
    "print(batch_grid.eval(session=sess))\n",
    "print('    bbox_grid  shape  ', bbox_grid.get_shape())\n",
    "print(bbox_grid.eval(session=sess))\n",
    "print('    sequence shape    ', sequence.get_shape())\n",
    "print(sequence.eval(session=sess)) \n",
    "\n",
    "gt_array        = tf.concat([gt_bboxes, gt_classes_exp, gt_scores_exp, sequence ], axis=2)\n",
    "\n",
    "print('    gt_array shape    ', gt_array.get_shape())\n",
    "print(gt_array.eval(session=sess)) \n",
    "print(gt_array.shape[-1])    \n",
    "# print(gt_array[:,:10].eval(session=sess))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-12T19:02:01.703229Z",
     "start_time": "2018-05-12T19:02:00.975767Z"
    }
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# Create indicies to scatter rois out to multi-dim tensor by image id and class\n",
    "# resulting tensor is batch size x num_classes x num_detections x 7 (num columns)\n",
    "#------------------------------------------------------------------------------\n",
    "scatter_ind = tf.stack([batch_grid , gt_class_ids, bbox_grid],axis = -1)\n",
    "print('    scatter_ind shape ', scatter_ind.get_shape())\n",
    "print(scatter_ind.eval(session=sess))\n",
    "\n",
    "\n",
    "gt_scatter = tf.scatter_nd(scatter_ind, gt_array, [batch_size, num_classes, num_bboxes, gt_array.shape[-1] ])\n",
    "\n",
    "\n",
    "# print('-- stack results ----')\n",
    "print('    scatter_ind shape ', scatter_ind.get_shape())\n",
    "# print(scatter_ind.eval())\n",
    "print('    gt_scatter shape ', gt_scatter.get_shape())\n",
    "\n",
    "print(gt_scatter[1,:,:,:].eval(session=sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-12T19:02:25.628810Z",
     "start_time": "2018-05-12T19:02:25.310965Z"
    }
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------\n",
    "## sort in each class dimension based on y2 (column 1)\n",
    "# scatter_nd places bboxs in a sparse fashion --- this sort is to place all bboxes\n",
    "# at the top of the class bbox array\n",
    "#-------------------------------------------------------------------------------\n",
    "_ , sort_inds = tf.nn.top_k(gt_scatter[:,:,:,-1] , k=gt_scatter.shape[2])\n",
    "\n",
    "# build indexes to gather rows from pred_scatter based on sort order \n",
    "class_grid, batch_grid, bbox_grid = tf.meshgrid(tf.range(num_classes),tf.range(batch_size), tf.range(num_bboxes))\n",
    "bbox_grid_exp = tf.to_float(tf.expand_dims(bbox_grid, axis = -1))\n",
    "\n",
    "print('    build gathering indexes to use in sorting -------')    \n",
    "print('    sort inds shape : ', sort_inds.get_shape())\n",
    "print('    class_grid  shape ', class_grid.get_shape())\n",
    "# print(class_grid.eval())\n",
    "print('    batch_grid  shape ', batch_grid.get_shape())\n",
    "# print(batch_grid.eval())\n",
    "print('    bbox_grid   shape ', bbox_grid.get_shape() , ' bbox_grid_exp shape ', bbox_grid_exp.get_shape())\n",
    "# print(bbox_grid.eval())\n",
    "\n",
    "gather_inds = tf.stack([batch_grid , class_grid, sort_inds],axis = -1)\n",
    "gt_tensor   = tf.gather_nd(gt_scatter, gather_inds, name  = tensor_name)[...,:-1]\n",
    "print('    gather_inds shape      : ', gather_inds.get_shape())\n",
    "print('    gt_tensor (gathered)   : ', gt_tensor.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-12T19:02:29.074597Z",
     "start_time": "2018-05-12T19:02:28.600257Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(gt_tensor[2].eval(session=sess))\n",
    "print(target_bbox_deltas[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-12T18:54:35.217988Z",
     "start_time": "2018-05-12T18:54:34.182208Z"
    }
   },
   "outputs": [],
   "source": [
    "# append an index to the end of each row --- commented out 30-04-2018\n",
    "# gt_tensor   = tf.concat([gt_tensor, bbox_grid_exp], axis = -1)\n",
    "\n",
    "# count based on pred score > 0 (changed from index 0 to -1 on 30-04-2018)    \n",
    "gt_cls_cnt  = tf.count_nonzero(gt_tensor[:,:,:,-1],axis = -1, name = 'gt_cls_count')\n",
    "\n",
    "print('    final gt_tensor shape  : ', gt_tensor.get_shape())\n",
    "print('    final gt_cls_cnt shape : ', gt_cls_cnt.get_shape())\n",
    "print('    ', gt_cls_cnt.eval(session=sess))\n",
    "print('    complete')\n",
    "\n",
    "# return  [gt_tensor, gt_cls_cnt] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-12T14:40:59.566156Z",
     "start_time": "2018-05-12T14:40:59.323538Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(input_rpn_bbox.shape)\n",
    "print(target_bbox_deltas[0])\n",
    "print(gt_bboxes[0])\n",
    "print(gt_class_ids[0])\n",
    "print(gt_tensor[0,2].eval(session=sess))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-12T13:37:37.632674Z",
     "start_time": "2018-05-12T13:37:36.973663Z"
    }
   },
   "outputs": [],
   "source": [
    "print(target_class_ids.shape)\n",
    "sess = KB.get_session()\n",
    "with sess.as_default():\n",
    "    print(tf.where(target_class_ids > 0).eval())\n",
    "# target_class_ids[0]\n",
    "# target_bbox_deltas[0]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": true,
  "kernelspec": {
   "display_name": "Python [conda env:TF_gpu]",
   "language": "python",
   "name": "conda-env-TF_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
