{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Mask R-CNN - Train on Shapes Dataset\n",
    "\n",
    "### Compare ouptuts from Heatmap layer and FCN layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T14:39:17.460048Z",
     "start_time": "2018-05-03T14:38:47.586601Z"
    },
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 1.6.0   Keras Version : 2.1.4 \n",
      " Initialize config object - super\n",
      " COCO Model Path       :  E:\\Models\\mask_rcnn_coco.h5\n",
      " Checkpoint folder Path:  E:\\Models\\mrcnn_logs\n",
      "E:\\Models\n",
      "E:\\Models\\mask_rcnn_coco.h5\n",
      "E:\\Models\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "E:\\Models\\mrcnn_logs\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import  gc\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import keras.backend as KB\n",
    "sys.path.append('../')\n",
    "\n",
    "import mrcnn.model     as modellib\n",
    "import mrcnn.visualize as visualize\n",
    "import mrcnn.shapes    as shapes\n",
    "from mrcnn.config      import Config\n",
    "from mrcnn.model       import log\n",
    "from mrcnn.dataset     import Dataset \n",
    "\n",
    "from mrcnn.utils       import stack_tensors, stack_tensors_3d\n",
    "from mrcnn.datagen     import data_generator, load_image_gt\n",
    "from mrcnn.callbacks   import get_layer_output_1,get_layer_output_2\n",
    "from mrcnn.visualize   import plot_gaussian\n",
    "# from mrcnn.pc_layer    import PCTensor\n",
    "# from mrcnn.pc_layer   import PCNLayer\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "MODEL_PATH = 'E:\\Models'\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(MODEL_PATH, \"mrcnn_logs\")\n",
    "# Path to COCO trained weights\n",
    "COCO_MODEL_PATH   = os.path.join(MODEL_PATH, \"mask_rcnn_coco.h5\")\n",
    "RESNET_MODEL_PATH = os.path.join(MODEL_PATH, \"resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n",
    "\n",
    "print(\"Tensorflow Version: {}   Keras Version : {} \".format(tf.__version__,keras.__version__))\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
    "np.set_printoptions(linewidth=100,precision=4)\n",
    "\n",
    "\n",
    "# Build configuration object -----------------------------------------------\n",
    "config = shapes.ShapesConfig()\n",
    "config.BATCH_SIZE      = 5                  # Batch size is 2 (# GPUs * images/GPU).\n",
    "config.IMAGES_PER_GPU  = 5                  # Must match BATCH_SIZE\n",
    "config.STEPS_PER_EPOCH = 2\n",
    "config.FCN_INPUT_SHAPE = config.IMAGE_SHAPE[0:2]\n",
    "# config.display() \n",
    "\n",
    "# Build shape dataset        -----------------------------------------------\n",
    "# Training dataset\n",
    "# generate 500 shapes \n",
    "dataset_train = shapes.ShapesDataset()\n",
    "dataset_train.load_shapes(500, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = shapes.ShapesDataset()\n",
    "dataset_val.load_shapes(50, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_val.prepare()\n",
    "\n",
    "try :\n",
    "    del model, train_generator, val_generator, mm\n",
    "    gc.collect()\n",
    "except: \n",
    "    pass\n",
    "# Load and display random samples\n",
    "# image_ids = np.random.choice(dataset_train.image_ids, 3)\n",
    "# for image_id in [3]:\n",
    "#     image = dataset_train.load_image(image_id)\n",
    "#     mask, class_ids = dataset_train.load_mask(image_id)\n",
    "#     visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "print(' COCO Model Path       : ', COCO_MODEL_PATH)\n",
    "print(' Checkpoint folder Path: ', MODEL_DIR)\n",
    "print(MODEL_PATH)\n",
    "print(COCO_MODEL_PATH)\n",
    "print(RESNET_MODEL_PATH)\n",
    "print(MODEL_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T14:39:28.178493Z",
     "start_time": "2018-05-03T14:39:17.461008Z"
    },
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    set_log_dir: Checkpoint path set to : E:\\Models\\mrcnn_logs\\shapes20180503T1639\\mask_rcnn_shapes_{epoch:04d}.h5\n",
      "    set_log_dir: self.epoch set to 0 \n",
      "\n",
      ">>> Resnet Graph \n",
      "     Input_image shape : (?, 128, 128, 3)\n",
      "     After ZeroPadding2D  : (?, 134, 134, 3) (?, 134, 134, 3)\n",
      "     After Conv2D padding : (?, 64, 64, 64) (?, 64, 64, 64)\n",
      "     After BatchNorm      : (?, 64, 64, 64) (?, 64, 64, 64)\n",
      "     After MaxPooling2D   : (?, 32, 32, 64) (?, 32, 32, 64)\n",
      "\n",
      ">>> Feature Pyramid Network (FPN) Graph \n",
      "     FPN P2 shape : (None, 32, 32, 256)\n",
      "     FPN P3 shape : (None, 16, 16, 256)\n",
      "     FPN P4 shape : (None, 8, 8, 256)\n",
      "     FPN P5 shape : (None, 4, 4, 256)\n",
      "     FPN P6 shape : (None, 2, 2, 256)\n",
      "\n",
      ">>> RPN Layer \n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     depth                   : 256\n",
      "     Input_feature_map shape : (?, ?, ?, 256)\n",
      "     anchors_per_location    : 3\n",
      "     anchor_stride           : 1\n",
      "\n",
      ">>> RPN Outputs  <class 'list'>\n",
      "      rpn_class_logits/concat:0\n",
      "      rpn_class/concat:0\n",
      "      rpn_bbox/concat:0\n",
      "\n",
      ">>> Proposal Layer - generate  2000  proposals\n",
      "    Init complete. Size of anchors:  (4092, 4)\n",
      "     Scores :  (5, 4092)\n",
      "     Deltas :  (5, 4092, 4)\n",
      "     Anchors:  (5, 4092, 4)\n",
      "     Boxes shape / type after processing:  (5, 4092, 4) <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "     Output: Prposals shape :  (5, ?, ?) (5, None, None)\n",
      "\n",
      ">>> Detection Target Layer \n",
      "    Detection Target Layer : call()  <class 'list'> 4\n",
      "     proposals.shape    : (5, ?, ?) (5, ?, ?) (None, 2000, 4)\n",
      "     gt_class_ids.shape : (?, ?) (?, ?) (None, None)\n",
      "     gt_bboxes.shape    : (?, ?, 4) (?, ?, 4) (None, None, 4)\n",
      "     gt_masks.shape     : (?, 56, 56, ?) (?, 56, 56, ?) (None, 56, 56, None)\n",
      ">>> detection_targets_graph \n",
      "     propsals.shape        : (?, ?) (?, ?) (None, None)\n",
      "     gt_boxes.shape        : (?, 4) (None, 4)\n",
      "     gt_class_ids.shape    : (?,) (None,)\n",
      "     gt_masks.shape        : (56, 56, ?) (56, 56, None)\n",
      "\t>>> detection_targets_graph - calculate Overlaps_graph\n",
      "\t     overlaps_graph: shape of boxes1 before reshape:  (?, ?) (None, None)\n",
      "\t     overlaps_graph: shape of boxes2 before reshape:  (?, 4) (None, None)\n",
      "\t>>> detection_targets_graph - calculate Overlaps_graph\n",
      "\t     overlaps_graph: shape of boxes1 before reshape:  (?, ?) (None, None)\n",
      "\t     overlaps_graph: shape of boxes2 before reshape:  (?, 4) (None, None)\n",
      "     overlaps.shape        : (?, ?) (None, None)\n",
      ">>> detection_targets_graph \n",
      "     propsals.shape        : (?, ?) (?, ?) (None, None)\n",
      "     gt_boxes.shape        : (?, 4) (None, 4)\n",
      "     gt_class_ids.shape    : (?,) (None,)\n",
      "     gt_masks.shape        : (56, 56, ?) (56, 56, None)\n",
      "\t>>> detection_targets_graph - calculate Overlaps_graph\n",
      "\t     overlaps_graph: shape of boxes1 before reshape:  (?, ?) (None, None)\n",
      "\t     overlaps_graph: shape of boxes2 before reshape:  (?, 4) (None, None)\n",
      "\t>>> detection_targets_graph - calculate Overlaps_graph\n",
      "\t     overlaps_graph: shape of boxes1 before reshape:  (?, ?) (None, None)\n",
      "\t     overlaps_graph: shape of boxes2 before reshape:  (?, 4) (None, None)\n",
      "     overlaps.shape        : (?, ?) (None, None)\n",
      ">>> detection_targets_graph \n",
      "     propsals.shape        : (?, ?) (?, ?) (None, None)\n",
      "     gt_boxes.shape        : (?, 4) (None, 4)\n",
      "     gt_class_ids.shape    : (?,) (None,)\n",
      "     gt_masks.shape        : (56, 56, ?) (56, 56, None)\n",
      "\t>>> detection_targets_graph - calculate Overlaps_graph\n",
      "\t     overlaps_graph: shape of boxes1 before reshape:  (?, ?) (None, None)\n",
      "\t     overlaps_graph: shape of boxes2 before reshape:  (?, 4) (None, None)\n",
      "\t>>> detection_targets_graph - calculate Overlaps_graph\n",
      "\t     overlaps_graph: shape of boxes1 before reshape:  (?, ?) (None, None)\n",
      "\t     overlaps_graph: shape of boxes2 before reshape:  (?, 4) (None, None)\n",
      "     overlaps.shape        : (?, ?) (None, None)\n",
      ">>> detection_targets_graph \n",
      "     propsals.shape        : (?, ?) (?, ?) (None, None)\n",
      "     gt_boxes.shape        : (?, 4) (None, 4)\n",
      "     gt_class_ids.shape    : (?,) (None,)\n",
      "     gt_masks.shape        : (56, 56, ?) (56, 56, None)\n",
      "\t>>> detection_targets_graph - calculate Overlaps_graph\n",
      "\t     overlaps_graph: shape of boxes1 before reshape:  (?, ?) (None, None)\n",
      "\t     overlaps_graph: shape of boxes2 before reshape:  (?, 4) (None, None)\n",
      "\t>>> detection_targets_graph - calculate Overlaps_graph\n",
      "\t     overlaps_graph: shape of boxes1 before reshape:  (?, ?) (None, None)\n",
      "\t     overlaps_graph: shape of boxes2 before reshape:  (?, 4) (None, None)\n",
      "     overlaps.shape        : (?, ?) (None, None)\n",
      ">>> detection_targets_graph \n",
      "     propsals.shape        : (?, ?) (?, ?) (None, None)\n",
      "     gt_boxes.shape        : (?, 4) (None, 4)\n",
      "     gt_class_ids.shape    : (?,) (None,)\n",
      "     gt_masks.shape        : (56, 56, ?) (56, 56, None)\n",
      "\t>>> detection_targets_graph - calculate Overlaps_graph\n",
      "\t     overlaps_graph: shape of boxes1 before reshape:  (?, ?) (None, None)\n",
      "\t     overlaps_graph: shape of boxes2 before reshape:  (?, 4) (None, None)\n",
      "\t>>> detection_targets_graph - calculate Overlaps_graph\n",
      "\t     overlaps_graph: shape of boxes1 before reshape:  (?, ?) (None, None)\n",
      "\t     overlaps_graph: shape of boxes2 before reshape:  (?, 4) (None, None)\n",
      "     overlaps.shape        : (?, ?) (None, None)\n",
      "\n",
      "    Detection Target Layer : return  <class 'list'> 5\n",
      "     output 0  shape (5, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 1  shape (5, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 2  shape (5, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 3  shape (5, ?, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "     output 4  shape (5, ?, ?)  type <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "\n",
      ">>> FPN Classifier Graph \n",
      "     rois shape          : (5, ?, ?)\n",
      "     feature_maps : 4\n",
      "     feature_maps shape  : (?, 32, 32, 256)\n",
      "     feature_maps shape  : (?, 16, 16, 256)\n",
      "     feature_maps shape  : (?, 8, 8, 256)\n",
      "     feature_maps shape  : (?, 4, 4, 256)\n",
      "     input_shape         : [128 128   3]\n",
      "     pool_size           : 7\n",
      "\n",
      ">>> FPN Mask Graph \n",
      "     rois shape          : (5, ?, ?)\n",
      "     feature_maps : 4\n",
      "     feature_maps shape  : (?, 32, 32, 256)\n",
      "     feature_maps shape  : (?, 16, 16, 256)\n",
      "     feature_maps shape  : (?, 8, 8, 256)\n",
      "     feature_maps shape  : (?, 4, 4, 256)\n",
      "     input_shape         : [128 128   3]\n",
      "     pool_size           : 14\n",
      "     FPN Mask Graph output shape : (?, 32, 28, 28, 4)\n",
      "\n",
      ">>> PCN Layer TF \n",
      "   > PCNLayerTF Call()  5\n",
      "     mrcnn_class.shape    : (?, 32, 4) (None, 32, 4)\n",
      "     mrcnn_bbox.shape     : (?, 32, 4, 4) (None, 32, 4, 4)\n",
      "     output_rois.shape    : (5, ?, ?) (None, 32, 4)\n",
      "     gt_class_ids.shape   : (?, ?) (None, None)\n",
      "     gt_bboxes.shape      : (?, ?, 4) (None, None, 4)\n",
      "\n",
      "  > BUILD_PREDICTIONS_TF()\n",
      "    num_rois          :  32\n",
      "    mrcnn_class shape :  Tensor(\"cntxt_layer/Shape:0\", shape=(3,), dtype=int32) (None, 32, 4)\n",
      "    mrcnn_bbox.shape  :  Tensor(\"cntxt_layer/Shape_1:0\", shape=(4,), dtype=int32) (None, 32, 4, 4) (?, 32, 4, 4)\n",
      "    output_rois.shape :  Tensor(\"cntxt_layer/Shape_2:0\", shape=(3,), dtype=int32) (5, None, 4)\n",
      "    pred_classes     :  (?, 32)\n",
      "    pred_classes_exp :  (?, 32, 1)\n",
      "    pred_scores      :  (?, 32, 1)\n",
      "    batch_grid       :  (5, 32)\n",
      "    roi_grid         :  (5, 32)\n",
      "    bbox_idx         :  (5, 32, 1)\n",
      "\n",
      "    -- pred_tensor tf ------------------------------\n",
      "    pred_array shape: (5, 32, 6)\n",
      "    pred_scatter shape is  (5, 4, 32, 6) Tensor(\"cntxt_layer/ScatterNd:0\", shape=(5, 4, 32, 6), dtype=float32)\n",
      "    sort inds shape :  (5, 4, 32)\n",
      "    class_grid   <class 'tensorflow.python.framework.ops.Tensor'> shape (5, 4, 32)\n",
      "    batch_grid   <class 'tensorflow.python.framework.ops.Tensor'> shape (5, 4, 32)\n",
      "    roi_grid shape (5, 4, 32) roi_grid_exp shape  (5, 4, 32, 1)\n",
      "    gather_inds  <class 'tensorflow.python.framework.ops.Tensor'> shape (5, 4, 32, 3)\n",
      "    pred_tensor (gathered)  :  (5, 4, 32, 6)\n",
      "    -- pred_tensor results (bboxes sorted by score) ----\n",
      "    final pred_tensor shape  :  (5, 4, 32, 6)\n",
      "    final pred_cls_cnt shape :  (5, 4)\n",
      "    complete\n",
      "\n",
      "\n",
      "  > BUILD_GROUND TRUTH_TF()\n",
      "    gt_class_ids shape :  (?, ?)     notm_gt_bbox.shape  :  (?, ?, 4)\n",
      "    gt_classes_exp shape  (?, ?, 1)\n",
      "    pred_ scores shape  (?, ?)\n",
      "    bbox_idx shape     (5, 100, 1)\n",
      "    gt_array shape     (?, ?, 6)\n",
      "    bbox_grid  shape   (5, 100)\n",
      "    batch_grid shape   (5, 100)\n",
      "    scatter_ind shape  (5, 100, 3)\n",
      "    gt_scatter shape  (5, 4, 100, 6)\n",
      "    build gathering indexes to use in sorting -------\n",
      "    sort inds shape :  (5, 4, 100)\n",
      "    class_grid  shape  (5, 4, 100)\n",
      "    batch_grid  shape  (5, 4, 100)\n",
      "    bbox_grid   shape  (5, 4, 100)  bbox_grid_exp shape  (5, 4, 100, 1)\n",
      "    gather_inds shape      :  (5, 4, 100, 3)\n",
      "    gt_tensor (gathered)   :  (5, 4, 100, 6)\n",
      "    final gt_tensor shape  :  (5, 4, 100, 6)\n",
      "    final gt_cls_cnt shape :  (5, 4)\n",
      "    complete\n",
      "\n",
      " \n",
      "  > BUILD_GAUSSIAN_TF() for  ['pred_gaussian']\n",
      "    orignal in_tensor shape :  (5, 4, 32, 6)\n",
      "    modified in_tensor shape :  (5, 4, 32, 6)\n",
      "    num of bboxes per class is :  Tensor(\"cntxt_layer/ToInt32_1/x:0\", shape=(), dtype=int32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    after transpose  (128, 128, 5, 32, 2)\n",
      "    pt2_sum shape  (5, 4, 32)\n",
      "    dense shape  (?, 6)\n",
      "    Build Stacked output from dynamically partitioned lists --------------\n",
      "    >> input to MVN.PROB: pos_grid (meshgrid) shape:  (128, 128, 5, 32, 2)\n",
      "    << output probabilities shape: (5, 32, 128, 128)\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    gaussian_grid      :  (5, 32, 128, 128)\n",
      "    class shape        :  (5, ?)\n",
      "    roi_grid shape     :  (5, 32)\n",
      "    batch_grid shape   :  (5, 32)\n",
      "    scatter_classes    :  (5, 32, 3)\n",
      "    gaussian scattered :  (5, 4, 32, 128, 128)\n",
      "\n",
      "    Reduce sum based on class ---------------------------------------------\n",
      "    gaussian sum type/name :  <class 'tensorflow.python.framework.ops.Tensor'> cntxt_layer/pred_gaussian_1:0 pred_gaussian\n",
      "    gaussian_sum shape     :  (5, 128, 128, 4) Keras tensor  False\n",
      "\n",
      " \n",
      "  > BUILD_GAUSSIAN_TF() for  ['gt_gaussian']\n",
      "    orignal in_tensor shape :  (5, 4, 100, 6)\n",
      "    modified in_tensor shape :  (5, 4, 100, 6)\n",
      "    num of bboxes per class is :  Tensor(\"cntxt_layer/ToInt32_4/x:0\", shape=(), dtype=int32)\n",
      "    after transpose  (128, 128, 5, 100, 2)\n",
      "    pt2_sum shape  (5, 4, 100)\n",
      "    dense shape  (?, 6)\n",
      "    Build Stacked output from dynamically partitioned lists --------------\n",
      "    >> input to MVN.PROB: pos_grid (meshgrid) shape:  (128, 128, 5, 100, 2)\n",
      "    << output probabilities shape: (5, 100, 128, 128)\n",
      "\n",
      "    Scatter out the probability distributions based on class --------------\n",
      "    gaussian_grid      :  (5, 100, 128, 128)\n",
      "    class shape        :  (5, ?)\n",
      "    roi_grid shape     :  (5, 100)\n",
      "    batch_grid shape   :  (5, 100)\n",
      "    scatter_classes    :  (5, 100, 3)\n",
      "    gaussian scattered :  (5, 4, 100, 128, 128)\n",
      "\n",
      "    Reduce sum based on class ---------------------------------------------\n",
      "    gaussian sum type/name :  <class 'tensorflow.python.framework.ops.Tensor'> cntxt_layer/gt_gaussian:0 gt_gaussian\n",
      "    gaussian_sum shape     :  (5, 128, 128, 4) Keras tensor  False\n",
      "\n",
      "    Output build_gaussian_tf \n",
      "     pred_gaussian :  (5, 128, 128, 4) Keras tensor  False\n",
      "     gt_gaussian   :  (5, 128, 128, 4) Keras tensor  False\n",
      "<<<  shape of pred_gaussian   :  (5, 128, 128, 4)  Keras tensor  True\n",
      "<<<  shape of gt_gaussian     :  (5, 128, 128, 4)  Keras tensor  True\n",
      "\n",
      ">>> FCN Layer \n",
      "     feature map shape is  (5, 128, 128, 4)\n",
      "     height : 128 width : 128 classes : 4\n",
      "     image_data_format     channels_last\n",
      "   FCN Block 11 shape is :  (5, 128, 128, 64)\n",
      "   FCN Block 12 shape is :  (5, 128, 128, 64)\n",
      "   FCN Block 13 shape is :  (5, 64, 64, 64)\n",
      "   FCN Block 21 shape is :  (5, 64, 64, 128)\n",
      "   FCN Block 22 shape is :  (5, 64, 64, 128)\n",
      "   FCN Block 23 (Max pooling) shape is :  (5, 32, 32, 128)\n",
      "   FCN Block 31 shape is :  (5, 32, 32, 256)\n",
      "   FCN Block 32 shape is :  (5, 32, 32, 256)\n",
      "   FCN Block 33 shape is :  (5, 32, 32, 256)\n",
      "   FCN Block 34 (Max pooling) shape is :  (5, 16, 16, 256)\n",
      "   FCN fully connected 1 (fcn_fc1) shape is :  (5, 16, 16, 2048)\n",
      "   FCN fully connected 2 (fcn_fc2) shape is :  (5, 16, 16, 2048)\n",
      "   FCN final conv2d (fcn_classify) shape is :  (None, 16, 16, 4)\n",
      "   h_factor :  8.0 w_factor :  8.0\n",
      "\n",
      ">>> BilinearUpSampling2D layer\n",
      "     data_format :  channels_last\n",
      "     size        :  (8.0, 8.0)\n",
      "     target_size :  None\n",
      "     input_spec  :  [InputSpec(ndim=4)]\n",
      "     call resize_images_bilinear with size:  (8.0, 8.0)\n",
      "     CHANNELS LAST: X:  (5, 16, 16, 4)  KB.int_shape() :  (None, 16, 16, 4)\n",
      "     target_height   :  None  target_width  :  None\n",
      "     new_shape (2):  (2,) (2,)\n",
      "     new_shape (3):  (2,) (2,)\n",
      "     X after image.resize_bilinear:  (5, ?, ?, 4)\n",
      "     Dimensions of X after set_shape() :  (5, 128, 128, 4)\n",
      "    BilinearUpSampling2D. compute_output_shape()\n",
      "   FCN output (fcn_bilinear) shape is :  (5, 128, 128, 4) Keras tensor  True\n",
      "   fcn_output  shape is :  (None, 128, 128, 4)  Keras tensor  True\n",
      "\n",
      ">>> rpn_bbox_loss_graph\n",
      "    rpn_match size : (?, ?)\n",
      "    rpn_bbox  size : (?, ?, 4)\n",
      "    tf default session:  None\n",
      "\n",
      ">>> rpn_bbox_loss_graph\n",
      "    rpn_match size : (?, ?)\n",
      "    rpn_bbox  size : (?, ?, 4)\n",
      "    tf default session:  None\n",
      "\n",
      ">>> mrcnn_class_loss_graph \n",
      "    target_class_ids  size : (5, ?)\n",
      "    pred_class_logits size : (?, 32, 4)\n",
      "    active_class_ids  size : (?, ?)\n",
      "\n",
      ">>> mrcnn_class_loss_graph \n",
      "    target_class_ids  size : (?, 1)\n",
      "    pred_class_logits size : (?, 32, 4)\n",
      "    active_class_ids  size : (?, ?)\n",
      "\n",
      ">>> mrcnn_bbox_loss_graph \n",
      "    target_class_ids  size : (5, ?)\n",
      "    pred_bbox size         : (?, 32, 4, 4)\n",
      "    target_bbox size       : (5, ?, ?)\n",
      "\n",
      ">>> mrcnn_bbox_loss_graph \n",
      "    target_class_ids  size : (?, 1)\n",
      "    pred_bbox size         : (?, 32, 4, 4)\n",
      "    target_bbox size       : (?, 32, 4)\n",
      "\n",
      ">>> mrcnn_mask_loss_graph \n",
      "    target_class_ids shape : (5, ?)\n",
      "    target_masks     shape : (5, ?, ?, ?)\n",
      "    pred_masks       shape : (?, 32, 28, 28, 4)\n",
      "    target_class_ids shape : (?,)\n",
      "    target_shape       shape : (4,)\n",
      "    target_masks     shape : (?, ?, ?)\n",
      "    pred_shape       shape : (5,)\n",
      "    pred_masks       shape : (?, ?, ?, ?)\n",
      "     y_true shape: (?, ?, ?)\n",
      "     y_pred shape: (?, ?, ?)\n",
      "     final loss shape: (1, 1) <class 'tensorflow.python.framework.ops.Tensor'> False\n",
      "\n",
      ">>> mrcnn_mask_loss_graph \n",
      "    target_class_ids shape : (?, 1)\n",
      "    target_masks     shape : (?, 32, 28, 28)\n",
      "    pred_masks       shape : (?, 32, 28, 28, 4)\n",
      "    target_class_ids shape : (?,)\n",
      "    target_shape       shape : (4,)\n",
      "    target_masks     shape : (?, ?, ?)\n",
      "    pred_shape       shape : (5,)\n",
      "    pred_masks       shape : (?, ?, ?, ?)\n",
      "     y_true shape: (?, ?, ?)\n",
      "     y_pred shape: (?, ?, ?)\n",
      "     final loss shape: (1, 1) <class 'tensorflow.python.framework.ops.Tensor'> False\n",
      "\n",
      "\n",
      "---------------------------------------------------\n",
      "    building fcn_loss\n",
      "---------------------------------------------------\n",
      "\n",
      ">>> fcn_loss_graph \n",
      "    target_masks     shape : (5, 128, 128, 4) Tensor(\"fcn_loss/Shape:0\", shape=(4,), dtype=int32)\n",
      "    target_masks is keras tensor: True\n",
      "    pred_masks       shape : (5, 128, 128, 4) Tensor(\"fcn_loss/Shape_1:0\", shape=(4,), dtype=int32)\n",
      "    pred_masks is keras tensor: True\n",
      "    target_shape       shape : (4,)\n",
      "    target_masks     shape : (?, ?, ?)\n",
      "    pred_shape       shape : (4,)\n",
      "    pred_masks       shape : (?, ?, ?)\n",
      "    loss is keras tensor: False\n",
      "    loss type is : <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "\n",
      ">>> fcn_loss_graph \n",
      "    target_masks     shape : (?, 128, 128, 4) Tensor(\"fcn_loss/Shape_4:0\", shape=(4,), dtype=int32)\n",
      "    target_masks is keras tensor: False\n",
      "    pred_masks       shape : (?, 128, 128, 4) Tensor(\"fcn_loss/Shape_5:0\", shape=(4,), dtype=int32)\n",
      "    pred_masks is keras tensor: False\n",
      "    target_shape       shape : (4,)\n",
      "    target_masks     shape : (?, ?, ?)\n",
      "    pred_shape       shape : (4,)\n",
      "    pred_masks       shape : (?, ?, ?)\n",
      "    loss is keras tensor: False\n",
      "    loss type is : <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---------------------------------------------------\n",
      "    building fcn_norm_loss\n",
      "---------------------------------------------------\n",
      "\n",
      ">>> fcn_norm_loss_graph \n",
      "    target_masks     shape : (5, 128, 128, 4)\n",
      "    pred_masks       shape : (5, 128, 128, 4)\n",
      "\n",
      "    L2 normalization ------------------------------------------------------\n",
      " pred_shape: KB.shape: Tensor(\"fcn_norm_loss/Shape:0\", shape=(4,), dtype=int32)  tf.get_shape():  (5, 128, 128, 4)  pred_maks.shape: (5, 128, 128, 4) tf.shape : Tensor(\"fcn_norm_loss/Shape_1:0\", shape=(4,), dtype=int32)\n",
      "WARNING:tensorflow:From D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3157: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "   output_flatten    :  (None, None, None) (?, ?, ?)  Keras tensor  False\n",
      "   output_norm1      :  (None, None, None) (?, ?, ?)  Keras tensor  False\n",
      "   output_norm final :  (5, 128, 128, 4) (5, 128, 128, 4)  Keras tensor  False\n",
      "\n",
      "    L2 normalization ------------------------------------------------------\n",
      " target shape is : Tensor(\"fcn_norm_loss/Shape_2:0\", shape=(4,), dtype=int32)     (5, 128, 128, 4) (5, 128, 128, 4) Tensor(\"fcn_norm_loss/Shape_3:0\", shape=(4,), dtype=int32)\n",
      "    guass_flatten         :  (?, ?, ?) (?, ?, ?) Keras tensor  False\n",
      "    gauss_norm shape      :  (?, ?, ?) (?, ?, ?) Keras tensor  False\n",
      "    gauss_norm final shape:  (5, 128, 128, 4) (5, 128, 128, 4) Keras tensor  False\n",
      "    target_masks1 shape : (?, ?, ?) (None, None, None)\n",
      "    pred_masks1  shape : (?, ?, ?)\n",
      "    loss type is : <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "\n",
      ">>> fcn_norm_loss_graph \n",
      "    target_masks     shape : (?, 128, 128, 4)\n",
      "    pred_masks       shape : (?, 128, 128, 4)\n",
      "\n",
      "    L2 normalization ------------------------------------------------------\n",
      " pred_shape: KB.shape: Tensor(\"fcn_norm_loss/Shape_4:0\", shape=(4,), dtype=int32)  tf.get_shape():  (?, 128, 128, 4)  pred_maks.shape: (?, 128, 128, 4) tf.shape : Tensor(\"fcn_norm_loss/Shape_5:0\", shape=(4,), dtype=int32)\n",
      "   output_flatten    :  (None, None, None) (?, ?, ?)  Keras tensor  False\n",
      "   output_norm1      :  (None, None, None) (?, ?, ?)  Keras tensor  False\n",
      "   output_norm final :  (None, 128, 128, 4) (?, 128, 128, 4)  Keras tensor  False\n",
      "\n",
      "    L2 normalization ------------------------------------------------------\n",
      " target shape is : Tensor(\"fcn_norm_loss/Shape_6:0\", shape=(4,), dtype=int32)     (?, 128, 128, 4) (?, 128, 128, 4) Tensor(\"fcn_norm_loss/Shape_7:0\", shape=(4,), dtype=int32)\n",
      "    guass_flatten         :  (?, ?, ?) (?, ?, ?) Keras tensor  False\n",
      "    gauss_norm shape      :  (?, ?, ?) (?, ?, ?) Keras tensor  False\n",
      "    gauss_norm final shape:  (?, 128, 128, 4) (?, 128, 128, 4) Keras tensor  False\n",
      "    target_masks1 shape : (?, ?, ?) (None, None, None)\n",
      "    pred_masks1  shape : (?, ?, ?)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    loss type is : <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "\n",
      " Keras Tensors?? \n",
      " pred_gaussian : True\n",
      " gt_gaussian   : True\n",
      " mask_loss     : True\n",
      " rpn_rois      : True\n",
      " fcn_loss      : True\n",
      " fcn_norm_loss : True\n",
      ">>> MaskRCNN build complete\n",
      ">>> MaskRCNN initialization complete\n"
     ]
    }
   ],
   "source": [
    "try :\n",
    "    del model\n",
    "    print('delete model is successful')\n",
    "    gc.collect()\n",
    "except: \n",
    "    pass\n",
    "KB.clear_session()\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T14:39:40.038228Z",
     "start_time": "2018-05-03T14:39:28.180500Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('E:\\\\Models\\\\mrcnn_logs\\\\shapes20180428T1819', 'E:\\\\Models\\\\mrcnn_logs\\\\shapes20180428T1819\\\\mask_rcnn_shapes_5784.h5')\n",
      ">>> load_weights()\n",
      "    load_weights: Loading weights from: E:\\Models\\mrcnn_logs\\shapes20180428T1819\\mask_rcnn_shapes_5784.h5\n",
      "    load_weights: Log directory set to : E:\\Models\\mrcnn_logs\\shapes20180428T1819\\mask_rcnn_shapes_5784.h5\n",
      "    set_log_dir: Checkpoint path set to : E:\\Models\\mrcnn_logs\\shapes20180428T1819\\mask_rcnn_shapes_{epoch:04d}.h5\n",
      "    set_log_dir: self.epoch set to 5785 \n",
      "    Load weights complete :  E:\\Models\\mrcnn_logs\\shapes20180428T1819\\mask_rcnn_shapes_5784.h5\n",
      "Load weights complete\n"
     ]
    }
   ],
   "source": [
    "print(model.find_last())\n",
    "# Which weights to start with?\n",
    "init_with = \"last\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "#     loc=model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "    loc=model.load_weights(RESNET_MODEL_PATH, by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    \n",
    "    # See README for instructions to download the COCO weights\n",
    "    loc=model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    loc= model.load_weights(model.find_last()[1], by_name=True)\n",
    "print('Load weights complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false
   },
   "source": [
    "###  Print some model information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T14:39:40.300936Z",
     "start_time": "2018-05-03T14:39:40.041235Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Outputs: \n",
      "[ <tf.Tensor 'output_rois/mul:0' shape=(5, ?, ?) dtype=float32>,\n",
      "  <tf.Tensor 'proposal_targets/target_class_ids:0' shape=(5, ?) dtype=int32>,\n",
      "  <tf.Tensor 'proposal_targets/target_bbox_deltas:0' shape=(5, ?, ?) dtype=float32>,\n",
      "  <tf.Tensor 'proposal_targets/target_mask:0' shape=(5, ?, ?, ?) dtype=float32>,\n",
      "  <tf.Tensor 'rpn_class_logits/concat:0' shape=(?, ?, 2) dtype=float32>,\n",
      "  <tf.Tensor 'proposal_rois/packed_2:0' shape=(5, ?, ?) dtype=float32>,\n",
      "  <tf.Tensor 'rpn_class/concat:0' shape=(?, ?, 2) dtype=float32>,\n",
      "  <tf.Tensor 'rpn_bbox/concat:0' shape=(?, ?, 4) dtype=float32>,\n",
      "  <tf.Tensor 'mrcnn_class_logits/Reshape_1:0' shape=(?, 32, 4) dtype=float32>,\n",
      "  <tf.Tensor 'mrcnn_class/Reshape_1:0' shape=(?, 32, 4) dtype=float32>,\n",
      "  <tf.Tensor 'mrcnn_bbox/Reshape:0' shape=(?, 32, 4, 4) dtype=float32>,\n",
      "  <tf.Tensor 'mrcnn_mask/Reshape_1:0' shape=(?, 32, 28, 28, 4) dtype=float32>,\n",
      "  <tf.Tensor 'fcn_bilinear/ResizeBilinear:0' shape=(5, 128, 128, 4) dtype=float32>,\n",
      "  <tf.Tensor 'rpn_class_loss/cond/Merge:0' shape=() dtype=float32>,\n",
      "  <tf.Tensor 'rpn_bbox_loss/Mean:0' shape=() dtype=float32>,\n",
      "  <tf.Tensor 'mrcnn_class_loss/Reshape:0' shape=(1, 1) dtype=float32>,\n",
      "  <tf.Tensor 'mrcnn_bbox_loss/Reshape_3:0' shape=(1, 1) dtype=float32>,\n",
      "  <tf.Tensor 'mrcnn_mask_loss/Reshape_3:0' shape=(1, 1) dtype=float32>,\n",
      "  <tf.Tensor 'cntxt_layer/pred_gaussian_1:0' shape=(5, 128, 128, 4) dtype=float32>,\n",
      "  <tf.Tensor 'cntxt_layer/gt_gaussian:0' shape=(5, 128, 128, 4) dtype=float32>,\n",
      "  <tf.Tensor 'fcn_loss/Reshape_2:0' shape=(1, 1) dtype=float32>,\n",
      "  <tf.Tensor 'fcn_norm_loss/Reshape_6:0' shape=(1, 1) dtype=float32>,\n",
      "  <tf.Tensor 'cntxt_layer/pred_tensor:0' shape=(5, 4, 32, 6) dtype=float32>,\n",
      "  <tf.Tensor 'cntxt_layer/gt_tensor:0' shape=(5, 4, 100, 6) dtype=float32>,\n",
      "  <tf.Tensor 'proposal_targets/roi_gt_boxes:0' shape=(5, ?, ?) dtype=float32>]\n",
      "\n",
      " Losses (model.metrics_names): \n"
     ]
    }
   ],
   "source": [
    "#model.keras_model.summary(line_length = 120) \n",
    "# model.compile_only(learning_rate=config.LEARNING_RATE, layers='heads')\n",
    "# KB.set_learning_phase(1)\n",
    "print('\\n Outputs: ') \n",
    "pp.pprint(model.keras_model.outputs)\n",
    "print('\\n Losses (model.metrics_names): ') \n",
    "# pp.pprint(model.keras_model.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T14:39:40.573651Z",
     "start_time": "2018-05-03T14:39:40.302932Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.keras_model.summary(line_length = 150) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Define Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T14:39:40.839357Z",
     "start_time": "2018-05-03T14:39:40.575658Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_generator = data_generator(dataset_train, model.config, shuffle=True,\n",
    "                                 batch_size=model.config.BATCH_SIZE,\n",
    "                                 augment = False)\n",
    "val_generator = data_generator(dataset_val, model.config, shuffle=True, \n",
    "                                batch_size=model.config.BATCH_SIZE,\n",
    "                                augment=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Get next shapes from generator and display loaded shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T14:39:41.176251Z",
     "start_time": "2018-05-03T14:39:40.841363Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_batch_x, train_batch_y = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T14:39:42.740421Z",
     "start_time": "2018-05-03T14:39:41.178258Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Image id:  132\n",
      "Image meta [132 128 128   3   0   0 128 128   1   1   1   1]\n",
      "Classes (1: circle, 2: square, 3: triangle ):  [2 2]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23ecb7a1b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image id:  116\n",
      "Image meta [116 128 128   3   0   0 128 128   1   1   1   1]\n",
      "Classes (1: circle, 2: square, 3: triangle ):  [1 2]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAysAAACoCAYAAADgm3G3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAACy9JREFUeJzt3W+sJXddx/HP2ooUEammgdSkMVBplSeVpBSCDqM8GKs0NI0RYkWwIiak/GlBEh7UxmBtaa2tulVsIKsPLAiFJmIIoyk7OxUDrkpDTIgbWRoCFJR0wdZSqPT6YOba62X37t1295zvuff1Sjb37pwzc35388s5531+M3f3rK2tBQAAoJrvWfYAAAAAjkasAAAAJYkVAACgJLECAACUJFYAAICSxAoAAFDS6csewLK1TdcmuXQY+7ds2HbvMPYXbHP/TyS5bBj7r7ZNd0WS3x3G/uz5ttuSfHgY+7uPse/3JRmSXDyM/dfbpjsvye1JTkvymWHs39A23blJ/mLe9lfD2N+yxVhekaQdxv6q+e/vTPKzSfYkeeMw9v/cNt3vJPm5JA8nuXwY+y9v5+cEOBnapnvPMPavO859XpvkmcPY37qYUQFQlZWVJ+9Akovm738myafapnv+/PcXJPmHo+3UNt05Se5O8pwNm69N8tZh7H8qyTPapntRkiuTvCvJi5Nc3jbd049xvKuT3JgpTNI23fOSXDCM/UuS/GqS69qme2aSlyd5UZI/TvKmJ/QTAzxBxwsVANho16+sbEfbdNdkioA/SvJ3Sbph7B+Ybz6QpEny10nOTvLuJC9rm+6+JA8PY//NtumGTYd8S5JvJbki00rKujcn+dr8/elJHk3yL0nOTPKUefujbdP9bZLr5mNcM4z9LyQ5lOQNSS6Z7/f5TJGy8VjfSHL/fKynJ3nwhP8xKG1eKbwhyVqSDyT5epI3JvlcknOGsb9ono+Xzqt5Q5JLk5w77/e9mebFK5JckymSk+RXkuzLNG++kOSKYez/ZzE/FausbbpnJPnLJGcl+UqS84ax//G26T6Z6Tmpz/S8dHWm56rf3rDvniR/kuQnMj9nDmP/xcX+BAAsk1iZ/GLbdFud9nV9knuSXJjk2g2hkiSfSHJV23TnJ/m3TKd1/VmSzyT5+yQZxr491oHbpvu/74ex/8952yuTPG0+beusTKeBXZvkrmHsv9U23euTvG997PO+fzO/UV0/1qNJjswrMe9J8rZMb0QfS/LZJGdkWmFhZ7kkyS1JPpjkNZneAF6Y5IeS/NMW+52f5DXD2H+pbbq7Mr05TJL9w9jf0DbdHyR59zzP3pHklZnegMLxvDbJx4axv61tul9PcvG8/VmZovkrbdPdm+n56GlJfjNTvCTTfP7vYexf2jbdizM9D/7GQkcPwFI5DWxy5zD27fqfzTfOnyD/eZLnJ/nYptseyvTv+LIkH5+D4/szvfAOSdI23bDpzzHDqG26V2d6sb583nRdptPLzk1yTtt0LxnG/r4k9yU5NIz9l7Y41plJPprk1mHsP5npWpWHkjx3/v72Y+3LyrohyU8n+XimT7K/OIz9I/O1SYePcv8989f7k9zSNt2+TPPjtHn7ofnr+UnesWEl5kdOzfDZgc7LHMrD2L8304clSfLgHCpnJbl/nqcPDGN//YZ9z09y8TzvbkjywwscN7tI23Q3zq/PNy57LOxe5uHRWVnZhrbpfjDJ65K8P8lVSW7edJd7k7w60/UgybTC8vNJbk22XlnZ9DiXZPo0/OXD2D88b/5GkoeGsX+sbbr/yHQtywszBdEPtE33wmHs//EoxzotyUeSvGsY+4/Mmx/M9CnlWtt0X810Sg87y6syxem/t0336Uzz5YwkT01yznyfR5I8u226b+fxa6ZuTtIleSDJp/J4xDw2f/1ckg8MY39P23Tr0QvbcTjJBZmu57s6j4fw+tx6IMnZbdM9JdPq775MH7Ik07x7/zD272yb7rmZTrmFk24Y+7cvewxgHh6dlZXtuTnJ72c6BeGX2qb7sU23H0jy1GHs16832Z/kO8PYP3KCj/N7mT45/Ohc1i9N8vYk72ub7p5ML+R3J7kt0/Utb0py2/wiv9mlmVaC3jofa98w9vuTPDL/BrMPZTo1jJ3l3iR3zp9E7890GtiQ6Q3gt+f7/GmSOzOdSnjfvO2DmVZj9if5ryTP3nTc6zOtrNyTKdg/G9ie2/P46shF2fS6M4z9dzKtIB/I9Pz23g0335XkR9umO5Bpvv7rIgYMQB171tbWlj0GYAFO5FdyAwBUYGUFAAAoycoKAABQkpUVAACgJLECAACUJFYAAICSyvw/K+Ov/eFKXzzz4eeNyx7CSXHZocX8NwbNvjfvOf69Fu+Mn7xypefhkYN7lz2Ek+LMC69cyON889N7y83DVZ+DnJiKczAxD3ebivPQHNxdtpqDVlYAAICSxAoAAFCSWAEAAEoSKwAAQEliBQAAKEmsAAAAJYkVAACgJLECAACUJFYAAICSxAoAAFCSWAEAAEoSKwAAQEliBQAAKEmsAAAAJYkVAACgJLECAACUJFb4f246fMeyhwCwdEcO7l32EACIWOEobjp8h2gBdr0jB/eKFoAlEysck2ABsMoCsExihS0JFgDBArAsYoXjEiwAggVgGcQK2yJYAAQLwKKJFbZNsAAIFoBFEiucEMECIFgAFkWsAAAAJYkVTpjVFQCrKwCLIFYAAICSxAoAAFCSWOEJcSoYgFPBAE41sQIAAJQkVgAAgJLECk+YU8EAnAoGcCqJFQAAoCSxAgAAlCRWAACAksQKAABQklgBAABKEisAAEBJYoUnxa8vBvDriwFOFbHCk/Jbz/nlZQ8BYOnOvPDKZQ8BYEcSKwAAQEliBQAAKEmsAAAAJZ2+7AHsFJcdak54Hxenc7I5b55V5OJ0AI7FygoAAFCSWFmiVf9NWqs+fqCGVV8RXPXxA1QmVgAAgJLECgAAUJJYWbJVPZVqVccN1LSqp1Kt6rgBVoVYAQAAShIrBVilALBKAcB3EytFrFKwrNJYgdWySsGySmMFWFViBQAAKEmsFLIKKxarMEZgta3CisUqjBFgJxArxVSOgcpjA3aWyjFQeWwAO41YKahiFFQcE7CzVYyCimMC2MnESlGV4qDSWIDdpVIcVBoLwG4hVgqrEAkVxgDsbhUiocIYAHYjsVLcMmNBqABVLDMWhArA8py+7AFwfOvRcNPhOxb6eACVrEfDkYN7F/p4ACyPlZUVsoiIECpAdYuICKECUIOVlRVzqlZZRAqwSk7VKotIAahFrKyokxEtAgVYdScjWgQKQF1iZcVtFRw3Hb5DkAC7wlbBceTgXkECsKJcs7KDCRUAKycAq0ysAAAAJYkVAACgJLECAACUJFYAAICSxAoAAFCSWAEAAEoSKwAAQEliBQAAKEmsAAAAJYkVAACgJLECAACUJFYAAICSxAoAAFCSWAEAAEoSKwAAQEliBQAAKEmsAAAAJYkVAACgJLECAACUJFYAAICSxAoAAFCSWAEAAEoSKwAAQEliBQAAKEmsAAAAJYkVAACgJLECAACUJFYAAICSxAoAAFCSWAEAAEoSKwAAQEliBQAAKEmsAAAAJYkVAACgJLECAACUJFYAAICSxAoAAFCSWAEAAEoSKwAAQEliBQAAKEmsAAAAJYkVAACgJLECAACUJFYAAICSxAoAAFCSWAEAAEoSKwAAQEliBQAAKEmsAAAAJYkVAACgJLECAACUJFYAAICSxAoAAFCSWAEAAEoSKwAAQEliBQAAKEmsAAAAJe1ZW1tb9hgAAAC+i5UVAACgJLECAACUJFYAAICSxAoAAFCSWAEAAEoSKwAAQEliBQAAKEmsAAAAJYkVAACgJLECAACUJFYAAICSxAoAAFCSWAEAAEoSKwAAQEliBQAAKEmsAAAAJYkVAACgJLECAACUJFYAAICSxAoAAFCSWAEAAEoSKwAAQEliBQAAKEmsAAAAJf0vLdCCcdbPaLYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23ecb8199e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image id:  109\n",
      "Image meta [109 128 128   3   0   0 128 128   1   1   1   1]\n",
      "Classes (1: circle, 2: square, 3: triangle ):  [3 3]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23f5467cdd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image id:  294\n",
      "Image meta [294 128 128   3   0   0 128 128   1   1   1   1]\n",
      "Classes (1: circle, 2: square, 3: triangle ):  [3 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23f55f49128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image id:  448\n",
      "Image meta [448 128 128   3   0   0 128 128   1   1   1   1]\n",
      "Classes (1: circle, 2: square, 3: triangle ):  [1 2 3 3]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23ecd02d5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train_batch_x, train_batch_y = next(train_generator)\n",
    "imgmeta_idx = model.keras_model.input_names.index('input_image_meta')\n",
    "print(imgmeta_idx)\n",
    "img_meta    = train_batch_x[imgmeta_idx]\n",
    "\n",
    "for img_idx in range(config.BATCH_SIZE):\n",
    "    image_id = img_meta[img_idx,0]\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    print('Image id: ',image_id)\n",
    "    print('Image meta', img_meta[img_idx])\n",
    "    print('Classes (1: circle, 2: square, 3: triangle ): ',class_ids)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Push Data thru model using get_layer_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-05-03T14:43:21.703Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/* Inputs */\n",
      "Input 0:  (input_image             ) \t  Input shape: (5, 128, 128, 3)\n",
      "Input 1:  (input_image_meta        ) \t  Input shape: (5, 12)\n",
      "Input 2:  (input_rpn_match         ) \t  Input shape: (5, 4092, 1)\n",
      "Input 3:  (input_rpn_bbox          ) \t  Input shape: (5, 256, 4)\n",
      "Input 4:  (input_gt_class_ids      ) \t  Input shape: (5, 100)\n",
      "Input 5:  (input_gt_boxes          ) \t  Input shape: (5, 100, 4)\n",
      "Input 6:  (input_gt_masks          ) \t  Input shape: (5, 56, 56, 100)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "layers_out = get_layer_output_2(model.keras_model, train_batch_x, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-05-03T14:43:24.995Z"
    }
   },
   "outputs": [],
   "source": [
    "sess=  tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Compute mean/min/max of Pred/GT gaussian tensors and FCN output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:57:00.620812Z",
     "start_time": "2018-05-02T11:56:55.389850Z"
    },
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "fcn_masks  = tf.identity(layers_out[12])\n",
    "pred_masks = tf.identity(layers_out[18])\n",
    "gt_masks   = tf.identity(layers_out[19])\n",
    "shape = KB.int_shape(pred_masks)\n",
    "print(shape)\n",
    "\n",
    "pred_masks_r = tf.reshape(pred_masks, [shape[0], -1, shape[-1]])\n",
    "fcn_masks_r = tf.reshape(fcn_masks, [shape[0], -1, shape[-1]])\n",
    "gt_masks_r  = tf.reshape(gt_masks, [shape[0], -1, shape[-1]])\n",
    "\n",
    "print(gt_masks_r.shape, fcn_masks_r.shape)\n",
    "\n",
    "pred_mean2 = KB.mean(pred_masks_r, axis = 1).eval()\n",
    "pred_max2  =  KB.max(pred_masks_r, axis=1).eval()\n",
    "pred_min2  =  KB.min(pred_masks_r, axis=1).eval()\n",
    "\n",
    "gt_mean2 = KB.mean(gt_masks_r, axis = 1).eval()\n",
    "gt_max2  =  KB.max(gt_masks_r, axis=1).eval()\n",
    "gt_min2  =  KB.min(gt_masks_r, axis=1).eval()\n",
    "\n",
    "fcn_mean2 = KB.mean(fcn_masks_r, axis = 1).eval()\n",
    "fcn_max2  =  KB.max(fcn_masks_r, axis=1).eval()\n",
    "fcn_min2  =  KB.min(fcn_masks_r, axis=1).eval()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute L2 Normalizationof Pred, GT, and FCN tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:57:50.121346Z",
     "start_time": "2018-05-02T11:57:47.648793Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_l2      = KB.l2_normalize(pred_masks_r, axis = 1)\n",
    "gt_l2        = KB.l2_normalize(gt_masks_r, axis = 1)\n",
    "fcn_l2       = KB.l2_normalize(fcn_masks_r, axis = 1)\n",
    "pred_l2_min  = KB.min(pred_l2, axis = 1).eval()\n",
    "pred_l2_max  = KB.max(pred_l2, axis = 1).eval()\n",
    "pred_l2_mean = KB.mean(pred_l2, axis = 1).eval()\n",
    "gt_l2_min    = KB.min(gt_l2, axis = 1).eval()\n",
    "gt_l2_max    = KB.max(gt_l2, axis = 1).eval()\n",
    "gt_l2_mean   = KB.mean(gt_l2, axis = 1).eval()\n",
    "fcn_l2_min   = KB.min(fcn_l2, axis = 1).eval()\n",
    "fcn_l2_max   = KB.max(fcn_l2, axis = 1).eval()\n",
    "fcn_l2_mean  = KB.mean(fcn_l2, axis = 1).eval()\n",
    "\n",
    "print(' Shape of L2 normalized tensor: ',pred_l2.shape, gt_l2.shape, fcn_l2.shape)\n",
    "print(' Shape of L2 min tensor       : ',pred_l2_min.shape, gt_l2_min.shape, fcn_l2_min.shape)\n",
    "print(' Shape of L2 max tensor       : ',pred_l2_max.shape, gt_l2_max.shape, fcn_l2_max.shape)\n",
    "print(' Shape of L2 mean tensor      : ',pred_l2_mean.shape, gt_l2_mean.shape, fcn_l2_mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T19:30:00.463214Z",
     "start_time": "2018-04-30T19:29:58.395080Z"
    }
   },
   "outputs": [],
   "source": [
    "# pred_l2      = tf.nn.l2_normalize(pred_masks_r, axis = 1)\n",
    "# gt_l2        = tf.nn.l2_normalize(gt_masks_r, axis = 1)\n",
    "# fcn_l2       = tf.nn.l2_normalize(fcn_masks_r, axis = 1)\n",
    "# pred_l2_min  = tf.reduce_min(pred_l2, axis = 1).eval()\n",
    "# pred_l2_max  = tf.reduce_max(pred_l2, axis = 1).eval()\n",
    "# pred_l2_mean = tf.reduce_mean(pred_l2, axis = 1).eval()\n",
    "# gt_l2_min    = tf.reduce_min(gt_l2, axis = 1).eval()\n",
    "# gt_l2_max    = tf.reduce_max(gt_l2, axis = 1).eval()\n",
    "# gt_l2_mean   = tf.reduce_mean(gt_l2, axis = 1).eval()\n",
    "# fcn_l2_min   = tf.reduce_min(fcn_l2, axis = 1).eval()\n",
    "# fcn_l2_max   = tf.reduce_max(fcn_l2, axis = 1).eval()\n",
    "# fcn_l2_mean  = tf.reduce_mean(fcn_l2, axis = 1).eval()\n",
    "\n",
    "# print(' Shape of L2 normalized tensor: ',pred_l2.shape, gt_l2.shape, fcn_l2.shape)\n",
    "# print(' Shape of L2 min tensor       : ',pred_l2_min.shape, gt_l2_min.shape, fcn_l2_min.shape)\n",
    "# print(' Shape of L2 max tensor       : ',pred_l2_max.shape, gt_l2_max.shape, fcn_l2_max.shape)\n",
    "# print(' Shape of L2 mean tensor      : ',pred_l2_mean.shape, gt_l2_mean.shape, fcn_l2_mean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Print results of L2 normalization (Mean, Min , Max) vs. Original values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:58:04.116559Z",
     "start_time": "2018-05-02T11:58:03.880152Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img in range(5):\n",
    "    for cls in range(4):\n",
    "        print('\\n I/C:{}/{} '.format(img, cls))\n",
    "        print('             Mean:  gt:{:.5e}  fcn:{: 11.5e}   pred: {:.6f}'\\\n",
    "              .format(gt_mean2[img,cls], fcn_mean2[img,cls], pred_mean2[img,cls]))\n",
    "        print('          L2 Mean:  gt:{:.5e}  fcn:{: 11.5e}   pred: {:.6f}'\\\n",
    "              .format(gt_l2_mean[img,cls], fcn_l2_mean[img,cls], pred_l2_mean[img,cls]))\n",
    "        print('             MAX:   gt:{:.5e}  fcn:{: 11.5e}   pred: {:.5e}' \\\n",
    "              .format(gt_max2[img,cls], fcn_max2[img,cls], pred_max2[img,cls]))\n",
    "        print('          L2 MAX:   gt:{:.5e}  fcn:{: 11.5e}   pred: {:.5e}' \\\n",
    "              .format(gt_l2_max[img,cls], fcn_l2_max[img,cls], pred_l2_max[img,cls]))\n",
    "        print('             MIN:   gt:{:.5e}  fcn:{: 11.5e}   pred: {:.5e}'\\\n",
    "              .format(gt_min2[img,cls], fcn_min2[img,cls], pred_min2[img,cls]))              \n",
    "        print('          L2 MIN:   gt:{:.5e}  fcn:{: 11.5e}   pred: {:.5e}'\\\n",
    "              .format(gt_l2_min[img,cls], fcn_l2_min[img,cls], pred_l2_min[img,cls]))              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print (Mean, Min , Max)  values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:58:34.705338Z",
     "start_time": "2018-05-02T11:58:34.470714Z"
    },
    "hideCode": false,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "print(gt_masks.shape, fcn_masks.shape)\n",
    "\n",
    "for img in range(5):\n",
    "    for cls in range(4):\n",
    "        print('I/C: {}/{}  min/max     gt: [{:.5e} , {:.5e}]       pred: [{:.5e} , {:.5e}]     fcn:[{:.5e} , {:.5e}]   '\\\n",
    "              .format(img, cls,    gt_min2[img,cls], gt_max2[img,cls], pred_min2[img,cls], pred_max2[img,cls] ,\n",
    "                                  fcn_min2[img,cls], fcn_max2[img,cls] ))    \n",
    "        \n",
    "print('\\n\\n')        \n",
    "for img in range(5):\n",
    "    for cls in range(4):\n",
    "        print('I/C:{}/{}  Mean:  gt: {:.5e}   fcn : {:9.5e}   pred : {:.6f}   \\t MAX: gt:{:.5e}  fcn:{:.5e}  pred: {:.5e}'\\\n",
    "              .format(img, cls, gt_mean2[img,cls], fcn_mean2[img,cls], pred_mean2[img,cls], \n",
    "                      gt_max2[img,cls], fcn_max2[img,cls], pred_max2[img,cls]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T13:45:09.321729Z",
     "start_time": "2018-04-27T13:45:07.895936Z"
    }
   },
   "outputs": [],
   "source": [
    "print(tf.shape(pred_masks).eval())\n",
    "shape = tf.shape(pred_masks).eval()\n",
    "pred_masks_r = tf.reshape(pred_masks, [shape[0], -1, shape[-1]])\n",
    "means = KB.mean(pred_masks_r, axis = 1)\n",
    "maxs  = KB.max(pred_masks_r, axis=1)\n",
    "\n",
    "# norms, means2, var = KB.normalize_batch_in_training(pred_masks[, 1.0, 0.0,[0,3])\n",
    "l2_norm = KB.l2_normalize (pred_masks_r,axis = 1)\n",
    "print(pred_masks.shape,pred_masks_r.shape)\n",
    "print(means.shape, maxs.shape)\n",
    "# print(' Shape of BN tensor: ', norms.shape)\n",
    "# print(' Shape of means2 tensor: ', means2.shape)\n",
    "# print(' Shape of var tensor: ', var.shape)\n",
    "print(' Shape of L2 normalized tensor: ',l2_norm.shape)\n",
    "print()\n",
    "np.set_printoptions(linewidth=130, threshold=20000, precision=6)\n",
    "print('norms')\n",
    "print(norms.eval())\n",
    "print('means')\n",
    "print(means.eval())\n",
    "print('maxs')\n",
    "print(maxs.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Show reshaped tensor and original tensor are equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T16:37:25.446823Z",
     "start_time": "2018-04-27T16:37:25.178129Z"
    }
   },
   "outputs": [],
   "source": [
    "p2 = tf.reshape(pred_masks_r, shape)   # reshape flattened back to original shape\n",
    "print(KB.int_shape(pred_masks),KB.int_shape(p2))\n",
    "equal = KB.equal(pred_masks, p2)\n",
    "print(KB.all(equal).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T13:12:19.679083Z",
     "start_time": "2018-04-27T13:12:19.086002Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pt   = layers_out[4]   # pred_gaussian \n",
    "# pt2  = layers_out[10]  # pred_gaussian_2\n",
    "np.set_printoptions(linewidth=130, threshold=20000)\n",
    "gt   =  np.transpose(pred_masks.eval(), [0,3,1,2])\n",
    "gt2  =  np.transpose(p2.eval(), [0,3,1,2])\n",
    "# gt   = np.where(gt > 1e-6,gt,0)\n",
    "# gt2   = np.where(gt2 > 1e-6,gt2,0)\n",
    "print( ' pt shape ', gt.shape, ' pt2.shape ', gt2.shape)\n",
    "\n",
    "for img in range(config.BATCH_SIZE):\n",
    "#     print(' from np ')\n",
    "#     print(pt[img])\n",
    "#     print(' from tensorflow')\n",
    "#     print(pt2[img])\n",
    "    for cls in range(4):\n",
    "        equal = np.equal(gt2[img,cls,:,:] , gt[img, cls,:,:])\n",
    "        print(equal.shape)\n",
    "        print( 'Image ',img,' Class ',cls, '  all equal: ',equal.all())        \n",
    "        print(equal.shape)\n",
    "        \n",
    "        if (~equal.all()):\n",
    "            print('Not Equal: ',~equal)\n",
    "            print( 'Image ',img,' Class ',cls, ' ALL EQUAL: ',equal.all())\n",
    "#             print('\\n -- using numpy      \\n',  gt[img, cls, ~equal])\n",
    "#             print('\\n -- using tensorflow \\n', gt2[img, cls, ~equal])\n",
    "# if not equal display the different between the mismatching rows\n",
    "            for i in range(equal.shape[0]):\n",
    "                if ~equal[i]:\n",
    "                    diff = np.abs(gt2[img, cls, i] - gt[img, cls, i])\n",
    "                    big_error = np.any(diff > 3.0e-9, axis = -1)\n",
    "                    print('   row = ', i, ' rows equal = ',equal[i], '   Big Error (larger than 7.0e-8): ' ,big_error)\n",
    "                    if big_error:\n",
    "                        print(' difference  :', diff )\n",
    "#                     print(' -- using numpy      \\n',gt[img,cls,i])            \n",
    "#                     print(' -- using tensorflow \\n',gt2[img,cls,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Plot Predicted and Ground Truth Probability Heatmaps `pred_gaussian` and `gt_gaussian` (Tensorflow)\n",
    "\n",
    "`pred_gaussian2` and `gt_gaussian2` from Tensorflow PCN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T12:03:50.991894Z",
     "start_time": "2018-05-02T12:03:49.403155Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# gt_heatmap  = layers_out[27]     # gt_gaussiam \n",
    "# pred_heatmap= layers_out[24]  # pred_gaussian\n",
    "gt_heatmap  = layers_out[19]     # gt_gaussiam \n",
    "pred_heatmap= layers_out[18]  # pred_gaussian\n",
    "print('gt_gaussian heatmap shape : ', gt_heatmap.shape, ' pred_gaussian heatmap shape: ', pred_heatmap.shape)\n",
    "num_images = 1 # config.IMAGES_PER_GPU\n",
    "num_classes = config.NUM_CLASSES\n",
    "\n",
    "img = 4\n",
    "\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "print('Classes (1: circle, 2: square, 3: triangle ): ')\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "\n",
    "for cls in range(1,num_classes):\n",
    "    ttl = 'GROUND TRUTH HEATMAP - image :  {} class: {} '.format(img,cls)\n",
    "    print(' *** Zout  ', gt_heatmap[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian( gt_heatmap[img,:,:,cls], title = ttl)\n",
    "    \n",
    "    ttl = 'PREDICTED heatmap  - image :  {} class: {} '.format(img,cls)     \n",
    "    print(' *** pred_heatmap ', pred_heatmap[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian(pred_heatmap[img,:,:,cls], title = ttl)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T20:22:44.443661Z",
     "start_time": "2018-04-30T20:22:44.181416Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred_tensor = layers_out[22]\n",
    "gt_tensor   = layers_out[23]\n",
    "print(pred_tensor.shape)\n",
    "# pt2_sum = tf.reduce_sum(tf.abs(in_tensor[:,:,:,:-1]), axis=-1)\n",
    "pred_tensor[2,:,:,:]\n",
    "# print(pred_tensor[2])\n",
    "# print(gt_tensor.shape)\n",
    "# print(gt_tensor[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T20:22:28.695670Z",
     "start_time": "2018-04-30T20:22:23.406687Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in [2]:\n",
    "    for cls in range(4):\n",
    "        pred_tst = pred_heatmap[img,:,:,cls]\n",
    "        gt_tst = gt_heatmap[img,:,:,cls]\n",
    "        print(pred_tst.shape, gt_tst.shape)\n",
    "        print('img/cls :', img,cls, 'pred sum : ',tf.reduce_sum(pred_tst).eval(), 'gt sum : ',tf.reduce_sum(gt_tst).eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Plot Output from FCN network `fcn_bilinear` and compare with `pred_gaussian`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T12:41:20.682566Z",
     "start_time": "2018-05-03T12:41:15.046586Z"
    },
    "hideCode": false,
    "hideOutput": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mrcnn.visualize import plot_gaussian\n",
    "import matplotlib as plt\n",
    "\n",
    "%matplotlib inline\n",
    "img = 3\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "print('Classes (1: circle, 2: square, 3: triangle ): ')\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "\n",
    "Zout  = layers_out[18]     # gt_gaussiam \n",
    "Zout2 = layers_out[12]     # fcn_bilinear\n",
    "\n",
    "print(Zout.shape, Zout2.shape)\n",
    "num_images = config.IMAGES_PER_GPU\n",
    "num_classes = config.NUM_CLASSES\n",
    "\n",
    "\n",
    "for cls in range(num_classes):\n",
    "    ttl = 'GroundTruth - image :  {} class: {} '.format(img,cls)\n",
    "    print(' *** Zout  ', Zout[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian( Zout[img,:,:,cls], title = ttl)\n",
    "    \n",
    "    ttl = 'FCN_Bilinear- image :  {} class: {} '.format(img,cls)     \n",
    "    print(' *** Zout2 ', Zout2[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian(Zout2[img,:,:,cls], title = ttl)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display ground truth bboxes from Shapes database (using `load_image_gt` )\n",
    "\n",
    "Here we are displaying the ground truth bounding boxes as provided by the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T12:09:01.819867Z",
     "start_time": "2018-05-02T12:09:01.408894Z"
    },
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "img = 0\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "p_original_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "# print(p_gt_class_id.shape, p_gt_bbox.shape, p_gt_mask.shape)\n",
    "print(p_gt_bbox[0:3,:])\n",
    "print(p_gt_class_id)\n",
    "visualize.draw_boxes(p_original_image, p_gt_bbox[0:3])\n",
    "\n",
    "# image_id = img_meta[img,0]\n",
    "# print('Image id: ',image_id)\n",
    "# p_original_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "#             load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "# # print(p_gt_class_id.shape, p_gt_bbox.shape, p_gt_mask.shape)\n",
    "# print(p_gt_bbox)\n",
    "# print(p_gt_class_id)\n",
    "# visualize.draw_boxes(p_original_image, p_gt_bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false
   },
   "source": [
    "### Display Predicted  Ground Truth Bounding Boxes  `gt_tensor` and `gt_tensor2`\n",
    "\n",
    "layers_out[22]  `gt_tensor` is based on input_gt_class_ids and input_normlzd_gt_boxes\n",
    "layers_out[28]  `gt_tensor2` is based on input_gt_class_ids and input_normlzd_gt_boxes, generated using Tensorflow\n",
    "\n",
    "Display the Ground Truth bounding boxes from the tensor we've constructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T12:11:32.751502Z",
     "start_time": "2018-05-02T12:11:32.344790Z"
    },
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "from mrcnn.utils  import stack_tensors, stack_tensors_3d\n",
    "gt_bboxes_stacked = stack_tensors_3d(layers_out[23][img])\n",
    "\n",
    "# print(gt_bboxes)\n",
    "# visualize.display_instances(p_original_image, p_gt_bbox, p_gt_mask, p_gt_class_id, \n",
    "#                             dataset_train.class_names, figsize=(8, 8))\n",
    "# pp.pprint(gt_bboxes)\n",
    "img = 0\n",
    "image_id = img_meta[img,0]\n",
    "\n",
    "print('Image id: ',image_id)\n",
    "p_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)   \n",
    "\n",
    "print(gt_bboxes_stacked)\n",
    "visualize.draw_boxes(p_image, gt_bboxes_stacked[:,0:4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display RoI proposals `pred_bboxes` generated for one class\n",
    "\n",
    "Display bounding boxes from tensor of proposals produced by the network \n",
    "Square: 1 , Circle:2 , Triangle 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T12:13:48.882533Z",
     "start_time": "2018-05-02T12:13:48.424337Z"
    },
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "img = 0\n",
    "cls = 3 # <==== Class to display\n",
    "pred_tensor = layers_out[22]   # numpy pred_tesnor\n",
    "# pred_tensor = layers_out[25]   # tensorflow pred_tensor \n",
    "\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "p_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "print(p_image_meta)\n",
    "print(pred_tensor[img,cls,:].shape)\n",
    "print(pred_tensor[img,cls])\n",
    "#+'-'+str(np.around(int(x[1]),decimals = 3))\n",
    "# class id: str(int(x[6]))+'-'+\n",
    "caps = [str(int(x[0]))+'-'+str(np.around(x[1],decimals = 3))  for x in pred_tensor[img,cls,:].tolist() ]\n",
    "print(caps)\n",
    "\n",
    "visualize.draw_boxes(p_image, pred_tensor[img,cls,:,0:4], captions = caps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate  mrcnn_bbox_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T13:30:12.704056Z",
     "start_time": "2018-04-24T13:30:09.806418Z"
    },
    "hideCode": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "from mrcnn.utils import apply_box_deltas\n",
    "from mrcnn.loss  import smooth_l1_loss\n",
    "\n",
    "target_class_ids = layers_out[1][0:1]\n",
    "target_bbox      = layers_out[2][0:1]\n",
    "mrcnn_bbox       = layers_out[10][0:1]\n",
    "mrcnn_class_ids  = np.argmax(layers_out[9][0:1],axis = -1)     # mrcnn_class_ids\n",
    "\n",
    "print('target_class_ids', target_class_ids.shape)\n",
    "print(target_class_ids)  # tgt_class_ids\n",
    "print(' class with max probability', mrcnn_class_ids.shape)\n",
    "print(mrcnn_class_ids)\n",
    "print('target_bboxes', target_bbox.shape)\n",
    "# print(target_bbox)  # tgt_bounding boxes\n",
    "print('mrcnn_bboxes',mrcnn_bbox.shape)\n",
    "# print(mrcnn_bbox)  #mrcnn_bboxes\n",
    "pred_bbox = mrcnn_bbox\n",
    "\n",
    "# calc mrcnn_bbox_loss\n",
    "target_class_ids = K.reshape(target_class_ids, (-1,))\n",
    "print(target_class_ids.shape)\n",
    "target_bbox      = K.reshape(target_bbox, (-1, 4))\n",
    "print('target_bboxx: ', target_bbox.shape)\n",
    "pred_bbox        = K.reshape(pred_bbox, (-1, pred_bbox.shape[2], 4))\n",
    "print('pred_bbox : ', pred_bbox.shape)\n",
    "\n",
    "positive_roi_ix        = tf.where(target_class_ids > 0)[:, 0]\n",
    "print(positive_roi_ix.eval())\n",
    "positive_roi_class_ids = tf.cast( tf.gather(target_class_ids, positive_roi_ix), tf.int64)\n",
    "print(positive_roi_class_ids.eval())\n",
    "indices                = tf.stack([positive_roi_ix, positive_roi_class_ids], axis=1)\n",
    "print(indices.eval())\n",
    "\n",
    "\n",
    "target_bbox = tf.gather(target_bbox, positive_roi_ix)\n",
    "print(target_bbox.eval())\n",
    "pred_bbox   = tf.gather_nd(pred_bbox, indices)\n",
    "print(pred_bbox.eval())\n",
    "\n",
    "print('tf.size ',tf.size(target_bbox).eval())\n",
    "\n",
    "diff = K.abs(target_bbox - pred_bbox)\n",
    "print(diff.eval())\n",
    "\n",
    "less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n",
    "# print(less_than_one.eval())\n",
    "\n",
    "loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "# print( (1-less_than_one).eval())\n",
    "\n",
    "\n",
    "\n",
    "# loss        = K.switch(tf.size(target_bbox) > 0,\n",
    "#                 smooth_l1_loss(y_true=target_bbox, y_pred=pred_bbox),\n",
    "#                 tf.constant(0.0))\n",
    "print(loss.eval())\n",
    "sumloss = K.sum(loss)\n",
    "print(sumloss.eval())\n",
    "print((sumloss/40).eval())\n",
    "meanloss        = K.mean(loss)\n",
    "print(meanloss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Calculate mrcnn_class_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T14:00:16.666089Z",
     "start_time": "2018-04-24T14:00:14.585712Z"
    },
    "hideCode": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "from mrcnn.utils import apply_box_deltas\n",
    "from mrcnn.loss  import smooth_l1_loss\n",
    "\n",
    "target_class_ids = layers_out[1][0:1]\n",
    "pred_class_logits = layers_out[8][0:1]\n",
    "active_class_ids    = np.array([1,1,1,1])\n",
    "\n",
    "# mrcnn_class_ids  = np.argmax(layers_out[9][0:1],axis = -1)     # mrcnn_class_ids\n",
    "\n",
    "print(' target_class_ids', target_class_ids.shape)\n",
    "print(target_class_ids)  # tgt_class_ids\n",
    "print(' class logits', pred_class_logits.shape)\n",
    "print(pred_class_logits)\n",
    "print(' active, class_ids ', active_class_ids.shape)\n",
    "print(active_class_ids)  # tgt_bounding boxes\n",
    "\n",
    "pred_class_ids = tf.argmax(pred_class_logits, axis=2)\n",
    "print(pred_class_ids.eval())  #mrcnn_bboxes\n",
    "mrcnn_class_ids  = np.argmax(layers_out[9][0:1],axis = -1)     # mrcnn_class_ids\n",
    "print(mrcnn_class_ids)\n",
    "# pred_bbox = mrcnn_bbox\n",
    "pred_active = tf.to_float(tf.gather(active_class_ids, pred_class_ids))\n",
    "print(pred_active.eval())\n",
    "# calc mrcnn_bbox_loss\n",
    "loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "       labels=target_class_ids, logits=pred_class_logits)\n",
    "print(loss.eval())\n",
    "\n",
    "loss = loss * tf.to_float(pred_active)\n",
    "print(loss.eval())\n",
    "\n",
    "print(tf.reduce_sum(loss).eval())\n",
    "print(tf.reduce_sum(pred_active).eval())\n",
    "loss = tf.reduce_sum(loss) / tf.reduce_sum(pred_active)\n",
    "print(loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Calculate mrcnn_mask_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T14:30:39.761487Z",
     "start_time": "2018-04-24T14:30:35.393858Z"
    },
    "hideCode": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "from mrcnn.utils import apply_box_deltas\n",
    "from mrcnn.loss  import smooth_l1_loss\n",
    "\n",
    "target_class_ids    = layers_out[1][0:3]\n",
    "target_masks        = layers_out[3][0:3]\n",
    "pred_masks          = layers_out[11][0:3]\n",
    "# mrcnn_class_ids  = np.argmax(layers_out[9][0:1],axis = -1)     # mrcnn_class_ids\n",
    "print('    target_class_ids shape :', target_class_ids.shape)\n",
    "print('    target_masks     shape :', target_masks.shape)\n",
    "print('    pred_masks       shape :', pred_masks.shape)    \n",
    "\n",
    "\n",
    "target_class_ids = K.reshape(target_class_ids, (-1,))\n",
    "print('    target_class_ids shape :', target_class_ids.shape, '\\n', target_class_ids.eval())\n",
    "\n",
    "mask_shape       = tf.shape(target_masks)\n",
    "print('    mask_shape       shape :', mask_shape.shape, mask_shape.eval())    \n",
    "\n",
    "target_masks     = K.reshape(target_masks, (-1, mask_shape[2], mask_shape[3]))\n",
    "print('    target_masks     shape :', tf.shape(target_masks).eval())        \n",
    "\n",
    "pred_shape       = tf.shape(pred_masks)\n",
    "print('    pred_shape       shape :', pred_shape.shape, pred_shape.eval())        \n",
    "\n",
    "pred_masks       = K.reshape(pred_masks, (-1, pred_shape[2], pred_shape[3], pred_shape[4]))\n",
    "print('    pred_masks       shape :', tf.shape(pred_masks).eval())        \n",
    "\n",
    "\n",
    "pred_masks = tf.transpose(pred_masks, [0, 3, 1, 2])\n",
    "print('    pred_masks       shape :', tf.shape(pred_masks).eval())        \n",
    "\n",
    "# Only positive ROIs contribute to the loss. And only\n",
    "# the class specific mask of each ROI.\n",
    "positive_ix        = tf.where(target_class_ids > 0)[:, 0]\n",
    "positive_class_ids = tf.cast(tf.gather(target_class_ids, positive_ix), tf.int64)\n",
    "indices            = tf.stack([positive_ix, positive_class_ids], axis=1)\n",
    "print(indices.eval())\n",
    "\n",
    "\n",
    "\n",
    "y_true = tf.gather(target_masks, positive_ix)\n",
    "print('     y_true shape:', tf.shape(y_true).eval())\n",
    "y_pred = tf.gather_nd(pred_masks, indices)\n",
    "print('     y_pred shape:', tf.shape(y_pred).eval())\n",
    "\n",
    "loss = K.switch(tf.size(y_true) > 0,\n",
    "                K.binary_crossentropy(target=y_true, output=y_pred),\n",
    "                tf.constant(0.0))\n",
    "print(tf.shape(loss).eval())\n",
    "\n",
    "loss = K.mean(loss)\n",
    "print('     final loss shape:', tf.shape(loss).eval())\n",
    "print(loss.eval())\n",
    "loss = K.reshape(loss, [1, 1])\n",
    "print('     final loss shape:', tf.shape(loss).eval())\n",
    "print(loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate a pixel loss on fcn_gaussian and gt_gaussian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-26T19:56:22.310929Z",
     "start_time": "2018-04-26T19:56:13.583609Z"
    },
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "from mrcnn.utils import apply_box_deltas\n",
    "from mrcnn.loss  import smooth_l1_loss\n",
    "pred_masks          = layers_out[12][0:3]   # fcn_predictions \n",
    "target_masks        = layers_out[19][0:3]   # gt_gaussians\n",
    "\n",
    "print('    target_masks     shape :', tf.shape(target_masks).eval())\n",
    "print('    pred_masks       shape :', tf.shape(pred_masks).eval())    \n",
    "\n",
    "diff = K.abs(target_masks - pred_masks)\n",
    "print(tf.shape(diff).eval())\n",
    "\n",
    "less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n",
    "print('   less_than_one     shape :', tf.shape(less_than_one).eval(), K.sum(less_than_one).eval())\n",
    "\n",
    "more_than_one = 1 - less_than_one\n",
    "print('   more_than_one     shape :', tf.shape(more_than_one).eval(), K.sum(more_than_one).eval())\n",
    "# loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "\n",
    "loss = (less_than_one * 0.5 * diff**2) + (more_than_one * (diff - 0.5))\n",
    "print(tf.shape(loss).eval())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# loss = K.switch(tf.size(y_true) > 0,\n",
    "#                 K.binary_crossentropy(target=y_true, output=y_pred),\n",
    "#                 tf.constant(0.0))\n",
    "meanloss = K.mean(loss)\n",
    "print(tf.shape(meanloss).eval())\n",
    "print(meanloss.eval())\n",
    "# loss = K.reshape(loss, [1, 1])\n",
    "# print('     final loss shape:', loss.get_shape())\n",
    "# return loss\n",
    "\n",
    "\n",
    "mask_shape       = tf.shape(target_masks)\n",
    "print('    mask_shape       shape :', tf.shape(mask_shape).eval())    \n",
    "\n",
    "target_masks     = K.reshape(target_masks, (-1, mask_shape[1], mask_shape[2]))\n",
    "print('    target_masks     shape :', tf.shape(target_masks).eval())        \n",
    "\n",
    "pred_shape       = tf.shape(pred_masks)\n",
    "print('    pred_shape       shape :', tf.shape(pred_shape).eval())        \n",
    "\n",
    "pred_masks       = K.reshape(pred_masks, (-1, pred_shape[1], pred_shape[2]))\n",
    "print('    pred_masks       shape :', tf.shape(pred_masks).eval())\n",
    "\n",
    "# Permute predicted masks to [N, num_classes, height, width]\n",
    "# diff = K.abs(target_masks - pred_masks)\n",
    "# print(tf.shape(diff).eval())\n",
    "\n",
    "# less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n",
    "# print(tf.shape(less_than_one).eval())\n",
    "\n",
    "# loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "# print(tf.shape(loss).eval())\n",
    "\n",
    "# meanloss = K.mean(loss)\n",
    "# print(tf.shape(meanloss).eval())\n",
    "# print(meanloss.eval())\n",
    "\n",
    "loss = K.switch(tf.size(target_masks) > 0,\n",
    "                smooth_l1_loss(y_true=target_masks, y_pred=pred_masks),\n",
    "                tf.constant(0.0))\n",
    "loss = K.mean(loss)\n",
    "loss = K.reshape(loss, [1, 1])\n",
    "print('     final loss shape:', loss.get_shape())\n",
    "print(loss.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T12:52:37.323856Z",
     "start_time": "2018-04-24T12:52:37.052134Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img  = 0\n",
    "class_probs = layers_out[9][img]   # mrcnn_class\n",
    "deltas      = layers_out[10][img]       # mrcnn_bbox\n",
    "\n",
    "print(class_probs.shape)\n",
    "print('class probabilities')\n",
    "print(class_probs)\n",
    "class_ids = np.argmax(layers_out[9][img],axis = 1)     # mrcnn_class_ids\n",
    "print(' class with max probability')\n",
    "print(class_ids)\n",
    "\n",
    "\n",
    "# layers_out[10][2,0,3]\n",
    "print('deltas.shape :', deltas.shape)\n",
    "print(deltas[0:4])\n",
    "\n",
    "deltas_specific = deltas[np.arange(32),class_ids]\n",
    "print('deltas of max prob class: ', deltas_specific.shape)\n",
    "print(deltas_specific[0:5])\n",
    "output_rois = layers_out[0][img]*[128,128,128,128]\n",
    "print('output_rois: ', output_rois.shape)\n",
    "print(output_rois[0:])\n",
    "\n",
    "refined_rois    = apply_box_deltas(output_rois, deltas_specific * config.BBOX_STD_DEV)\n",
    "print('refined rois: ',refined_rois.shape)\n",
    "print(refined_rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T20:11:05.556185Z",
     "start_time": "2018-04-23T20:11:05.323590Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layers_out[30][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T09:56:40.181058Z",
     "start_time": "2018-04-24T09:56:39.956461Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = 0\n",
    "cls = 0\n",
    "fcn_out = layers_out[12][img]\n",
    "fcn_sum = np.sum(fcn_out, axis=(0,1))\n",
    "print(fcn_sum)\n",
    "for cls in range(4):\n",
    "    print('min :', np.min(fcn_out[:,:,cls]), 'max :', np.max(fcn_out[:,:,cls]), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T20:55:21.917361Z",
     "start_time": "2018-04-23T20:55:21.676734Z"
    }
   },
   "outputs": [],
   "source": [
    "print(train_batch_x[4][2])\n",
    "print(train_batch_x[5][2]/[128,128,128,128])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Fine Tuning\n",
    "Fine tune all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also \n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=211,\n",
    "            layers=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "# Uncomment to save manually\n",
    "model_path = os.path.join(MODEL_DIR, \"mask_rcnn_shapes.h5\")\n",
    "model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Training\n",
    "\n",
    "Train in two stages:\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
    "\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Training head using  Keras.model.fit_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-26T19:24:26.445711Z",
     "start_time": "2018-04-26T19:24:26.442202Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "\n",
    "# model.train(dataset_train, dataset_val, \n",
    "#             learning_rate=config.LEARNING_RATE, \n",
    "# #             epochs = 69,\n",
    "#             epochs_to_run =2, \n",
    "#             layers='heads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## - Training heads using train_in_batches ()\n",
    "\n",
    "We need to use this method for the time being as the fit generator does not have provide EASY access to the output in Keras call backs. By training in batches, we pass a batch through the network, pick up the generated RoI detections and bounding boxes and generate our semantic / gaussian tensors ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-26T19:24:22.024942Z",
     "start_time": "2018-04-26T19:24:22.020900Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model.train_in_batches(dataset_train, dataset_val, \n",
    "#             learning_rate=config.LEARNING_RATE/6, \n",
    "#             epochs_to_run = 200,\n",
    "#             layers='heads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Losses process in compile routine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T15:41:00.742329Z",
     "start_time": "2018-04-27T15:40:59.008093Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Add Losses\n",
    "# First, clear previously set losses to avoid duplication\n",
    "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
    "model.keras_model._losses = []\n",
    "model.keras_model._per_input_losses = {}\n",
    "loss_names = [\"rpn_class_loss\", \"rpn_bbox_loss\",\n",
    "              \"mrcnn_class_loss\", \"mrcnn_bbox_loss\", \"mrcnn_mask_loss\", \"fcn_loss\"]\n",
    "print(model.keras_model._losses)\n",
    "for name in loss_names:\n",
    "    layer = model.keras_model.get_layer(name)\n",
    "    print('layer output is : ', layer.output)\n",
    "\n",
    "    if layer.output in model.keras_model.losses:\n",
    "        continue\n",
    "    print('   keras model add loss for ', layer.output)\n",
    "    model.keras_model.add_loss(tf.reduce_mean(layer.output, keepdims=True))\n",
    "    \n",
    "pp.pprint(model.keras_model._losses)\n",
    "    \n",
    "    \n",
    "# Skip gamma and beta weights of batch normalization layers.\n",
    "reg_losses = [keras.regularizers.l2(model.config.WEIGHT_DECAY)(w) / tf.cast(tf.size(w), tf.float32)\n",
    "              for w in model.keras_model.trainable_weights\n",
    "              if 'gamma' not in w.name and 'beta' not in w.name]\n",
    "\n",
    "model.keras_model.add_loss(tf.add_n(reg_losses))\n",
    "print(' model losses')\n",
    "pp.pprint(model.keras_model._losses)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python [conda env:TF_gpu]",
   "language": "python",
   "name": "conda-env-TF_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
