{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Mask R-CNN - Compare ouptuts from Heatmap layer and FCN layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T14:39:17.460048Z",
     "start_time": "2018-05-03T14:38:47.586601Z"
    },
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import  gc\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import keras.backend as KB\n",
    "sys.path.append('../')\n",
    "\n",
    "import mrcnn.model     as modellib\n",
    "import mrcnn.visualize as visualize\n",
    "import mrcnn.shapes    as shapes\n",
    "from mrcnn.config      import Config\n",
    "from mrcnn.model       import log\n",
    "from mrcnn.dataset     import Dataset \n",
    "\n",
    "from mrcnn.utils       import stack_tensors, stack_tensors_3d\n",
    "from mrcnn.datagen     import data_generator, load_image_gt\n",
    "from mrcnn.callbacks   import get_layer_output_1,get_layer_output_2\n",
    "from mrcnn.visualize   import plot_gaussian\n",
    "# from mrcnn.pc_layer    import PCTensor\n",
    "# from mrcnn.pc_layer   import PCNLayer\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "MODEL_PATH = 'E:\\Models'\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(MODEL_PATH, \"mrcnn_logs\")\n",
    "# Path to COCO trained weights\n",
    "COCO_MODEL_PATH   = os.path.join(MODEL_PATH, \"mask_rcnn_coco.h5\")\n",
    "RESNET_MODEL_PATH = os.path.join(MODEL_PATH, \"resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n",
    "\n",
    "print(\"Tensorflow Version: {}   Keras Version : {} \".format(tf.__version__,keras.__version__))\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
    "np.set_printoptions(linewidth=100,precision=4)\n",
    "\n",
    "\n",
    "# Build configuration object -----------------------------------------------\n",
    "config = shapes.ShapesConfig()\n",
    "config.BATCH_SIZE      = 5                  # Batch size is 2 (# GPUs * images/GPU).\n",
    "config.IMAGES_PER_GPU  = 5                  # Must match BATCH_SIZE\n",
    "config.STEPS_PER_EPOCH = 2\n",
    "config.FCN_INPUT_SHAPE = config.IMAGE_SHAPE[0:2]\n",
    "# config.display() \n",
    "\n",
    "# Build shape dataset        -----------------------------------------------\n",
    "# Training dataset\n",
    "# generate 500 shapes \n",
    "dataset_train = shapes.ShapesDataset()\n",
    "dataset_train.load_shapes(500, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = shapes.ShapesDataset()\n",
    "dataset_val.load_shapes(50, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_val.prepare()\n",
    "\n",
    "try :\n",
    "    del model, train_generator, val_generator, mm\n",
    "    gc.collect()\n",
    "except: \n",
    "    pass\n",
    "# Load and display random samples\n",
    "# image_ids = np.random.choice(dataset_train.image_ids, 3)\n",
    "# for image_id in [3]:\n",
    "#     image = dataset_train.load_image(image_id)\n",
    "#     mask, class_ids = dataset_train.load_mask(image_id)\n",
    "#     visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "print(' COCO Model Path       : ', COCO_MODEL_PATH)\n",
    "print(' Checkpoint folder Path: ', MODEL_DIR)\n",
    "print(MODEL_PATH)\n",
    "print(COCO_MODEL_PATH)\n",
    "print(RESNET_MODEL_PATH)\n",
    "print(MODEL_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T14:39:28.178493Z",
     "start_time": "2018-05-03T14:39:17.461008Z"
    },
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try :\n",
    "    del model\n",
    "    print('delete model is successful')\n",
    "    gc.collect()\n",
    "except: \n",
    "    pass\n",
    "KB.clear_session()\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T14:39:40.038228Z",
     "start_time": "2018-05-03T14:39:28.180500Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(model.find_last())\n",
    "# Which weights to start with?\n",
    "init_with = \"last\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "#     loc=model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "    loc=model.load_weights(RESNET_MODEL_PATH, by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    \n",
    "    # See README for instructions to download the COCO weights\n",
    "    loc=model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    loc= model.load_weights(model.find_last()[1], by_name=True)\n",
    "print('Load weights complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false
   },
   "source": [
    "###  Print some model information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T14:39:40.300936Z",
     "start_time": "2018-05-03T14:39:40.041235Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "#model.keras_model.summary(line_length = 120) \n",
    "# model.compile_only(learning_rate=config.LEARNING_RATE, layers='heads')\n",
    "# KB.set_learning_phase(1)\n",
    "print('\\n Outputs: ') \n",
    "pp.pprint(model.keras_model.outputs)\n",
    "print('\\n Losses (model.metrics_names): ') \n",
    "# pp.pprint(model.keras_model.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T14:39:40.573651Z",
     "start_time": "2018-05-03T14:39:40.302932Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.keras_model.summary(line_length = 150) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Define Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T14:39:40.839357Z",
     "start_time": "2018-05-03T14:39:40.575658Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_generator = data_generator(dataset_train, model.config, shuffle=True,\n",
    "                                 batch_size=model.config.BATCH_SIZE,\n",
    "                                 augment = False)\n",
    "val_generator = data_generator(dataset_val, model.config, shuffle=True, \n",
    "                                batch_size=model.config.BATCH_SIZE,\n",
    "                                augment=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Get next shapes from generator and display loaded shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T14:39:41.176251Z",
     "start_time": "2018-05-03T14:39:40.841363Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_batch_x, train_batch_y = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T14:39:42.740421Z",
     "start_time": "2018-05-03T14:39:41.178258Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train_batch_x, train_batch_y = next(train_generator)\n",
    "imgmeta_idx = model.keras_model.input_names.index('input_image_meta')\n",
    "print(imgmeta_idx)\n",
    "img_meta    = train_batch_x[imgmeta_idx]\n",
    "\n",
    "for img_idx in range(config.BATCH_SIZE):\n",
    "    image_id = img_meta[img_idx,0]\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    print('Image id: ',image_id)\n",
    "    print('Image meta', img_meta[img_idx])\n",
    "    print('Classes (1: circle, 2: square, 3: triangle ): ',class_ids)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Push Data thru model using get_layer_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-05-03T14:43:21.703Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "layers_out = get_layer_output_2(model.keras_model, train_batch_x, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-05-03T14:43:24.995Z"
    }
   },
   "outputs": [],
   "source": [
    "sess=  tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Compute mean/min/max of Pred/GT gaussian tensors and FCN output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:57:00.620812Z",
     "start_time": "2018-05-02T11:56:55.389850Z"
    },
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "fcn_masks  = tf.identity(layers_out[12])\n",
    "pred_masks = tf.identity(layers_out[18])\n",
    "gt_masks   = tf.identity(layers_out[19])\n",
    "shape = KB.int_shape(pred_masks)\n",
    "print(shape)\n",
    "\n",
    "pred_masks_r = tf.reshape(pred_masks, [shape[0], -1, shape[-1]])\n",
    "fcn_masks_r = tf.reshape(fcn_masks, [shape[0], -1, shape[-1]])\n",
    "gt_masks_r  = tf.reshape(gt_masks, [shape[0], -1, shape[-1]])\n",
    "\n",
    "print(gt_masks_r.shape, fcn_masks_r.shape)\n",
    "\n",
    "pred_mean2 = KB.mean(pred_masks_r, axis = 1).eval()\n",
    "pred_max2  =  KB.max(pred_masks_r, axis=1).eval()\n",
    "pred_min2  =  KB.min(pred_masks_r, axis=1).eval()\n",
    "\n",
    "gt_mean2 = KB.mean(gt_masks_r, axis = 1).eval()\n",
    "gt_max2  =  KB.max(gt_masks_r, axis=1).eval()\n",
    "gt_min2  =  KB.min(gt_masks_r, axis=1).eval()\n",
    "\n",
    "fcn_mean2 = KB.mean(fcn_masks_r, axis = 1).eval()\n",
    "fcn_max2  =  KB.max(fcn_masks_r, axis=1).eval()\n",
    "fcn_min2  =  KB.min(fcn_masks_r, axis=1).eval()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute L2 Normalizationof Pred, GT, and FCN tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:57:50.121346Z",
     "start_time": "2018-05-02T11:57:47.648793Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_l2      = KB.l2_normalize(pred_masks_r, axis = 1)\n",
    "gt_l2        = KB.l2_normalize(gt_masks_r, axis = 1)\n",
    "fcn_l2       = KB.l2_normalize(fcn_masks_r, axis = 1)\n",
    "pred_l2_min  = KB.min(pred_l2, axis = 1).eval()\n",
    "pred_l2_max  = KB.max(pred_l2, axis = 1).eval()\n",
    "pred_l2_mean = KB.mean(pred_l2, axis = 1).eval()\n",
    "gt_l2_min    = KB.min(gt_l2, axis = 1).eval()\n",
    "gt_l2_max    = KB.max(gt_l2, axis = 1).eval()\n",
    "gt_l2_mean   = KB.mean(gt_l2, axis = 1).eval()\n",
    "fcn_l2_min   = KB.min(fcn_l2, axis = 1).eval()\n",
    "fcn_l2_max   = KB.max(fcn_l2, axis = 1).eval()\n",
    "fcn_l2_mean  = KB.mean(fcn_l2, axis = 1).eval()\n",
    "\n",
    "print(' Shape of L2 normalized tensor: ',pred_l2.shape, gt_l2.shape, fcn_l2.shape)\n",
    "print(' Shape of L2 min tensor       : ',pred_l2_min.shape, gt_l2_min.shape, fcn_l2_min.shape)\n",
    "print(' Shape of L2 max tensor       : ',pred_l2_max.shape, gt_l2_max.shape, fcn_l2_max.shape)\n",
    "print(' Shape of L2 mean tensor      : ',pred_l2_mean.shape, gt_l2_mean.shape, fcn_l2_mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T19:30:00.463214Z",
     "start_time": "2018-04-30T19:29:58.395080Z"
    }
   },
   "outputs": [],
   "source": [
    "# pred_l2      = tf.nn.l2_normalize(pred_masks_r, axis = 1)\n",
    "# gt_l2        = tf.nn.l2_normalize(gt_masks_r, axis = 1)\n",
    "# fcn_l2       = tf.nn.l2_normalize(fcn_masks_r, axis = 1)\n",
    "# pred_l2_min  = tf.reduce_min(pred_l2, axis = 1).eval()\n",
    "# pred_l2_max  = tf.reduce_max(pred_l2, axis = 1).eval()\n",
    "# pred_l2_mean = tf.reduce_mean(pred_l2, axis = 1).eval()\n",
    "# gt_l2_min    = tf.reduce_min(gt_l2, axis = 1).eval()\n",
    "# gt_l2_max    = tf.reduce_max(gt_l2, axis = 1).eval()\n",
    "# gt_l2_mean   = tf.reduce_mean(gt_l2, axis = 1).eval()\n",
    "# fcn_l2_min   = tf.reduce_min(fcn_l2, axis = 1).eval()\n",
    "# fcn_l2_max   = tf.reduce_max(fcn_l2, axis = 1).eval()\n",
    "# fcn_l2_mean  = tf.reduce_mean(fcn_l2, axis = 1).eval()\n",
    "\n",
    "# print(' Shape of L2 normalized tensor: ',pred_l2.shape, gt_l2.shape, fcn_l2.shape)\n",
    "# print(' Shape of L2 min tensor       : ',pred_l2_min.shape, gt_l2_min.shape, fcn_l2_min.shape)\n",
    "# print(' Shape of L2 max tensor       : ',pred_l2_max.shape, gt_l2_max.shape, fcn_l2_max.shape)\n",
    "# print(' Shape of L2 mean tensor      : ',pred_l2_mean.shape, gt_l2_mean.shape, fcn_l2_mean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Print results of L2 normalization (Mean, Min , Max) vs. Original values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:58:04.116559Z",
     "start_time": "2018-05-02T11:58:03.880152Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img in range(5):\n",
    "    for cls in range(4):\n",
    "        print('\\n I/C:{}/{} '.format(img, cls))\n",
    "        print('             Mean:  gt:{:.5e}  fcn:{: 11.5e}   pred: {:.6f}'\\\n",
    "              .format(gt_mean2[img,cls], fcn_mean2[img,cls], pred_mean2[img,cls]))\n",
    "        print('          L2 Mean:  gt:{:.5e}  fcn:{: 11.5e}   pred: {:.6f}'\\\n",
    "              .format(gt_l2_mean[img,cls], fcn_l2_mean[img,cls], pred_l2_mean[img,cls]))\n",
    "        print('             MAX:   gt:{:.5e}  fcn:{: 11.5e}   pred: {:.5e}' \\\n",
    "              .format(gt_max2[img,cls], fcn_max2[img,cls], pred_max2[img,cls]))\n",
    "        print('          L2 MAX:   gt:{:.5e}  fcn:{: 11.5e}   pred: {:.5e}' \\\n",
    "              .format(gt_l2_max[img,cls], fcn_l2_max[img,cls], pred_l2_max[img,cls]))\n",
    "        print('             MIN:   gt:{:.5e}  fcn:{: 11.5e}   pred: {:.5e}'\\\n",
    "              .format(gt_min2[img,cls], fcn_min2[img,cls], pred_min2[img,cls]))              \n",
    "        print('          L2 MIN:   gt:{:.5e}  fcn:{: 11.5e}   pred: {:.5e}'\\\n",
    "              .format(gt_l2_min[img,cls], fcn_l2_min[img,cls], pred_l2_min[img,cls]))              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print (Mean, Min , Max)  values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T11:58:34.705338Z",
     "start_time": "2018-05-02T11:58:34.470714Z"
    },
    "hideCode": false,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "print(gt_masks.shape, fcn_masks.shape)\n",
    "\n",
    "for img in range(5):\n",
    "    for cls in range(4):\n",
    "        print('I/C: {}/{}  min/max     gt: [{:.5e} , {:.5e}]       pred: [{:.5e} , {:.5e}]     fcn:[{:.5e} , {:.5e}]   '\\\n",
    "              .format(img, cls,    gt_min2[img,cls], gt_max2[img,cls], pred_min2[img,cls], pred_max2[img,cls] ,\n",
    "                                  fcn_min2[img,cls], fcn_max2[img,cls] ))    \n",
    "        \n",
    "print('\\n\\n')        \n",
    "for img in range(5):\n",
    "    for cls in range(4):\n",
    "        print('I/C:{}/{}  Mean:  gt: {:.5e}   fcn : {:9.5e}   pred : {:.6f}   \\t MAX: gt:{:.5e}  fcn:{:.5e}  pred: {:.5e}'\\\n",
    "              .format(img, cls, gt_mean2[img,cls], fcn_mean2[img,cls], pred_mean2[img,cls], \n",
    "                      gt_max2[img,cls], fcn_max2[img,cls], pred_max2[img,cls]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T13:45:09.321729Z",
     "start_time": "2018-04-27T13:45:07.895936Z"
    }
   },
   "outputs": [],
   "source": [
    "print(tf.shape(pred_masks).eval())\n",
    "shape = tf.shape(pred_masks).eval()\n",
    "pred_masks_r = tf.reshape(pred_masks, [shape[0], -1, shape[-1]])\n",
    "means = KB.mean(pred_masks_r, axis = 1)\n",
    "maxs  = KB.max(pred_masks_r, axis=1)\n",
    "\n",
    "# norms, means2, var = KB.normalize_batch_in_training(pred_masks[, 1.0, 0.0,[0,3])\n",
    "l2_norm = KB.l2_normalize (pred_masks_r,axis = 1)\n",
    "print(pred_masks.shape,pred_masks_r.shape)\n",
    "print(means.shape, maxs.shape)\n",
    "# print(' Shape of BN tensor: ', norms.shape)\n",
    "# print(' Shape of means2 tensor: ', means2.shape)\n",
    "# print(' Shape of var tensor: ', var.shape)\n",
    "print(' Shape of L2 normalized tensor: ',l2_norm.shape)\n",
    "print()\n",
    "np.set_printoptions(linewidth=130, threshold=20000, precision=6)\n",
    "print('norms')\n",
    "print(norms.eval())\n",
    "print('means')\n",
    "print(means.eval())\n",
    "print('maxs')\n",
    "print(maxs.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Show reshaped tensor and original tensor are equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T16:37:25.446823Z",
     "start_time": "2018-04-27T16:37:25.178129Z"
    }
   },
   "outputs": [],
   "source": [
    "p2 = tf.reshape(pred_masks_r, shape)   # reshape flattened back to original shape\n",
    "print(KB.int_shape(pred_masks),KB.int_shape(p2))\n",
    "equal = KB.equal(pred_masks, p2)\n",
    "print(KB.all(equal).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T13:12:19.679083Z",
     "start_time": "2018-04-27T13:12:19.086002Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pt   = layers_out[4]   # pred_gaussian \n",
    "# pt2  = layers_out[10]  # pred_gaussian_2\n",
    "np.set_printoptions(linewidth=130, threshold=20000)\n",
    "gt   =  np.transpose(pred_masks.eval(), [0,3,1,2])\n",
    "gt2  =  np.transpose(p2.eval(), [0,3,1,2])\n",
    "# gt   = np.where(gt > 1e-6,gt,0)\n",
    "# gt2   = np.where(gt2 > 1e-6,gt2,0)\n",
    "print( ' pt shape ', gt.shape, ' pt2.shape ', gt2.shape)\n",
    "\n",
    "for img in range(config.BATCH_SIZE):\n",
    "#     print(' from np ')\n",
    "#     print(pt[img])\n",
    "#     print(' from tensorflow')\n",
    "#     print(pt2[img])\n",
    "    for cls in range(4):\n",
    "        equal = np.equal(gt2[img,cls,:,:] , gt[img, cls,:,:])\n",
    "        print(equal.shape)\n",
    "        print( 'Image ',img,' Class ',cls, '  all equal: ',equal.all())        \n",
    "        print(equal.shape)\n",
    "        \n",
    "        if (~equal.all()):\n",
    "            print('Not Equal: ',~equal)\n",
    "            print( 'Image ',img,' Class ',cls, ' ALL EQUAL: ',equal.all())\n",
    "#             print('\\n -- using numpy      \\n',  gt[img, cls, ~equal])\n",
    "#             print('\\n -- using tensorflow \\n', gt2[img, cls, ~equal])\n",
    "# if not equal display the different between the mismatching rows\n",
    "            for i in range(equal.shape[0]):\n",
    "                if ~equal[i]:\n",
    "                    diff = np.abs(gt2[img, cls, i] - gt[img, cls, i])\n",
    "                    big_error = np.any(diff > 3.0e-9, axis = -1)\n",
    "                    print('   row = ', i, ' rows equal = ',equal[i], '   Big Error (larger than 7.0e-8): ' ,big_error)\n",
    "                    if big_error:\n",
    "                        print(' difference  :', diff )\n",
    "#                     print(' -- using numpy      \\n',gt[img,cls,i])            \n",
    "#                     print(' -- using tensorflow \\n',gt2[img,cls,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Plot Predicted and Ground Truth Probability Heatmaps `pred_gaussian` and `gt_gaussian` (Tensorflow)\n",
    "\n",
    "`pred_gaussian2` and `gt_gaussian2` from Tensorflow PCN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T12:03:50.991894Z",
     "start_time": "2018-05-02T12:03:49.403155Z"
    },
    "hideCode": false,
    "hideOutput": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# gt_heatmap  = layers_out[27]     # gt_gaussiam \n",
    "# pred_heatmap= layers_out[24]  # pred_gaussian\n",
    "gt_heatmap  = layers_out[19]     # gt_gaussiam \n",
    "pred_heatmap= layers_out[18]  # pred_gaussian\n",
    "print('gt_gaussian heatmap shape : ', gt_heatmap.shape, ' pred_gaussian heatmap shape: ', pred_heatmap.shape)\n",
    "num_images = 1 # config.IMAGES_PER_GPU\n",
    "num_classes = config.NUM_CLASSES\n",
    "\n",
    "img = 4\n",
    "\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "print('Classes (1: circle, 2: square, 3: triangle ): ')\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "\n",
    "for cls in range(1,num_classes):\n",
    "    ttl = 'GROUND TRUTH HEATMAP - image :  {} class: {} '.format(img,cls)\n",
    "    print(' *** Zout  ', gt_heatmap[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian( gt_heatmap[img,:,:,cls], title = ttl)\n",
    "    \n",
    "    ttl = 'PREDICTED heatmap  - image :  {} class: {} '.format(img,cls)     \n",
    "    print(' *** pred_heatmap ', pred_heatmap[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian(pred_heatmap[img,:,:,cls], title = ttl)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T20:22:44.443661Z",
     "start_time": "2018-04-30T20:22:44.181416Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred_tensor = layers_out[22]\n",
    "gt_tensor   = layers_out[23]\n",
    "print(pred_tensor.shape)\n",
    "# pt2_sum = tf.reduce_sum(tf.abs(in_tensor[:,:,:,:-1]), axis=-1)\n",
    "pred_tensor[2,:,:,:]\n",
    "# print(pred_tensor[2])\n",
    "# print(gt_tensor.shape)\n",
    "# print(gt_tensor[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T20:22:28.695670Z",
     "start_time": "2018-04-30T20:22:23.406687Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in [2]:\n",
    "    for cls in range(4):\n",
    "        pred_tst = pred_heatmap[img,:,:,cls]\n",
    "        gt_tst = gt_heatmap[img,:,:,cls]\n",
    "        print(pred_tst.shape, gt_tst.shape)\n",
    "        print('img/cls :', img,cls, 'pred sum : ',tf.reduce_sum(pred_tst).eval(), 'gt sum : ',tf.reduce_sum(gt_tst).eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Plot Output from FCN network `fcn_bilinear` and compare with `pred_gaussian`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T12:41:20.682566Z",
     "start_time": "2018-05-03T12:41:15.046586Z"
    },
    "hideCode": false,
    "hideOutput": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mrcnn.visualize import plot_gaussian\n",
    "import matplotlib as plt\n",
    "\n",
    "%matplotlib inline\n",
    "img = 3\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "print('Classes (1: circle, 2: square, 3: triangle ): ')\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "\n",
    "Zout  = layers_out[18]     # gt_gaussiam \n",
    "Zout2 = layers_out[12]     # fcn_bilinear\n",
    "\n",
    "print(Zout.shape, Zout2.shape)\n",
    "num_images = config.IMAGES_PER_GPU\n",
    "num_classes = config.NUM_CLASSES\n",
    "\n",
    "\n",
    "for cls in range(num_classes):\n",
    "    ttl = 'GroundTruth - image :  {} class: {} '.format(img,cls)\n",
    "    print(' *** Zout  ', Zout[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian( Zout[img,:,:,cls], title = ttl)\n",
    "    \n",
    "    ttl = 'FCN_Bilinear- image :  {} class: {} '.format(img,cls)     \n",
    "    print(' *** Zout2 ', Zout2[img,:,:,cls].shape, ttl)   \n",
    "    plot_gaussian(Zout2[img,:,:,cls], title = ttl)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display ground truth bboxes from Shapes database (using `load_image_gt` )\n",
    "\n",
    "Here we are displaying the ground truth bounding boxes as provided by the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T12:09:01.819867Z",
     "start_time": "2018-05-02T12:09:01.408894Z"
    },
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "img = 0\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "p_original_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "# print(p_gt_class_id.shape, p_gt_bbox.shape, p_gt_mask.shape)\n",
    "print(p_gt_bbox[0:3,:])\n",
    "print(p_gt_class_id)\n",
    "visualize.draw_boxes(p_original_image, p_gt_bbox[0:3])\n",
    "\n",
    "# image_id = img_meta[img,0]\n",
    "# print('Image id: ',image_id)\n",
    "# p_original_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "#             load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "# # print(p_gt_class_id.shape, p_gt_bbox.shape, p_gt_mask.shape)\n",
    "# print(p_gt_bbox)\n",
    "# print(p_gt_class_id)\n",
    "# visualize.draw_boxes(p_original_image, p_gt_bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false
   },
   "source": [
    "### Display Predicted  Ground Truth Bounding Boxes  `gt_tensor` and `gt_tensor2`\n",
    "\n",
    "layers_out[22]  `gt_tensor` is based on input_gt_class_ids and input_normlzd_gt_boxes\n",
    "layers_out[28]  `gt_tensor2` is based on input_gt_class_ids and input_normlzd_gt_boxes, generated using Tensorflow\n",
    "\n",
    "Display the Ground Truth bounding boxes from the tensor we've constructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T12:11:32.751502Z",
     "start_time": "2018-05-02T12:11:32.344790Z"
    },
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "from mrcnn.utils  import stack_tensors, stack_tensors_3d\n",
    "gt_bboxes_stacked = stack_tensors_3d(layers_out[23][img])\n",
    "\n",
    "# print(gt_bboxes)\n",
    "# visualize.display_instances(p_original_image, p_gt_bbox, p_gt_mask, p_gt_class_id, \n",
    "#                             dataset_train.class_names, figsize=(8, 8))\n",
    "# pp.pprint(gt_bboxes)\n",
    "img = 0\n",
    "image_id = img_meta[img,0]\n",
    "\n",
    "print('Image id: ',image_id)\n",
    "p_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)   \n",
    "\n",
    "print(gt_bboxes_stacked)\n",
    "visualize.draw_boxes(p_image, gt_bboxes_stacked[:,0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display RoI proposals `pred_bboxes` generated for one class\n",
    "\n",
    "Display bounding boxes from tensor of proposals produced by the network \n",
    "Square: 1 , Circle:2 , Triangle 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T12:13:48.882533Z",
     "start_time": "2018-05-02T12:13:48.424337Z"
    },
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "img = 0\n",
    "cls = 3 # <==== Class to display\n",
    "pred_tensor = layers_out[22]   # numpy pred_tesnor\n",
    "# pred_tensor = layers_out[25]   # tensorflow pred_tensor \n",
    "\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "p_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "print(p_image_meta)\n",
    "print(pred_tensor[img,cls,:].shape)\n",
    "print(pred_tensor[img,cls])\n",
    "#+'-'+str(np.around(int(x[1]),decimals = 3))\n",
    "# class id: str(int(x[6]))+'-'+\n",
    "caps = [str(int(x[0]))+'-'+str(np.around(x[1],decimals = 3))  for x in pred_tensor[img,cls,:].tolist() ]\n",
    "print(caps)\n",
    "\n",
    "visualize.draw_boxes(p_image, pred_tensor[img,cls,:,0:4], captions = caps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate  mrcnn_bbox_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T13:30:12.704056Z",
     "start_time": "2018-04-24T13:30:09.806418Z"
    },
    "hideCode": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "from mrcnn.utils import apply_box_deltas\n",
    "from mrcnn.loss  import smooth_l1_loss\n",
    "\n",
    "target_class_ids = layers_out[1][0:1]\n",
    "target_bbox      = layers_out[2][0:1]\n",
    "mrcnn_bbox       = layers_out[10][0:1]\n",
    "mrcnn_class_ids  = np.argmax(layers_out[9][0:1],axis = -1)     # mrcnn_class_ids\n",
    "\n",
    "print('target_class_ids', target_class_ids.shape)\n",
    "print(target_class_ids)  # tgt_class_ids\n",
    "print(' class with max probability', mrcnn_class_ids.shape)\n",
    "print(mrcnn_class_ids)\n",
    "print('target_bboxes', target_bbox.shape)\n",
    "# print(target_bbox)  # tgt_bounding boxes\n",
    "print('mrcnn_bboxes',mrcnn_bbox.shape)\n",
    "# print(mrcnn_bbox)  #mrcnn_bboxes\n",
    "pred_bbox = mrcnn_bbox\n",
    "\n",
    "# calc mrcnn_bbox_loss\n",
    "target_class_ids = K.reshape(target_class_ids, (-1,))\n",
    "print(target_class_ids.shape)\n",
    "target_bbox      = K.reshape(target_bbox, (-1, 4))\n",
    "print('target_bboxx: ', target_bbox.shape)\n",
    "pred_bbox        = K.reshape(pred_bbox, (-1, pred_bbox.shape[2], 4))\n",
    "print('pred_bbox : ', pred_bbox.shape)\n",
    "\n",
    "positive_roi_ix        = tf.where(target_class_ids > 0)[:, 0]\n",
    "print(positive_roi_ix.eval())\n",
    "positive_roi_class_ids = tf.cast( tf.gather(target_class_ids, positive_roi_ix), tf.int64)\n",
    "print(positive_roi_class_ids.eval())\n",
    "indices                = tf.stack([positive_roi_ix, positive_roi_class_ids], axis=1)\n",
    "print(indices.eval())\n",
    "\n",
    "\n",
    "target_bbox = tf.gather(target_bbox, positive_roi_ix)\n",
    "print(target_bbox.eval())\n",
    "pred_bbox   = tf.gather_nd(pred_bbox, indices)\n",
    "print(pred_bbox.eval())\n",
    "\n",
    "print('tf.size ',tf.size(target_bbox).eval())\n",
    "\n",
    "diff = K.abs(target_bbox - pred_bbox)\n",
    "print(diff.eval())\n",
    "\n",
    "less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n",
    "# print(less_than_one.eval())\n",
    "\n",
    "loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "# print( (1-less_than_one).eval())\n",
    "\n",
    "\n",
    "\n",
    "# loss        = K.switch(tf.size(target_bbox) > 0,\n",
    "#                 smooth_l1_loss(y_true=target_bbox, y_pred=pred_bbox),\n",
    "#                 tf.constant(0.0))\n",
    "print(loss.eval())\n",
    "sumloss = K.sum(loss)\n",
    "print(sumloss.eval())\n",
    "print((sumloss/40).eval())\n",
    "meanloss        = K.mean(loss)\n",
    "print(meanloss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Calculate mrcnn_class_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T14:00:16.666089Z",
     "start_time": "2018-04-24T14:00:14.585712Z"
    },
    "hideCode": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "from mrcnn.utils import apply_box_deltas\n",
    "from mrcnn.loss  import smooth_l1_loss\n",
    "\n",
    "target_class_ids = layers_out[1][0:1]\n",
    "pred_class_logits = layers_out[8][0:1]\n",
    "active_class_ids    = np.array([1,1,1,1])\n",
    "\n",
    "# mrcnn_class_ids  = np.argmax(layers_out[9][0:1],axis = -1)     # mrcnn_class_ids\n",
    "\n",
    "print(' target_class_ids', target_class_ids.shape)\n",
    "print(target_class_ids)  # tgt_class_ids\n",
    "print(' class logits', pred_class_logits.shape)\n",
    "print(pred_class_logits)\n",
    "print(' active, class_ids ', active_class_ids.shape)\n",
    "print(active_class_ids)  # tgt_bounding boxes\n",
    "\n",
    "pred_class_ids = tf.argmax(pred_class_logits, axis=2)\n",
    "print(pred_class_ids.eval())  #mrcnn_bboxes\n",
    "mrcnn_class_ids  = np.argmax(layers_out[9][0:1],axis = -1)     # mrcnn_class_ids\n",
    "print(mrcnn_class_ids)\n",
    "# pred_bbox = mrcnn_bbox\n",
    "pred_active = tf.to_float(tf.gather(active_class_ids, pred_class_ids))\n",
    "print(pred_active.eval())\n",
    "# calc mrcnn_bbox_loss\n",
    "loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "       labels=target_class_ids, logits=pred_class_logits)\n",
    "print(loss.eval())\n",
    "\n",
    "loss = loss * tf.to_float(pred_active)\n",
    "print(loss.eval())\n",
    "\n",
    "print(tf.reduce_sum(loss).eval())\n",
    "print(tf.reduce_sum(pred_active).eval())\n",
    "loss = tf.reduce_sum(loss) / tf.reduce_sum(pred_active)\n",
    "print(loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Calculate mrcnn_mask_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T14:30:39.761487Z",
     "start_time": "2018-04-24T14:30:35.393858Z"
    },
    "hideCode": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "from mrcnn.utils import apply_box_deltas\n",
    "from mrcnn.loss  import smooth_l1_loss\n",
    "\n",
    "target_class_ids    = layers_out[1][0:3]\n",
    "target_masks        = layers_out[3][0:3]\n",
    "pred_masks          = layers_out[11][0:3]\n",
    "# mrcnn_class_ids  = np.argmax(layers_out[9][0:1],axis = -1)     # mrcnn_class_ids\n",
    "print('    target_class_ids shape :', target_class_ids.shape)\n",
    "print('    target_masks     shape :', target_masks.shape)\n",
    "print('    pred_masks       shape :', pred_masks.shape)    \n",
    "\n",
    "\n",
    "target_class_ids = K.reshape(target_class_ids, (-1,))\n",
    "print('    target_class_ids shape :', target_class_ids.shape, '\\n', target_class_ids.eval())\n",
    "\n",
    "mask_shape       = tf.shape(target_masks)\n",
    "print('    mask_shape       shape :', mask_shape.shape, mask_shape.eval())    \n",
    "\n",
    "target_masks     = K.reshape(target_masks, (-1, mask_shape[2], mask_shape[3]))\n",
    "print('    target_masks     shape :', tf.shape(target_masks).eval())        \n",
    "\n",
    "pred_shape       = tf.shape(pred_masks)\n",
    "print('    pred_shape       shape :', pred_shape.shape, pred_shape.eval())        \n",
    "\n",
    "pred_masks       = K.reshape(pred_masks, (-1, pred_shape[2], pred_shape[3], pred_shape[4]))\n",
    "print('    pred_masks       shape :', tf.shape(pred_masks).eval())        \n",
    "\n",
    "\n",
    "pred_masks = tf.transpose(pred_masks, [0, 3, 1, 2])\n",
    "print('    pred_masks       shape :', tf.shape(pred_masks).eval())        \n",
    "\n",
    "# Only positive ROIs contribute to the loss. And only\n",
    "# the class specific mask of each ROI.\n",
    "positive_ix        = tf.where(target_class_ids > 0)[:, 0]\n",
    "positive_class_ids = tf.cast(tf.gather(target_class_ids, positive_ix), tf.int64)\n",
    "indices            = tf.stack([positive_ix, positive_class_ids], axis=1)\n",
    "print(indices.eval())\n",
    "\n",
    "\n",
    "\n",
    "y_true = tf.gather(target_masks, positive_ix)\n",
    "print('     y_true shape:', tf.shape(y_true).eval())\n",
    "y_pred = tf.gather_nd(pred_masks, indices)\n",
    "print('     y_pred shape:', tf.shape(y_pred).eval())\n",
    "\n",
    "loss = K.switch(tf.size(y_true) > 0,\n",
    "                K.binary_crossentropy(target=y_true, output=y_pred),\n",
    "                tf.constant(0.0))\n",
    "print(tf.shape(loss).eval())\n",
    "\n",
    "loss = K.mean(loss)\n",
    "print('     final loss shape:', tf.shape(loss).eval())\n",
    "print(loss.eval())\n",
    "loss = K.reshape(loss, [1, 1])\n",
    "print('     final loss shape:', tf.shape(loss).eval())\n",
    "print(loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate a pixel loss on fcn_gaussian and gt_gaussian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-26T19:56:22.310929Z",
     "start_time": "2018-04-26T19:56:13.583609Z"
    },
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "from mrcnn.utils import apply_box_deltas\n",
    "from mrcnn.loss  import smooth_l1_loss\n",
    "pred_masks          = layers_out[12][0:3]   # fcn_predictions \n",
    "target_masks        = layers_out[19][0:3]   # gt_gaussians\n",
    "\n",
    "print('    target_masks     shape :', tf.shape(target_masks).eval())\n",
    "print('    pred_masks       shape :', tf.shape(pred_masks).eval())    \n",
    "\n",
    "diff = K.abs(target_masks - pred_masks)\n",
    "print(tf.shape(diff).eval())\n",
    "\n",
    "less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n",
    "print('   less_than_one     shape :', tf.shape(less_than_one).eval(), K.sum(less_than_one).eval())\n",
    "\n",
    "more_than_one = 1 - less_than_one\n",
    "print('   more_than_one     shape :', tf.shape(more_than_one).eval(), K.sum(more_than_one).eval())\n",
    "# loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "\n",
    "loss = (less_than_one * 0.5 * diff**2) + (more_than_one * (diff - 0.5))\n",
    "print(tf.shape(loss).eval())\n",
    "\n",
    "# loss = K.switch(tf.size(y_true) > 0,\n",
    "#                 K.binary_crossentropy(target=y_true, output=y_pred),\n",
    "#                 tf.constant(0.0))\n",
    "meanloss = K.mean(loss)\n",
    "print(tf.shape(meanloss).eval())\n",
    "print(meanloss.eval())\n",
    "# loss = K.reshape(loss, [1, 1])\n",
    "# print('     final loss shape:', loss.get_shape())\n",
    "# return loss\n",
    "\n",
    "\n",
    "mask_shape       = tf.shape(target_masks)\n",
    "print('    mask_shape       shape :', tf.shape(mask_shape).eval())    \n",
    "\n",
    "target_masks     = K.reshape(target_masks, (-1, mask_shape[1], mask_shape[2]))\n",
    "print('    target_masks     shape :', tf.shape(target_masks).eval())        \n",
    "\n",
    "pred_shape       = tf.shape(pred_masks)\n",
    "print('    pred_shape       shape :', tf.shape(pred_shape).eval())        \n",
    "\n",
    "pred_masks       = K.reshape(pred_masks, (-1, pred_shape[1], pred_shape[2]))\n",
    "print('    pred_masks       shape :', tf.shape(pred_masks).eval())\n",
    "\n",
    "# Permute predicted masks to [N, num_classes, height, width]\n",
    "# diff = K.abs(target_masks - pred_masks)\n",
    "# print(tf.shape(diff).eval())\n",
    "\n",
    "# less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n",
    "# print(tf.shape(less_than_one).eval())\n",
    "\n",
    "# loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "# print(tf.shape(loss).eval())\n",
    "\n",
    "# meanloss = K.mean(loss)\n",
    "# print(tf.shape(meanloss).eval())\n",
    "# print(meanloss.eval())\n",
    "\n",
    "loss = K.switch(tf.size(target_masks) > 0,\n",
    "                smooth_l1_loss(y_true=target_masks, y_pred=pred_masks),\n",
    "                tf.constant(0.0))\n",
    "loss = K.mean(loss)\n",
    "loss = K.reshape(loss, [1, 1])\n",
    "print('     final loss shape:', loss.get_shape())\n",
    "print(loss.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T12:52:37.323856Z",
     "start_time": "2018-04-24T12:52:37.052134Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img  = 0\n",
    "class_probs = layers_out[9][img]   # mrcnn_class\n",
    "deltas      = layers_out[10][img]       # mrcnn_bbox\n",
    "\n",
    "print(class_probs.shape)\n",
    "print('class probabilities')\n",
    "print(class_probs)\n",
    "class_ids = np.argmax(layers_out[9][img],axis = 1)     # mrcnn_class_ids\n",
    "print(' class with max probability')\n",
    "print(class_ids)\n",
    "\n",
    "\n",
    "# layers_out[10][2,0,3]\n",
    "print('deltas.shape :', deltas.shape)\n",
    "print(deltas[0:4])\n",
    "\n",
    "deltas_specific = deltas[np.arange(32),class_ids]\n",
    "print('deltas of max prob class: ', deltas_specific.shape)\n",
    "print(deltas_specific[0:5])\n",
    "output_rois = layers_out[0][img]*[128,128,128,128]\n",
    "print('output_rois: ', output_rois.shape)\n",
    "print(output_rois[0:])\n",
    "\n",
    "refined_rois    = apply_box_deltas(output_rois, deltas_specific * config.BBOX_STD_DEV)\n",
    "print('refined rois: ',refined_rois.shape)\n",
    "print(refined_rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T09:56:40.181058Z",
     "start_time": "2018-04-24T09:56:39.956461Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = 0\n",
    "cls = 0\n",
    "fcn_out = layers_out[12][img]\n",
    "fcn_sum = np.sum(fcn_out, axis=(0,1))\n",
    "print(fcn_sum)\n",
    "for cls in range(4):\n",
    "    print('min :', np.min(fcn_out[:,:,cls]), 'max :', np.max(fcn_out[:,:,cls]), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T20:55:21.917361Z",
     "start_time": "2018-04-23T20:55:21.676734Z"
    }
   },
   "outputs": [],
   "source": [
    "print(train_batch_x[4][2])\n",
    "print(train_batch_x[5][2]/[128,128,128,128])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python [conda env:TF_gpu]",
   "language": "python",
   "name": "conda-env-TF_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
