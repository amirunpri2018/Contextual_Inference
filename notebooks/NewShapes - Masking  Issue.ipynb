{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Mask R-CNN - Train on NewShapes Dataset\n",
    "\n",
    "### Notes from implementation\n",
    "\n",
    "This notebook shows how to train Mask R-CNN on your own dataset. To keep things simple we use a synthetic dataset of shapes (squares, triangles, and circles) which enables fast training. You'd still need a GPU, though, because the network backbone is a Resnet101, which would be too slow to train on a CPU. On a GPU, you can start to get okay-ish results in a few minutes, and good results in less than an hour.\n",
    "\n",
    "The code of the *Shapes* dataset is included below. It generates images on the fly, so it doesn't require downloading any data. And it can generate images of any size, so we pick a small image size to train faster. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T16:41:51.274551Z",
     "start_time": "2018-05-09T16:41:46.682708Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import  gc\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# import tensorflow as tf\n",
    "# import keras\n",
    "import pprint\n",
    "# import keras.backend as KB\n",
    "sys.path.append('../')\n",
    "\n",
    "# import mrcnn.model     as modellib\n",
    "import mrcnn.visualize as visualize\n",
    "# import mrcnn.shapes    as shapes\n",
    "import mrcnn.new_shapes as shapes\n",
    "from mrcnn.config      import Config\n",
    "from mrcnn.model       import log\n",
    "from mrcnn.dataset     import Dataset \n",
    "\n",
    "from mrcnn.utils       import stack_tensors, stack_tensors_3d\n",
    "from mrcnn.datagen     import data_generator, load_image_gt\n",
    "from mrcnn.callbacks   import get_layer_output_1,get_layer_output_2\n",
    "# from mrcnn.visualize   import plot_gaussian\n",
    "# from mrcnn.pc_layer    import PCTensor\n",
    "# from mrcnn.pc_layer   import PCNLayer\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "MODEL_PATH = 'E:\\Models'\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(MODEL_PATH, \"mrcnn_logs\")\n",
    "# Path to COCO trained weights\n",
    "COCO_MODEL_PATH   = os.path.join(MODEL_PATH, \"mask_rcnn_coco.h5\")\n",
    "RESNET_MODEL_PATH = os.path.join(MODEL_PATH, \"resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n",
    "\n",
    "# print(\"Tensorflow Version: {}   Keras Version : {} \".format(tf.__version__,keras.__version__))\n",
    "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
    "np.set_printoptions(linewidth=100,precision=4)\n",
    "\n",
    "\n",
    "# Build configuration object -----------------------------------------------\n",
    "config = shapes.ShapesConfig()\n",
    "config.BATCH_SIZE      = 5                  # Batch size is 2 (# GPUs * images/GPU).\n",
    "config.IMAGES_PER_GPU  = 5                  # Must match BATCH_SIZE\n",
    "config.STEPS_PER_EPOCH = 2\n",
    "config.FCN_INPUT_SHAPE = config.IMAGE_SHAPE[0:2]\n",
    "\n",
    "# config.LAST_EPOCH_RAN  = 5686  # <---- if we want to continue training from a previously run\n",
    "config.display() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T16:41:52.328919Z",
     "start_time": "2018-05-09T16:41:51.277065Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Build shape dataset        -----------------------------------------------\n",
    "# Training dataset\n",
    "# generate 500 shapes \n",
    "\n",
    "dataset_train = shapes.NewShapesDataset()\n",
    "dataset_train.load_shapes(500, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_train.prepare()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Display some random image samples and their masks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-08T19:54:42.538387Z",
     "start_time": "2018-05-08T19:54:42.076157Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Load and display random samples\n",
    "# image_ids = np.random.choice(dataset_train.image_ids, 3)\n",
    "# for image_id in [3]:\n",
    "#     image = dataset_train.load_image(image_id)\n",
    "#     mask, class_ids = dataset_train.load_mask(image_id)\n",
    "#     visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T14:02:52.023855Z",
     "start_time": "2018-05-09T14:02:50.397917Z"
    },
    "hideOutput": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names, limit=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Display some random image samples  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T16:42:37.885416Z",
     "start_time": "2018-05-09T16:42:37.210620Z"
    },
    "hideCode": false,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    visualize.display_images([image], cols = 1, width = 6)         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load and display masks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T13:44:55.179218Z",
     "start_time": "2018-05-09T13:44:54.766597Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load and display random samples\n",
    "from mrcnn.utils import mask_string\n",
    "image_id = np.random.choice(dataset_train.image_ids, 1)\n",
    "image_id = [113]\n",
    "image = dataset_train.load_image(image_id[0])\n",
    "mask, class_ids = dataset_train.load_mask(image_id[0])\n",
    "print(mask.shape)\n",
    "# for i in range(6):\n",
    "#     print()\n",
    "#     print(mask_string(mask[:,:,i]))\n",
    "\n",
    "# visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names, limit=6)\n",
    "# visualize.display_images([image], cols = 1, width = 6)         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Define data generators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T14:32:33.073841Z",
     "start_time": "2018-05-09T14:32:32.837193Z"
    }
   },
   "outputs": [],
   "source": [
    "train_generator = data_generator(dataset_train, config, shuffle=True, batch_size=100, augment = False)\n",
    "\n",
    "# val_generator = data_generator(dataset_val, model.config, shuffle=True, batch_size=model.config.BATCH_SIZE,  augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T14:41:23.406061Z",
     "start_time": "2018-05-09T14:41:22.565854Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_batch_x, train_batch_y = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T14:49:00.523911Z",
     "start_time": "2018-05-09T14:48:59.958768Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
    "image_ids  = [113, 326, 476, 97,174, 381, 488]\n",
    "image_ids  = [176]\n",
    "for image_id in image_ids:\n",
    "#     image = dataset_train.load_image(image_id)\n",
    "#     mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    image, image_meta, gt_class_ids, gt_boxes, gt_masks = \\\n",
    "                load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)    \n",
    "#     print(gt_boxes)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names, limit=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T14:06:05.414338Z",
     "start_time": "2018-05-09T14:06:05.070103Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=135,precision=4,threshold=20000)\n",
    "for img_id in image_ids:\n",
    "#     print('Classes (1: circle, 2: square, 3: triangle ): ',class_ids)\n",
    "    image, image_meta, gt_class_ids, gt_boxes, gt_masks = \\\n",
    "                    load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=False) \n",
    "    print(gt_class_ids.shape, gt_boxes.shape, gt_masks.shape)\n",
    "#     for i in range(gt_masks.shape[-1]):\n",
    "#         print('\\n',np.array2string(np.where(gt_masks[:,:,i],1,0),max_line_width=134, separator = ''))\n",
    "    print(gt_boxes)\n",
    "    print(gt_class_ids)        \n",
    "    visualize.display_images([image], cols = 1, width = 8)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Image info structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T14:06:32.050254Z",
     "start_time": "2018-05-09T14:06:31.821145Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_train.image_info[176]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T10:17:59.850346Z",
     "start_time": "2018-05-09T10:17:59.612715Z"
    }
   },
   "outputs": [],
   "source": [
    "img_id = 22\n",
    "\n",
    "shapes = dataset_train.image_info[img_id]['shapes']\n",
    "pp.pprint(shapes)\n",
    "sorted_shapes = []\n",
    "boxes_ls = []\n",
    "boxes_xy = []\n",
    "#--------------------------------------------------\n",
    "#---- toi sort in an order \n",
    "#--------------------------------------------------\n",
    "# sort_lst = [itm[2][1] for itm in shapes]\n",
    "# sorted_shape_ind = np.argsort(np.array(sort_lst))[::+1]\n",
    "# print(sort_lst, '\\n',sorted_shape_ind)\n",
    "\n",
    "# for i in sorted_shape_ind:\n",
    "#     sorted_shapes.append(shapes[i])\n",
    "#     x, y, sx, sy = shapes[i][2]\n",
    "#     boxes_ls.append([y - sy, x - sx, y + sy, x + sx])            \n",
    "            \n",
    "\n",
    "for shp in shapes:\n",
    "    x, y, sx, sy = shp[2]\n",
    "    boxes_ls.append([y - sy, x - sx, y + sy, x + sx])            \n",
    "    boxes_xy.append([x - sx, y - sy, x + sx, y + sy])            \n",
    "    \n",
    "pp.pprint(boxes_xy)\n",
    "pp.pprint(sorted_shapes)\n",
    "boxes = np.array(boxes_ls)\n",
    "# print(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T09:23:43.597616Z",
     "start_time": "2018-05-09T09:23:43.356998Z"
    }
   },
   "outputs": [],
   "source": [
    "from mrcnn.new_shapes import debug_non_max_suppression\n",
    "ixs = debug_non_max_suppression(boxes_np, np.arange(boxes_np.shape[0]), 0.29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T14:16:43.884241Z",
     "start_time": "2018-05-09T14:16:43.653582Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=100,precision=4, threshold=20000)\n",
    "image_id = [315]\n",
    "# from mrcnn.utils import mask_string\n",
    "# image = dataset_train.load_image(image_id[0])\n",
    "shapes = dataset_train.image_info[image_id[0]]['shapes']\n",
    "pp.pprint(shapes)\n",
    "# mask, class_ids =  dataset_train.load_mask(image_id[0])\n",
    "hidden =  dataset_train.find_hidden_shapes(shapes,128,128)\n",
    "# visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names, limit=6)\n",
    "# visualize.display_images([image], cols = 1, width = 6)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display ground truth bboxes from Shapes database (using `load_image_gt` )\n",
    "\n",
    "Here we are displaying the ground truth bounding boxes as provided by the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T15:02:20.558960Z",
     "start_time": "2018-05-09T15:02:19.078928Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 6)\n",
    "for image_id in image_ids:\n",
    "#     image = dataset_train.load_image(image_id)\n",
    "#     mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    image, image_meta, gt_class_ids, gt_boxes, gt_masks = \\\n",
    "                load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)    \n",
    "#     print(gt_boxes)\n",
    "    visualize.draw_boxes(image, gt_boxes)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T12:37:20.334041Z",
     "start_time": "2018-04-24T12:37:19.929956Z"
    },
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "img = 0\n",
    "image_id = img_meta[img,0]\n",
    "print('Image id: ',image_id)\n",
    "p_original_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "# print(p_gt_class_id.shape, p_gt_bbox.shape, p_gt_mask.shape)\n",
    "print(p_gt_bbox[0:3,:])\n",
    "print(p_gt_class_id)\n",
    "visualize.draw_boxes(p_original_image, p_gt_bbox[0:3])\n",
    "\n",
    "# image_id = img_meta[img,0]\n",
    "# print('Image id: ',image_id)\n",
    "# p_original_image, p_image_meta, p_gt_class_id, p_gt_bbox, p_gt_mask =  \\\n",
    "#             load_image_gt(dataset_train, config, image_id, augment=False, use_mini_mask=True)\n",
    "# # print(p_gt_class_id.shape, p_gt_bbox.shape, p_gt_mask.shape)\n",
    "# print(p_gt_bbox)\n",
    "# print(p_gt_class_id)\n",
    "# visualize.draw_boxes(p_original_image, p_gt_bbox)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python [conda env:TF_gpu]",
   "language": "python",
   "name": "conda-env-TF_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
